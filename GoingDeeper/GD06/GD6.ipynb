{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0896e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "3.6.5\n",
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import gensim\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(nltk.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc3e00",
   "metadata": {},
   "source": [
    "* 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635bb3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "     |████████████████████████████████| 23.4 MB 4.3 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.21.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (5.2.1)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-3.8.3-cp39-cp39-linux_x86_64.whl size=24328218 sha256=b60b8103ef7cde8e45c45abfe2b89665da4f542ca6452704d172d3effba78aff\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/ca/5d/af/618594ec2f28608c1d6ee7d2b7e95a3e9b06551e3b80a491d6\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.1.2\n",
      "    Uninstalling gensim-4.1.2:\n",
      "      Successfully uninstalled gensim-4.1.2\n",
      "Successfully installed gensim-3.8.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687ab600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cea7111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: rouge-score in /opt/conda/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge-score) (0.12.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge-score) (1.21.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5f6038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "     |████████████████████████████████| 61 kB 1.4 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from bert-score) (1.21.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from bert-score) (2.26.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from bert-score) (1.9.1+cu111)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.9/site-packages (from bert-score) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from bert-score) (21.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from bert-score) (1.3.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from bert-score) (3.4.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from bert-score) (4.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.9->bert-score) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.1->bert-score) (2021.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.0.0->bert-score) (4.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.0.19)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (0.0.46)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=3.0.0->bert-score) (2021.11.10)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->bert-score) (8.3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->bert-score) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->bert-score) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->bert-score) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->bert-score) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers>=3.0.0->bert-score) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers>=3.0.0->bert-score) (8.0.3)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f71a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1623850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/transformer_chatbot'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8726205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/aiffel/aiffel/transformer_chatbot/data/ChatbotData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78cd2e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3a9256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5290\n",
       "1    3570\n",
       "2    2963\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8613f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "\n",
    "    # 소문자 통일 \n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # 특수문자와 단어 사이 공백 생성\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    # 중복 따옴표 공백\n",
    "    sentence = re.sub(r'[\"]+', \" \", sentence)\n",
    "\n",
    "    # (숫자+한글+영어+문장부호)\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎ가-힣a-z0-9?.!,]+\", \" \", sentence) \n",
    "    \n",
    "    # 특수기호가 2개 이상 반복될 경우 하나로 통일\n",
    "    sentence = re.sub(r'([?.!,])\\1+', r'\\1', sentence)\n",
    "    \n",
    "    # 연속된 공백을 하나의 공백으로 통일\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38274930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# que 데이터 공백 제외한 글자 길이 분포\n",
    "Q = [len(sentence.replace(\" \", \"\")) for sentence in df['Q']]\n",
    "\n",
    "# ans 데이터 공백 제외한 글자 길이 분포\n",
    "A = [len(sentence.replace(\" \", \"\")) for sentence in df['A']]\n",
    "\n",
    "plt.hist(Q, bins=range(1, max(Q) + 1), edgecolor='black')\n",
    "plt.title(\"Q Length Distribution (No Spaces)\")\n",
    "plt.xlabel(\"Q Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(A, bins=range(1, max(A) + 1), edgecolor='black')\n",
    "plt.title(\"A Length Distribution (No Spaces)\")\n",
    "plt.xlabel(\"A Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1f60265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 57)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Q),max(A)\n",
    "# sequnece cutting 없음 전부 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f0bfb087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터 (que_corpus): ['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', 'ppl 심하네', 'sd카드 망가졌어']\n",
      "응답 데이터 (ans_corpus): ['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .', '다시 새로 사는 게 마음 편해요 .']\n",
      "que_corpus length 7725\n",
      "ans_corpus length 7725\n"
     ]
    }
   ],
   "source": [
    "def build_corpus(source_sentences, target_sentences, max_len=57):\n",
    "    \"\"\"\n",
    "    소스 및 타겟 데이터를 정제하고 중복을 제거하며 병렬 쌍을 유지.\n",
    "    1. ans_corpus 중복인 데이터들 인덱스 저장 후 제거\n",
    "    2. que_corpus 중복인 데이터들 인덱스 저장 후 제거\n",
    "    \"\"\"\n",
    "    # 전처리된 문장 저장\n",
    "    processed_pairs = []\n",
    "\n",
    "    for src, tgt in zip(source_sentences, target_sentences):\n",
    "        # 전처리\n",
    "        src = preprocess_sentence(src)\n",
    "        tgt = preprocess_sentence(tgt)\n",
    "\n",
    "        # 길이 필터링\n",
    "        if len(src.split()) <= max_len and len(tgt.split()) <= max_len:\n",
    "            processed_pairs.append((src, tgt))\n",
    "\n",
    "    # 1단계: ans_corpus 중복 제거\n",
    "    seen_tgt = {}\n",
    "    tgt_indices_to_keep = set()\n",
    "\n",
    "    for idx, (src, tgt) in enumerate(processed_pairs):\n",
    "        if tgt not in seen_tgt:\n",
    "            seen_tgt[tgt] = idx\n",
    "            tgt_indices_to_keep.add(idx)\n",
    "        else:\n",
    "            # 이전에 중복된 첫 번째 인덱스는 유지\n",
    "            tgt_indices_to_keep.add(seen_tgt[tgt])\n",
    "\n",
    "    # ans_corpus 중복 제거 후\n",
    "    processed_pairs = [pair for idx, pair in enumerate(processed_pairs) if idx in tgt_indices_to_keep]\n",
    "\n",
    "    # 2단계: que_corpus 중복 제거\n",
    "    seen_src = {}\n",
    "    src_indices_to_keep = set()\n",
    "\n",
    "    for idx, (src, tgt) in enumerate(processed_pairs):\n",
    "        if src not in seen_src:\n",
    "            seen_src[src] = idx\n",
    "            src_indices_to_keep.add(idx)\n",
    "        else:\n",
    "            # 이전에 중복된 첫 번째 인덱스는 유지\n",
    "            src_indices_to_keep.add(seen_src[src])\n",
    "\n",
    "    # que_corpus 중복 제거 후\n",
    "    processed_pairs = [pair for idx, pair in enumerate(processed_pairs) if idx in src_indices_to_keep]\n",
    "\n",
    "    # 소스와 타겟 데이터 분리\n",
    "    src_processed = [pair[0] for pair in processed_pairs]\n",
    "    tgt_processed = [pair[1] for pair in processed_pairs]\n",
    "\n",
    "    return src_processed, tgt_processed\n",
    "\n",
    "# build_corpus 함수 실행\n",
    "que_corpus, ans_corpus = build_corpus(df['Q'], df['A'])\n",
    "\n",
    "# 결과 확인\n",
    "print(\"질문 데이터 (que_corpus):\", que_corpus[:5])\n",
    "print(\"응답 데이터 (ans_corpus):\", ans_corpus[:5])\n",
    "print(\"que_corpus length\", len(que_corpus))\n",
    "print(\"ans_corpus length\", len(ans_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "15414ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que: 7725\n",
      "ans: 7725\n",
      "train_que: 7338 train_ans: 7338\n",
      "test_que: 387 test_ans: 387\n",
      "train_que[:5]: ['오늘밤은 비가 내립니다', '짝녀가 좋아하는 사람이 있답니다 .', '이러다 병걸리겠어', '데이트중에 정적 있어도 괜찮을까 ?', '그런 친구 아니었는데 너무 귀찮게 하네']\n",
      "train_ans[:5]: ['그러게요 . 비가 추적추적 내리네요 .', '그것 참 안됐군요 .', '아프면 안 돼요 . 그럼 제 마음이 아파요 .', '정적이 있을 때 아무렇지도 않으면 편안해진 거예요 .', '친구가 좋아하나봐요 .']\n",
      "test_que[:5]: ['동호회 나가기 귀찮아', '쉬고 싶은데 회식 가야돼', '후아 힘드네', '무릎 안 좋으면 스쿼트 하면 안되겠지 ?', '차단당했네']\n",
      "test_ans[:5]: ['오늘은 쉬세요 .', '일과 일상 사이에서 균형이 잘 맞길 바랄게요 .', '힘내라는 진부한 말 건네봅니다 .', '무릎에 무리가 갈 거예요 .', '잊는 데는 더 도움이 될지도 몰라요 .']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0.05%만 테스트 데이터로 \n",
    "train_que, test_que, train_ans, test_ans = train_test_split(que_corpus, ans_corpus, test_size=0.05, random_state=2024)\n",
    "\n",
    "print(\"que:\", len(que_corpus))\n",
    "print(\"ans:\", len(ans_corpus))\n",
    "print(\"train_que:\", len(train_que), \"train_ans:\", len(train_ans))\n",
    "print(\"test_que:\", len(test_que), \"test_ans:\", len(test_ans))\n",
    "\n",
    "print(\"train_que[:5]:\", train_que[:5])\n",
    "print(\"train_ans[:5]:\", train_ans[:5])\n",
    "print(\"test_que[:5]:\", test_que[:5])\n",
    "print(\"test_ans[:5]:\", test_ans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "09e2c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que_corpus: ['오늘밤은 비가 내립니다', '짝녀가 좋아하는 사람이 있답니다 .', '이러다 병걸리겠어', '데이트중에 정적 있어도 괜찮을까 ?', '그런 친구 아니었는데 너무 귀찮게 하네']\n",
      "ans_corpus: ['그러게요 . 비가 추적추적 내리네요 .', '그것 참 안됐군요 .', '아프면 안 돼요 . 그럼 제 마음이 아파요 .', '정적이 있을 때 아무렇지도 않으면 편안해진 거예요 .', '친구가 좋아하나봐요 .']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "# Mecab 인스턴스 생성\n",
    "mecab = Mecab()\n",
    "\n",
    "# train 토큰화 \n",
    "def tokenize_corpus(source_sentences, target_sentences, tokenizer):\n",
    "    \n",
    "    src_tokens = [tokenizer(sentence) for sentence in source_sentences]\n",
    "    tgt_tokens = [tokenizer(sentence) for sentence in target_sentences]\n",
    "    \n",
    "    return src_tokens, tgt_tokens\n",
    "\n",
    "# 토큰화\n",
    "que_tokens, ans_tokens = tokenize_corpus(train_que, train_ans, mecab.morphs)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"que_corpus:\", train_que[:5])\n",
    "print(\"ans_corpus:\", train_ans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1be27ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip ko.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75cd2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_model = gensim.models.Word2Vec.load('/aiffel/aiffel/transformer_chatbot/ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b50d4403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('끗', 0.4519278407096863),\n",
       " ('두면', 0.42365697026252747),\n",
       " ('경음', 0.4034014642238617),\n",
       " ('ㅋ', 0.398428738117218),\n",
       " ('파열음', 0.39511895179748535),\n",
       " ('홀소리', 0.3928065598011017),\n",
       " ('강호', 0.39152422547340393),\n",
       " ('비원', 0.3904140591621399),\n",
       " ('음수', 0.3901618421077728),\n",
       " ('장지', 0.3887813091278076)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_model.wv.most_similar(\"땡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692eb99b",
   "metadata": {},
   "source": [
    "### 유의어 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d1425f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub_with_pos(sentence, wv, num_words=4):\n",
    "    \"\"\"\n",
    "    문장에서 특정 품사(명사, 형용사, 동사)만 랜덤하게 선택하여 유사한 단어로 대체.\n",
    "    \"\"\"\n",
    "    mecab = Mecab()\n",
    "    tokens_with_pos = mecab.pos(sentence)\n",
    "    \n",
    "    # 명사, 형용사, 동사, 부사만 추출\n",
    "    valid_tokens = [word for word, pos in tokens_with_pos if pos in ('NNG', 'NNP', 'VA', 'VV','MAG')]\n",
    "\n",
    "    # 선택 가능한 단어 수 제한\n",
    "    num_words = min(num_words, len(valid_tokens))\n",
    "    selected_tokens = random.sample(valid_tokens, num_words) if valid_tokens else []\n",
    "\n",
    "    tokens = [word for word, _ in tokens_with_pos]  # 원본 문장 토큰화\n",
    "    \n",
    "    try:\n",
    "        for selected_tok in selected_tokens:\n",
    "            # 선택된 단어와 가장 유사한(유사도가 가장 높은) 단어 검색\n",
    "            similar_word = wv.most_similar(selected_tok)[0][0]\n",
    "            \n",
    "            # 선택된 단어를 유사한 단어로 대체 (첫 번째로 매칭된 단어만 변경)\n",
    "            for i, word in enumerate(tokens):\n",
    "                if word == selected_tok:\n",
    "                    tokens[i] = similar_word\n",
    "                    break\n",
    "    except KeyError:\n",
    "        # 선택된 단어가 Word2Vec 모델에 없을 경우 원래 문장 반환\n",
    "        return sentence\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# 증강\n",
    "def augment_corpus_with_pos(train_que, train_ans, wv, num_words=4):\n",
    "\n",
    "    augmented_data = []\n",
    "\n",
    "    for que, ans in zip(train_que, train_ans):\n",
    "        # 원본 병렬 데이터\n",
    "        augmented_data.append((que, ans))\n",
    "        \n",
    "        # train_que를 Augmentation\n",
    "        aug_que = lexical_sub_with_pos(que, wv, num_words=num_words)\n",
    "        if aug_que:\n",
    "            augmented_data.append((aug_que, ans))\n",
    "        \n",
    "        # train_ans를 Augmentation\n",
    "        aug_ans = lexical_sub_with_pos(ans, wv, num_words=num_words)\n",
    "        if aug_ans:\n",
    "            augmented_data.append((que, aug_ans))\n",
    "\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d40adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lexical 증강 데이터 생성\n",
    "\n",
    "# augmented_data_lexical = augment_corpus_with_pos(train_que, train_ans, ko_model.wv, num_words=4)\n",
    "\n",
    "# for que, ans in augmented_data_lexical:\n",
    "#     print(f\"Q: {que} \\nA: {ans}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "13b1ac16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22014"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augmented_data_lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "012bf1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('오늘밤은 비가 내립니다', '그러게요 . 비가 추적추적 내리네요 .'),\n",
       " ('아침 저녁 은 빌 가 내립니다', '그러게요 . 비가 추적추적 내리네요 .'),\n",
       " ('오늘밤은 비가 내립니다', '그러게요 . 비가 추적추적 내리네요 .')]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data_lexical[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea5b4a0",
   "metadata": {},
   "source": [
    "### random_swap\n",
    "* 명사-명사 or 부사-부사 or 동사-형용사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "381fa556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ea34e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap_with_pos(sentence, num_swaps=1, swap_types=['NNG-NNG', 'MAG-MAG', 'VV-VA']):\n",
    "    \"\"\"\n",
    "    문장에서 지정된 스왑 방식 중 하나를 랜덤으로 선택하여 단어의 위치를 교환.\n",
    "    :param sentence: 입력 문장\n",
    "    :param num_swaps: 교환 횟수\n",
    "    :param swap_types: 가능한 스왑 방식 리스트 (예: 'NNG-NNG', 'MAG-MAG', 'VV-VA')\n",
    "    :return: 단어가 교환된 문장\n",
    "    \"\"\"\n",
    "    mecab = Mecab()\n",
    "    tokens_with_pos = mecab.pos(sentence)\n",
    "    tokens = [word for word, _ in tokens_with_pos]  # 원본 문장 토큰화\n",
    "\n",
    "    # 랜덤 스왑 방식 선택\n",
    "    swap_type = random.choice(swap_types)\n",
    "    pos1, pos2 = swap_type.split('-')\n",
    "\n",
    "    # 첫 번째 품사에 해당하는 단어 추출\n",
    "    valid_tokens_1 = [(idx, word) for idx, (word, pos) in enumerate(tokens_with_pos) if pos == pos1]\n",
    "    valid_tokens_2 = [(idx, word) for idx, (word, pos) in enumerate(tokens_with_pos) if pos == pos2]\n",
    "\n",
    "    # 교환 가능한 단어 쌍이 부족한 경우 원래 문장 반환\n",
    "    if len(valid_tokens_1) < 1 or len(valid_tokens_2) < 1:\n",
    "        return sentence\n",
    "\n",
    "    # 지정된 횟수만큼 단어 위치 교환\n",
    "    for _ in range(min(num_swaps, len(valid_tokens_1), len(valid_tokens_2))):\n",
    "        idx1, word1 = random.choice(valid_tokens_1)\n",
    "        valid_tokens_2_filtered = [token for token in valid_tokens_2 if token[0] != idx1]\n",
    "        if not valid_tokens_2_filtered:\n",
    "            continue\n",
    "        idx2, word2 = random.choice(valid_tokens_2_filtered)\n",
    "\n",
    "        # 위치 교환\n",
    "        tokens[idx1], tokens[idx2] = tokens[idx2], tokens[idx1]\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6bf44684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_corpus_with_random_swap(train_que, train_ans, num_swaps=1, swap_types=['NNG-NNG', 'MAG-MAG', 'VV-VA']):\n",
    "    \"\"\"\n",
    "    que 또는 ans를 Random Swap 방식으로 증강. tqdm을 사용하여 진행 상황 표시.\n",
    "    :param train_que: 원본 질문 데이터\n",
    "    :param train_ans: 원본 답변 데이터\n",
    "    :param num_swaps: 교환 횟수\n",
    "    :param swap_types: 가능한 스왑 방식 리스트\n",
    "    :return: 증강된 데이터\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "\n",
    "    start_time = time.time() \n",
    "\n",
    "    with tqdm(total=len(train_que), desc=\"Random Swap Augmentation\") as pbar:\n",
    "        for que, ans in zip(train_que, train_ans):\n",
    "            # 원본 데이터 \n",
    "            augmented_data.append((que, ans))\n",
    "\n",
    "            # que 고정, ans만 Random Swap 증강\n",
    "            aug_ans = random_swap_with_pos(ans, num_swaps=num_swaps, swap_types=swap_types)\n",
    "            augmented_data.append((que, aug_ans))\n",
    "\n",
    "            # ans 고정, que만 Random Swap 증강\n",
    "            aug_que = random_swap_with_pos(que, num_swaps=num_swaps, swap_types=swap_types)\n",
    "            augmented_data.append((aug_que, ans))\n",
    "\n",
    "            pbar.update(1)  \n",
    "\n",
    "    end_time = time.time()  \n",
    "    print(f\"Total augmentation time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "8bf537bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb4748459a4c15ac2a511005e929c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Random Swap Augmentation:   0%|          | 0/7338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total augmentation time: 11.67 seconds\n",
      "Q: 오늘밤은 비가 내립니다 \n",
      "A: 그러게요 . 비가 추적추적 내리네요 .\n",
      "\n",
      "Q: 오늘밤은 비가 내립니다 \n",
      "A: 그러 게 요 . 비 가 추적추적 내리 네요 .\n",
      "\n",
      "Q: 오늘밤은 비가 내립니다 \n",
      "A: 그러게요 . 비가 추적추적 내리네요 .\n",
      "\n",
      "Q: 짝녀가 좋아하는 사람이 있답니다 . \n",
      "A: 그것 참 안됐군요 .\n",
      "\n",
      "Q: 짝녀가 좋아하는 사람이 있답니다 . \n",
      "A: 그것 참 안됐군요 .\n",
      "\n",
      "Q: 짝녀가 좋아하는 사람이 있답니다 . \n",
      "A: 그것 참 안됐군요 .\n",
      "\n",
      "Q: 이러다 병걸리겠어 \n",
      "A: 아프면 안 돼요 . 그럼 제 마음이 아파요 .\n",
      "\n",
      "Q: 이러다 병걸리겠어 \n",
      "A: 아프 면 안 돼요 . 그럼 제 마음 이 아파요 .\n",
      "\n",
      "Q: 이러다 병 걸리 겠 어 \n",
      "A: 아프면 안 돼요 . 그럼 제 마음이 아파요 .\n",
      "\n",
      "Q: 데이트중에 정적 있어도 괜찮을까 ? \n",
      "A: 정적이 있을 때 아무렇지도 않으면 편안해진 거예요 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Swap 증강 데이터 생성\n",
    "augmented_data_random_swap = augment_corpus_with_random_swap(\n",
    "    train_que, \n",
    "    train_ans, \n",
    "    num_swaps=1, \n",
    "    swap_types=['NNG-NNG', 'MAG-MAG', 'VV-VA']\n",
    ")\n",
    "\n",
    "for que, ans in augmented_data_random_swap[:10]:\n",
    "    print(f\"Q: {que} \\nA: {ans}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "28b820ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22014"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augmented_data_random_swap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a2212",
   "metadata": {},
   "source": [
    "### random_insertion\n",
    "* 명사 앞에 word2vec 중 가장 관련도 높은  형용사 추가. 없으면 동사 앞에 word2vec 중 가장 관련도 높은 부사 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "96b937c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_insertion_with_pos(sentence, wv, valid_pos_noun='NNG', valid_pos_verb='VV', insert_pos_noun='VA', insert_pos_verb='MAG', num_insertions=1):\n",
    "    \"\"\"\n",
    "    문장에서 명사 앞에 유의관계가 높은 형용사를 삽입하거나,\n",
    "    명사가 없을 경우 동사 앞에 부사를 삽입.\n",
    "    :param sentence: 입력 문장\n",
    "    :param wv: Word2Vec 모델\n",
    "    :param valid_pos_noun: 명사로 간주할 품사 태그\n",
    "    :param valid_pos_verb: 동사로 간주할 품사 태그\n",
    "    :param insert_pos_noun: 명사 앞에 삽입할 품사 태그\n",
    "    :param insert_pos_verb: 동사 앞에 삽입할 품사 태그\n",
    "    :param num_insertions: 삽입 횟수\n",
    "    :return: 단어가 삽입된 문장\n",
    "    \"\"\"\n",
    "    mecab = Mecab()\n",
    "    tokens_with_pos = mecab.pos(sentence)\n",
    "\n",
    "    tokens = [word for word, _ in tokens_with_pos]  # 원본 문장 토큰화\n",
    "\n",
    "    # 명사와 동사 위치 추출\n",
    "    noun_positions = [(idx, word) for idx, (word, pos) in enumerate(tokens_with_pos) if pos == valid_pos_noun]\n",
    "    verb_positions = [(idx, word) for idx, (word, pos) in enumerate(tokens_with_pos) if pos == valid_pos_verb]\n",
    "\n",
    "    # 명사가 있는 경우: 명사 앞에 형용사 삽입\n",
    "    if noun_positions:\n",
    "        for _ in range(min(num_insertions, len(noun_positions))):\n",
    "            idx, noun = random.choice(noun_positions)\n",
    "            try:\n",
    "                similar_word = wv.most_similar(noun)[0][0]  # 유사 단어 검색\n",
    "                tokens.insert(idx, similar_word)  # 명사 앞에 삽입\n",
    "            except KeyError:\n",
    "                continue  # 단어가 Word2Vec 모델에 없는 경우 무시\n",
    "\n",
    "    # 명사가 없는 경우: 동사 앞에 부사 삽입\n",
    "    elif verb_positions:\n",
    "        for _ in range(min(num_insertions, len(verb_positions))):\n",
    "            idx, verb = random.choice(verb_positions)\n",
    "            try:\n",
    "                similar_word = wv.most_similar(verb)[0][0]  # 유사 단어 검색\n",
    "                tokens.insert(idx, similar_word)  # 동사 앞에 삽입\n",
    "            except KeyError:\n",
    "                continue  # 단어가 Word2Vec 모델에 없는 경우 무시\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a03fefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_corpus_with_random_insertion(train_que, train_ans, wv, num_insertions=1):\n",
    "    \"\"\"\n",
    "    que 또는 ans를 Random Insertion 방식으로 증강.\n",
    "    :param train_que: 원본 질문 데이터\n",
    "    :param train_ans: 원본 답변 데이터\n",
    "    :param wv: Word2Vec 모델\n",
    "    :param num_insertions: 삽입 횟수\n",
    "    :return: 증강된 데이터\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "\n",
    "    with tqdm(total=len(train_que), desc=\"Random Insertion Augmentation\") as pbar:\n",
    "        for que, ans in zip(train_que, train_ans):\n",
    "            # 원본 데이터 \n",
    "            augmented_data.append((que, ans))\n",
    "\n",
    "            # que 고정, ans만 Random Insertion 증강\n",
    "            aug_ans = random_insertion_with_pos(ans, wv, num_insertions=num_insertions)\n",
    "            augmented_data.append((que, aug_ans))\n",
    "\n",
    "            # ans 고정, que만 Random Insertion 증강\n",
    "            aug_que = random_insertion_with_pos(que, wv, num_insertions=num_insertions)\n",
    "            augmented_data.append((aug_que, ans))\n",
    "\n",
    "            pbar.update(1) \n",
    "\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0ea02a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8e48056e7c444980458c929510abca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Random Insertion Augmentation:   0%|          | 0/7338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 오늘밤은 비가 내립니다 \n",
      "A: 그러게요 . 비가 추적추적 내리네요 .\n",
      "\n",
      "Q: 오늘밤은 비가 내립니다 \n",
      "A: 그러 게 요 . 빌 비 가 추적추적 내리 네요 .\n",
      "\n",
      "Q: 오늘 밤 은 빌 비 가 내립니다 \n",
      "A: 그러게요 . 비가 추적추적 내리네요 .\n",
      "\n",
      "Q: 짝녀가 좋아하는 사람이 있답니다 . \n",
      "A: 그것 참 안됐군요 .\n",
      "\n",
      "Q: 짝녀가 좋아하는 사람이 있답니다 . \n",
      "A: 그것 참 안 됐 군요 .\n",
      "\n",
      "Q: 쌍 짝 녀 가 좋 아 하 는 사람 이 있 답니다 . \n",
      "A: 그것 참 안됐군요 .\n",
      "\n",
      "Q: 이러다 병걸리겠어 \n",
      "A: 아프면 안 돼요 . 그럼 제 마음이 아파요 .\n",
      "\n",
      "Q: 이러다 병걸리겠어 \n",
      "A: 아프 면 안 돼요 . 그럼 제 괴로움 마음 이 아파요 .\n",
      "\n",
      "Q: 이러다 중풍 병 걸리 겠 어 \n",
      "A: 아프면 안 돼요 . 그럼 제 마음이 아파요 .\n",
      "\n",
      "Q: 데이트중에 정적 있어도 괜찮을까 ? \n",
      "A: 정적이 있을 때 아무렇지도 않으면 편안해진 거예요 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Insertion 증강 데이터 생성\n",
    "augmented_data_random_insertion = augment_corpus_with_random_insertion(\n",
    "    train_que, train_ans, ko_model.wv, num_insertions=1\n",
    ")\n",
    "\n",
    "for que, ans in augmented_data_random_insertion[:10]:\n",
    "    print(f\"Q: {que} \\nA: {ans}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42133563",
   "metadata": {},
   "source": [
    "### 데이터 셋 sequence가 짧은 관계로 Random Deletion은 진행 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ea0fcd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강 데이터셋 merge\n",
    "# augmented_data_random_swap \n",
    "augmented_data = augmented_data_lexical + augmented_data_random_insertion\n",
    "\n",
    "# 중복 제거 \n",
    "augmented_data = list(set(augmented_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "1f664df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34024"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ac373744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('한 번 은 던 볼 월과 이 없 을 것 똑같 았 는데 .', '살면서 볼 수도 있겠죠 .'),\n",
       " ('맘이 아푸네', '아프지마요 .'),\n",
       " ('이별을 준비하고 있습니다 .', '어렵 지 않 을 의결 이 었 을 텐데 .')]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f6a570ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 22243\n",
      "enc_train.shape: (34024, 42)\n",
      "dec_train.shape: (34024, 42)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ans_corpus에 <start>와 <end> 토큰 추가\n",
    "augmented_data_with_tokens = [\n",
    "    (que, f\"<start> {ans} <end>\") for que, ans in augmented_data\n",
    "]\n",
    "\n",
    "# que_corpus와 ans_corpus 분리\n",
    "train_que = [data[0] for data in augmented_data_with_tokens]\n",
    "train_ans = [data[1] for data in augmented_data_with_tokens]\n",
    "\n",
    "# 단어 사전 생성 (Tokenizer)\n",
    "tokenizer = Tokenizer(filters='', oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(train_que + train_ans)\n",
    "\n",
    "# 텍스트 벡터화 \n",
    "que_sequences = tokenizer.texts_to_sequences(train_que)\n",
    "ans_sequences = tokenizer.texts_to_sequences(train_ans)\n",
    "\n",
    "# 패딩\n",
    "# max_len_que = max(len(seq) for seq in que_sequences)\n",
    "# max_len_ans = max(len(seq) for seq in ans_sequences)\n",
    "# 계산결과 최대가 42임. 데이터 size가 작은 관계로 que-ans 통일 \n",
    "MAX_LEN = 42\n",
    "\n",
    "# 인코더 - 디코더 분리\n",
    "enc_train = pad_sequences(que_sequences, maxlen=MAX_LEN, padding=\"post\")\n",
    "dec_train = pad_sequences(ans_sequences, maxlen=MAX_LEN, padding=\"post\")\n",
    "\n",
    "# vocab size\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1  # 패딩 토큰\n",
    "\n",
    "print(f\"vocab_size: {VOCAB_SIZE}\")\n",
    "print(f\"enc_train.shape: {enc_train.shape}\")\n",
    "print(f\"dec_train.shape: {dec_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "46bab375",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "73498419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_batch.shape: (64, 42)\n",
      "dec_batch.shape: (64, 42)\n"
     ]
    }
   ],
   "source": [
    "# 데이터로더 차원 확인\n",
    "for enc_batch, dec_batch in train_dataset.take(1):\n",
    "    print(f\"enc_batch.shape: {enc_batch.shape}\") \n",
    "    print(f\"dec_batch.shape: {dec_batch.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2752d",
   "metadata": {},
   "source": [
    "### 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8294be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f2459d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2432c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = tf.shape(x)[0]  # 배치 크기\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = tf.shape(x)[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c956c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a72ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89370ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d074ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1135ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6450ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        # 인코더 디코더 임베딩 공유\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "        # 디코더 출력 FC 임베딩 공유\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b88e1467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_mask.shape: (64, 1, 1, 42)\n",
      "dec_enc_mask.shape: (64, 1, 1, 42)\n",
      "dec_mask.shape: (64, 1, 42, 42)\n"
     ]
    }
   ],
   "source": [
    "# 마스크 차원 확인\n",
    "enc_mask, dec_enc_mask, dec_mask = generate_masks(enc_batch, dec_batch)\n",
    "print(f\"enc_mask.shape: {enc_mask.shape}\")\n",
    "print(f\"dec_enc_mask.shape: {dec_enc_mask.shape}\")\n",
    "print(f\"dec_mask.shape: {dec_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "09a86922",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers=6,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=VOCAB_SIZE,\n",
    "    tgt_vocab_size=VOCAB_SIZE,\n",
    "    pos_len=200,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e5952a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_input (InputLayer)          [(None, 42)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_enc_mask (InputLayer)       [(None, 1, 1, 42)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (InputLayer)          [(None, 42)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_mask (InputLayer)           [(None, 1, 42, 42)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_mask (InputLayer)           [(None, 1, 1, 42)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_10 (Transformer)    ((None, 42, 22243),  66937571    enc_input[0][0]                  \n",
      "                                                                 dec_enc_mask[0][0]               \n",
      "                                                                 dec_input[0][0]                  \n",
      "                                                                 dec_mask[0][0]                   \n",
      "                                                                 enc_mask[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 66,937,571\n",
      "Trainable params: 66,937,571\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Functional API\n",
    "enc_input = tf.keras.Input(shape=(42,), dtype=tf.int32, name=\"enc_input\")\n",
    "dec_input = tf.keras.Input(shape=(42,), dtype=tf.int32, name=\"dec_input\")\n",
    "enc_mask = tf.keras.Input(shape=(1, 1, 42), dtype=tf.float32, name=\"enc_mask\")\n",
    "dec_enc_mask = tf.keras.Input(shape=(1, 1, 42), dtype=tf.float32, name=\"dec_enc_mask\")\n",
    "dec_mask = tf.keras.Input(shape=(1, 42, 42), dtype=tf.float32, name=\"dec_mask\")\n",
    "\n",
    "# Transformer 담기\n",
    "logits, enc_attns, dec_attns, dec_enc_attns = transformer(\n",
    "    enc_in=enc_input,\n",
    "    dec_in=dec_input,\n",
    "    enc_mask=enc_mask,\n",
    "    dec_enc_mask=dec_enc_mask,\n",
    "    dec_mask=dec_mask\n",
    ")\n",
    "\n",
    "# 모델 생성\n",
    "transformer_model = tf.keras.Model(\n",
    "    inputs=[enc_input, dec_input, enc_mask, dec_enc_mask, dec_mask],\n",
    "    outputs=logits,\n",
    "    name=\"Transformer\"\n",
    ")\n",
    "\n",
    "# 모델 summary\n",
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5d4992d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9d2ab0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3f36798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ffc97d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73aa94b798c4761a6be6efe3d8235df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 6.1610\n",
      "Starting epoch 2/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f90424ffd14b9a97dc4ee3f00fbd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 4.1900\n",
      "Starting epoch 3/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2c59281d14434d9ef0a27fec9abf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 2.7629\n",
      "Starting epoch 4/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b6df03e2044e5a8554dbb99f4a477e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 1.9385\n",
      "Starting epoch 5/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef154acc48e4984817125e2914c8331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 1.6364\n",
      "Starting epoch 6/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa9f6db587e4ba0848e2849d539328e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 1.4717\n",
      "Starting epoch 7/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dc9cbfc8824f688812c6ac03a49121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 1.3742\n",
      "Starting epoch 8/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df782df0033438dac07e11e685e74b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 1.3048\n",
      "Starting epoch 9/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fcf177fd054116ae57055e635a06af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 1.1275\n",
      "Starting epoch 10/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98797f2285d4d45802aa34261705dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.9470\n",
      "Starting epoch 11/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e201f7c16a594d30b8acebc0ad13111b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 0.8072\n",
      "Starting epoch 12/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8340e3aa1cc4f4a87f44e7f60067c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 0.7002\n",
      "Starting epoch 13/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1eaf6b8524e4480947ec5a57401616b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 0.6224\n",
      "Starting epoch 14/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b56b2a66e244ecaf0d35999849a974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 0.5525\n",
      "Starting epoch 15/15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5316d5b64a5d4a59af8969e0a0dda45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 0.4902\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실 기록을 위한 리스트\n",
    "train_losses = []\n",
    "\n",
    "# 학습 시작\n",
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Starting epoch {epoch + 1}/{EPOCHS}...\")\n",
    "    total_loss = 0  # 손실 초기화\n",
    "\n",
    "    # 데이터셋 count\n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count)  \n",
    "    # batch 당 손실 계산 & 업데이트\n",
    "    for batch, (src, tgt) in enumerate(train_dataset):\n",
    "\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = train_step(src, tgt, transformer, optimizer)\n",
    "        total_loss += batch_loss  \n",
    "\n",
    "        tqdm_bar.set_description(f\"Epoch {epoch + 1}/{EPOCHS}\")  \n",
    "        tqdm_bar.set_postfix(loss=batch_loss.numpy())  \n",
    "        tqdm_bar.update(1)  \n",
    "\n",
    "    tqdm_bar.close()  \n",
    "\n",
    "    # meal Loss\n",
    "    epoch_loss = total_loss / dataset_count\n",
    "    train_losses.append(epoch_loss)  \n",
    "    print(f\"Epoch {epoch + 1} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "plt.plot(range(1, EPOCHS + 1), train_losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f95fe16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['동호회 나가기 귀찮아',\n",
       "  '쉬고 싶은데 회식 가야돼',\n",
       "  '후아 힘드네',\n",
       "  '무릎 안 좋으면 스쿼트 하면 안되겠지 ?',\n",
       "  '차단당했네',\n",
       "  '보기만해도 짜증이 나지',\n",
       "  '허허 맴찢 .',\n",
       "  '이별의 아픔이 있는데 몸까지 아파서야',\n",
       "  '완전히 정리했어',\n",
       "  '배에서 꾸룩꾸룩 소리 남',\n",
       "  '좋아하는 감정이 뭐예요 ?',\n",
       "  '사표 낼까 ?',\n",
       "  '일 하면서 알게 된 사람한테 연락해도 될까 ?',\n",
       "  '짝남에게 밤에 자주 산책하자고 해도될까 ?',\n",
       "  '살만해 ?',\n",
       "  '대학 가고 싶다 .',\n",
       "  '또 전화 안받아',\n",
       "  '이런 일상에서 휙 떠나고 싶어',\n",
       "  '맥주 마셔야지',\n",
       "  '환승이였다는걸 알고서 .',\n",
       "  '나 윗집 남자애 좋아하는 것 같애 .',\n",
       "  '너한테 이글안보여줄거다 .',\n",
       "  '다른 사람들에 비해 만남은 짧앗지만',\n",
       "  '마음만은 청춘이야',\n",
       "  '사랑은 영원해 ?',\n",
       "  '이별 너무 힘드네',\n",
       "  '역류성 식도염 온 거 같아 .',\n",
       "  '붙잡으려고',\n",
       "  '아닌건 아니다',\n",
       "  '사랑이 뭐가 대수라고',\n",
       "  '삼겹살 냄새',\n",
       "  '짝남이 자꾸 꿈에 나오는데 꿈에서도 용기 없어서 피하고 그래 .',\n",
       "  '결혼을 앞두고 있습니다',\n",
       "  '사랑하는 사람이 있어',\n",
       "  '내가 그사람한테 필요했으면 좋겠어',\n",
       "  '울면서 카톡 보냈어 너무 힘들어서',\n",
       "  '수업시간 내내 잤어',\n",
       "  '숨막히는건 없어졌네',\n",
       "  '두달이 되가네 .',\n",
       "  '오늘도 어김없이 너무생각나네',\n",
       "  '남자친구가 나한테 너무 집착해',\n",
       "  '파혼한거 정말 잘했다',\n",
       "  '하품 나와',\n",
       "  '반년만에 연락해봤네',\n",
       "  '그 사람이 나 안 좋아하는 거 같아',\n",
       "  '군대 언제 끝나나',\n",
       "  '억울한 현실',\n",
       "  '남자친구가 너무 좋아',\n",
       "  '아주 잊기로 독하게 마음 먹고 신나게 놀고 있습니다',\n",
       "  'sd카드 망가졌어',\n",
       "  '오늘부터 내려놓기로 했습니다 .',\n",
       "  '참 힘드네',\n",
       "  '오늘 왤케 추워',\n",
       "  '그 사람도 그럴까 ? ?',\n",
       "  '조모임 왜 이케 많아',\n",
       "  '죽을 것 같아',\n",
       "  '세상에 영원한 것은 없다 .',\n",
       "  '뱃살 빵빵',\n",
       "  '권태기라고 이별을 통보하는 사람',\n",
       "  '2년동안 나 사랑해줘서 고맙다',\n",
       "  '남자친구가 술자리를 너무 좋아해 .',\n",
       "  '너무 상처를받아서',\n",
       "  '죽음을 뛰어넘는 사람',\n",
       "  '오늘은 학교 가고 싶지 않아',\n",
       "  '결혼식 날짜 잡았대',\n",
       "  '언젠가 나아지겠죠 ?',\n",
       "  '내가 친절하니까 쉬워보이나 ?',\n",
       "  '오늘따라 더 힘드네',\n",
       "  '엄마 힘들게 했어',\n",
       "  '외롭고 우울해서 잠이쏟아져',\n",
       "  '놓치고 싶지 않는 사람',\n",
       "  '잊고싶어도 잊질못하네',\n",
       "  '물 끓여서 차 마셔야지',\n",
       "  '제 아주 오래전 이별',\n",
       "  '너와 내가 인연이었으면 좋겠어',\n",
       "  '일하는 곳 근처 가서 염탐하고 왔네 .',\n",
       "  '첫사랑 생각만해도 아련해',\n",
       "  '너도 상사 있어',\n",
       "  '여자친구랑 종교 때문에 다툼',\n",
       "  '제가 그녀를 놓아줬어 .',\n",
       "  '상대와 헤어지고 돌아오는길',\n",
       "  '연애 갱년긴가',\n",
       "  '단수',\n",
       "  '이별 후 다른 이성 소개팅 후 후폭풍',\n",
       "  '바람쐬러 정동진가',\n",
       "  '헤어진지 벌써 두달이 다되가지만 .',\n",
       "  '몸이 아프니까',\n",
       "  '사랑이 밥 먹여주나요 ?',\n",
       "  '썸남이 너무 진지해서 부담 돼 .',\n",
       "  '더 사랑하고 싶다',\n",
       "  '밤보다 자고 일어났을 때 더 힘들어',\n",
       "  '자기 쓰레기 맞다고 잊고 살아가래',\n",
       "  '자꾸 폭식하는데 어떻게 고칠 수 있을까 ?',\n",
       "  '여사친이랑 사귀는 거 가능 ?',\n",
       "  '사람이 변하나 ?',\n",
       "  '오늘나 어제이나 똑같아',\n",
       "  '이별6일차 . 정신병자 같네 .',\n",
       "  '이별에도 준비가 필요한 거겠죠 ?',\n",
       "  '이제 한 삼주 되었나 ?',\n",
       "  '헤어지고 나서 많은 일들이 있었네 .',\n",
       "  '영어학원 다녀볼까',\n",
       "  '썸인 거 같은데 연락 안 하면',\n",
       "  '밤새 그리워서 편지 썼어',\n",
       "  '잊을수 없는 너 .',\n",
       "  '슬퍼 , 그리고 아려',\n",
       "  '많이슬퍼하고 그리워해야',\n",
       "  '혼자 노력하는 연애인 거 같아',\n",
       "  '게임에서 만난 사람 좋아하게 되었는데 괜찮을까요 ?',\n",
       "  '차 사야 할 거 같은데',\n",
       "  '점심 메뉴 고르는 거 힘드네',\n",
       "  '여자친구가 살이 너무 쪄서 고민임 .',\n",
       "  '나 아재인가',\n",
       "  '수영 막 잘하고 싶다 .',\n",
       "  '술 한잔 했더니 너무 보고 싶네 .',\n",
       "  '애들 총회 가야겠죠 ?',\n",
       "  '결혼하는데 돈이 엄청 드네',\n",
       "  '희망이 안보여',\n",
       "  '사랑에도 유효기간이 있다는데',\n",
       "  '마음을 억지로 접는게 어렵네',\n",
       "  '잊혀질까 ?',\n",
       "  '물 많이 마시라고 했는데',\n",
       "  '이별후 6개월',\n",
       "  '쳇바퀴 도는 하루',\n",
       "  '대외활동하다 만났어',\n",
       "  '성공할 수 있을까 ?',\n",
       "  '썸 타는 사람이 나오는 야한 꿈 꿨어 .',\n",
       "  '다시 한번 붙잡아도 안되네',\n",
       "  '혼술 중',\n",
       "  '드디어 처음으로 꿈에 나욌습니다 .',\n",
       "  '좋아하는 남자애 앞에서 표정 관리가 안돼 .',\n",
       "  '시간이 너무 빨리 가',\n",
       "  '여자는 호감 없어도 잘해줘 ?',\n",
       "  '이런사람을만나고싶네',\n",
       "  '서로 나쁘게 헤어지지 않고 싶은데',\n",
       "  '정은 많지만 설렘이 없다는 이유로 헤어졌습니다 .',\n",
       "  '첫눈 오는날 만나고 싶다',\n",
       "  '아휴 싱숭생숭한 하루',\n",
       "  '썸인지 쌈인지',\n",
       "  '3년 사겼는데 이제 결혼해야겠지 ?',\n",
       "  '잠이 계속 와',\n",
       "  '친구랑 술 한잔 기울이고 들어왔습니다 .',\n",
       "  '싸게 팔길래 샀어',\n",
       "  '남자친구가 욕함',\n",
       "  '신청했더니 정말로 왔네ㅎㅎ',\n",
       "  '여자친구 마중 나가야지',\n",
       "  '내 스타일 아니던데',\n",
       "  '혼영해야지',\n",
       "  '요리 재밌어',\n",
       "  '섬유유연제 향 좋다',\n",
       "  '아침에 벌떡 일어났네 .',\n",
       "  '썸 타는데 어디 가자고 할까 ?',\n",
       "  '이렇게 진짜 끝인걸까 .',\n",
       "  '썸녀랑 어떤 대화를 해야 해 ?',\n",
       "  '습관이 무서워 .',\n",
       "  '대출받아도 괜찮을까',\n",
       "  '덕질 중',\n",
       "  '꼬시는 방법',\n",
       "  '전 여자친구의 새 남자친구 .',\n",
       "  '이런 사랑도 있나',\n",
       "  '불륜이 될까봐 정리하려고 .',\n",
       "  '우산빌려달라고 해볼까 ?',\n",
       "  '가슴에 구멍이 너무 커 .',\n",
       "  '사랑하기에 시간이 부족해',\n",
       "  '짝남 나한테 마음 있는지 궁금해 .',\n",
       "  '혹시나 , 역시나',\n",
       "  '입장이 바뀐 상태에서 오랜만에 와보내',\n",
       "  '첫이별 너무힘드네',\n",
       "  '술병이네',\n",
       "  '짝남한테 괜히 만나자고 했나봐 .',\n",
       "  '키 작은 여자 좋아하는 남자 있나요 ?',\n",
       "  '좋아했던 기억 영원히 없앨 수는 없을까 .',\n",
       "  '저 잘 잊을 수 있겠죠 ?',\n",
       "  '상처 안 받고 싶다',\n",
       "  '단발 어울릴까 ?',\n",
       "  '이별이 있어야 인연도 있는거 같아 .',\n",
       "  '결국 완전 끝낫네 .',\n",
       "  '알뜰폰 괜찮을까',\n",
       "  '다음주에 전 여자친구를 보기로 했어',\n",
       "  '드론 자격증 딸까 ?',\n",
       "  '이별이 힘든 이유는 .',\n",
       "  '인형 뽑기 해줘',\n",
       "  '친한 친구의 구여친이랑 사귀어도 되나 .',\n",
       "  '몸살 나서 힘들어',\n",
       "  '돈 잃어버렸어',\n",
       "  '남자친구가 나를 떠날까봐 고민이야 .',\n",
       "  '나 축구는 진짜 잘해',\n",
       "  '좋아하는 여자한테 연락 하지 말자고 했는데 후회해 .',\n",
       "  '이거 뭘까 . 좋아하는 걸까 ?',\n",
       "  '내려놓을 준비 합니다',\n",
       "  '그냥 택시 타야지 .',\n",
       "  '대학 가면 좋겠지',\n",
       "  '너도 몰랐니',\n",
       "  '머리는 아는데 가슴은 모르네',\n",
       "  '재수학원에서 연애는 필망 ?',\n",
       "  '오늘도잠을못이루네',\n",
       "  '결혼하고 나서 애 낳기 싫어졌어',\n",
       "  '조금씩 아물어가는건가 이별의 상처',\n",
       "  '재밌는거 없나 ?',\n",
       "  '한달만에 . 제가',\n",
       "  '인생 포기한 걸까',\n",
       "  '제가 좋아하던 사람이 절 좋아하면 갑자기 거부감 들고 싫어져요 .',\n",
       "  '내가 만난 최악의 여자',\n",
       "  '그 사람이 나를 좋아하는 줄 알았는데 .',\n",
       "  '너무 추워서 시베리아 같아',\n",
       "  '질투가 너무 심한데 질투를 어떻게 줄일까 .',\n",
       "  '스스로에게 너무 인색했네',\n",
       "  '4년을 만난 여친이 떠났습니다 .',\n",
       "  '명품 선물 부담스러울까',\n",
       "  '이별후에',\n",
       "  '그녀도 내 생각을 할까 ?',\n",
       "  '망상이제일짜증나고 미치네 .',\n",
       "  '결혼날짜 받아왔어',\n",
       "  '점 보러 가볼까 ?',\n",
       "  '좋은 이별을 하려면 어떻게 해야 할까 ? ?',\n",
       "  '이별의 이유는 정말 다양하내',\n",
       "  '그 사람 때문에 하루에도 몇 번씩 기분이 오르락 내리락 해 .',\n",
       "  '썸남이 데리러 온다고 하는데 뭐라고 반응해 ?',\n",
       "  '시간표 개판',\n",
       "  '전부 다 줘도 아깝지 않은 사람',\n",
       "  '여러명 좋아하면 안돼 ?',\n",
       "  '헤어지자',\n",
       "  '머리가 지끈거려',\n",
       "  '썸에서 연인될 수 있을까',\n",
       "  '썸 타는 사람이 내 프사 보고 귀엽대 .',\n",
       "  '왕따된 거 같아',\n",
       "  '음악 들으면서 잊으려고',\n",
       "  '서로 사랑해',\n",
       "  '나 뚱뚱한데 좋아하는 남자에게 연락해도 될까 ?',\n",
       "  '구짝남한테 카톡했는데 읽씹해서 미련 없이 차단했어요 .',\n",
       "  '1지망 학교 떨어졌어',\n",
       "  '연락하는 게 어색해',\n",
       "  '따끔하게 혼내 줘',\n",
       "  '못된 사람',\n",
       "  '연락은 괜히 해서',\n",
       "  '재회를 바라는것도 새로운 사랑을 원하는것도 아닌데 .',\n",
       "  '너무 불공평한거 같애',\n",
       "  '친구한테 쌓인 게 안 풀려',\n",
       "  '1년이 지났어도',\n",
       "  '이별 후 그사람과 마주치는 거',\n",
       "  '봄방학이다 !',\n",
       "  '마무리',\n",
       "  '어떤 사람이랑 사랑하고 싶어 ?',\n",
       "  '밤 샜어',\n",
       "  '찬남자한테 연락 왔어',\n",
       "  '이별 후 들으면 더 힘든 노래들',\n",
       "  '말할 때 너무 떨려',\n",
       "  '답답한 마음',\n",
       "  '이별은 냉정할수록 좋은 것 같아',\n",
       "  '사랑의 묘약 같은 거 있나 ?',\n",
       "  '반지 많이 비쌀까',\n",
       "  '음식 편식하는 사람 사겨도 돼 ?',\n",
       "  '뭐 입지 ?',\n",
       "  '아 오늘 힘드네',\n",
       "  '연락왔는데 , 진짜 미칠거같네',\n",
       "  '헤어진지 3주째 입니다 .',\n",
       "  '퇴근길에 훅 ! 하고 연락오네 .',\n",
       "  '썸인데 연락이 너무 늦어',\n",
       "  '헤어짐 통보 당한지 1달 정도 지났네',\n",
       "  '개강이다',\n",
       "  '사랑받고싶어',\n",
       "  '앞으로 짝남 안봐야지 .',\n",
       "  '아파',\n",
       "  '짝사랑은 안 이뤄지나봐 .',\n",
       "  '여자친구랑 헤어졌네',\n",
       "  '체육복 또 까먹었어',\n",
       "  '여자친구 붙잡느라고 모든걸 쏟아붓고 있습니다',\n",
       "  '참 부질없다',\n",
       "  '헤어진지 열흘 됐는데 연락하고 싶네',\n",
       "  '아 잠수라니',\n",
       "  '여름인데 태닝할까',\n",
       "  '내 몸이 여러 개 였으면 좋겠다',\n",
       "  '좋아하는 그사람은 바람둥이야 좋아해도 될까 ?',\n",
       "  '다리 떠는거 말들음',\n",
       "  '이게 잠수이별인가 ? ? ?',\n",
       "  '남자친구가 너무 국밥류만 좋아해 .',\n",
       "  '여자친구가 너무 어린거 같아 .',\n",
       "  '꿈에 나온 여자를 어떻게 찾을 수 있을까 ?',\n",
       "  '첫여친이라 잘 안잊혀지네',\n",
       "  '그쪽은 너무 편안하고 즐겁게 지내 .',\n",
       "  '나쁜 꿈 꿨어',\n",
       "  '정말 왜 이러는걸까',\n",
       "  '결국 헤어지자고 했어 .',\n",
       "  '설레고 싶은데 아직 좋아하는 사람이 없어 .',\n",
       "  '남자친구 또 운동 갔어',\n",
       "  '말수 적은 남자인데 썸타도 괜찮을까 ?',\n",
       "  '사랑이 뭐야 ?',\n",
       "  '썸 탈 때 무슨 말하지',\n",
       "  '집착 ? 미련 ? 사랑 ?',\n",
       "  '이유라는게 뭔지',\n",
       "  '자꾸 미리 걱정해',\n",
       "  '어제 헤어졌어',\n",
       "  '너무 보고싶네 .',\n",
       "  '뜬금 시간을 가지자고 해서',\n",
       "  '좋아하는 사람한테 도와달라고 해볼까 ?',\n",
       "  '평일 저녁 데이트 장소 좀 추천해줘',\n",
       "  '의욕도 업고 너무 힘들어',\n",
       "  '내가미쳤지',\n",
       "  '주말이 제일 힘드네',\n",
       "  '남긴게 없이 줬다고 믿어 .',\n",
       "  '좋아하는 사람 언제까지 기다릴 수 있을까요 .',\n",
       "  '연예인 되고 싶어',\n",
       "  '보고싶어서 미치겠는데',\n",
       "  '나는 좋아하는 게 뭘까',\n",
       "  '친구인데 고백해도 될까 ?',\n",
       "  '내일 모의고사 본다',\n",
       "  '오늘 카톡방 나왔어 슬슬 정리하나봐',\n",
       "  '돈 모으고 싶어',\n",
       "  '비밀 지켜줄까 ?',\n",
       "  '이젠 보내줄게 .',\n",
       "  '여자친구에게 해줄만한 화장품 선물 뭐가 있을까 ?',\n",
       "  '모르는 걸까 ? 모르는 철 하는 걸까 ?',\n",
       "  '후배가 나보다 잘해서 속상해',\n",
       "  '사람들이 날 너무 힘들게 한다 .',\n",
       "  '대체 뭘해야 머릿속에서 지울수 있을까 ?',\n",
       "  '만남과 이별',\n",
       "  '데이트할 시간이 없네',\n",
       "  '노래 잘 부르는 사람 부러워',\n",
       "  '마음이 어려워서 들어왔어',\n",
       "  '남친이 나보다 눈물이 더 많아',\n",
       "  '내가 좋아하는 사람이 다른 사람을 짝사랑 해 . 도와줘야 할까 .',\n",
       "  '생일축하했다 바보야',\n",
       "  '누군가를 좋아해본 적이 없는데 문제가 있는걸까 ?',\n",
       "  '여친이 나를 좋아하는게 맞는지 모르겠음 .',\n",
       "  '여자친구가 감정없이 카톡 답장해',\n",
       "  '매주 월요일 그를 볼 수 있어 .',\n",
       "  '헤어진지 3주 . 오늘 그 친구 생일',\n",
       "  '교양수업 은근 재미져',\n",
       "  '서로가 원치 않았던 이별',\n",
       "  '이별을 받아들여야 하는데 생각이 자꾸 나네',\n",
       "  '다육이 키워보까',\n",
       "  '차단 반복하는 이남자 뭔가',\n",
       "  '그림 잘 그리고 싶다',\n",
       "  '일이랑 공부 병행 가능 ?',\n",
       "  '편의점 간식 먹어야지',\n",
       "  '불면증인가',\n",
       "  '살며시 다가왔어',\n",
       "  '슬퍼 .',\n",
       "  '한 사람만 죽을 때까지 사랑하는 게 가능할까 ?',\n",
       "  '결혼 생각 없었는데 결혼하고 싶어진 이유 ?',\n",
       "  '사랑하면서 외로워',\n",
       "  '썸에도 유통기한이 있어 ?',\n",
       "  '뭐하면서 노는 게 좋을까',\n",
       "  '예쁘니까 좋아하나',\n",
       "  '사귀면 끝일 줄 알았는데',\n",
       "  '결혼해도 될까 ?',\n",
       "  '수염 기를까',\n",
       "  '착한남자 . 너무 쿨하지못한남자 매력없어 .',\n",
       "  '안주 뭐 먹을까 ?',\n",
       "  '게스트하우스에서 만난 짝녀와 남은 일정을 같이 여행하고싶어 .',\n",
       "  '이별 후 젤 힘들 건 허전함인 거 같아',\n",
       "  '사회에서도 좋은 사람 만날 수 있어 ?',\n",
       "  '좋아하면서도 너무 싫은 감정 뭘까요 .',\n",
       "  '남편이 날 진심으로 사랑하는 걸까 ?',\n",
       "  '쿠폰 다 모았다 .',\n",
       "  '근사한 곳 알아 냈어',\n",
       "  '한쪽이 마음 떠나고 마음 돌리는 방법',\n",
       "  '같이 게임하자고 해도 되나 ?',\n",
       "  '끝나니까 허무하다',\n",
       "  '사랑하는사람',\n",
       "  '그녀의 남자사진을 봤습니다',\n",
       "  '남자친구 오지랖 너무 많아',\n",
       "  '썸남인줄 알았는데 짝남이었나봐 .',\n",
       "  '넌 충분히 좋은 사람이였어',\n",
       "  '이별은 왤케 힘드나',\n",
       "  '니가 이 글을 봤으면',\n",
       "  '오늘 따라 그 친구가 좀 보고싶네',\n",
       "  '야구 경기 보러 꼭 함께 가자던 그 남자',\n",
       "  '스킨십 좋아하는 남자친구 어떡해 ?',\n",
       "  '내 이기심과 욕심이 그녀를 떠나게 한거 같아',\n",
       "  '회사 체육대회 가기 싫다',\n",
       "  '누군가를 좋아한다는건 정말 힘들일이야 .',\n",
       "  '4년 반이라는 시간이 이렇게 끝나네 .',\n",
       "  '새로운 마음으로',\n",
       "  '퇴근했어 근데',\n",
       "  '내가 썸 깼는데 다시 연락하고 싶어 .',\n",
       "  '여친 쌩얼보고 깜놀했어',\n",
       "  '황사 심해',\n",
       "  '남잔데 남자 좋아해',\n",
       "  '날 좋아하는 여자애가 .',\n",
       "  '선배가 선배같지 않아',\n",
       "  '짝사랑 하는 남자 때문에 하루에도 몇 번 기분이 달라져 .',\n",
       "  '내가 좋아하는 거 알았는데도 나를 대하는게 변함이 없어 .',\n",
       "  '놀이동산 가자고 해볼까 ?',\n",
       "  '나한테 너무 잘해줘서 이래도 되나 싶어',\n",
       "  '추석연휴가 그렇게 좋지만은 않다 .',\n",
       "  '1년 만났는데도 그 사람에 대해 잘 모르겠어',\n",
       "  '지나가는 말로 이쁘다한 것을 다 기억해 두는게 좋은가요 ?'],\n",
       " ['오늘은 쉬세요 .',\n",
       "  '일과 일상 사이에서 균형이 잘 맞길 바랄게요 .',\n",
       "  '힘내라는 진부한 말 건네봅니다 .',\n",
       "  '무릎에 무리가 갈 거예요 .',\n",
       "  '잊는 데는 더 도움이 될지도 몰라요 .',\n",
       "  '짜증날 때는 기분 푸는 음악 어때요 ?',\n",
       "  '제 맘도 맴찢 .',\n",
       "  '꼭 병원 다녀와요 . 힘들 때 아픈 것 만큼 서러운 일은 없어요 .',\n",
       "  '조금 후련해졌길 바랍니다 .',\n",
       "  '꼬르륵',\n",
       "  '가만히 있어도 생각나는 거 아닐까요 .',\n",
       "  '뒷감당은 준비하세요 .',\n",
       "  '일 핑계로 연락해봐요 .',\n",
       "  '밤 데이트 신청 멋지네요 .',\n",
       "  '누구나 한번쯤 시도해 볼 만하죠 .',\n",
       "  '할 수 있을거예요 ! !',\n",
       "  '조금 기다리면 풀릴 거예요',\n",
       "  '여행을 떠나세요 .',\n",
       "  '적당히 드세요 .',\n",
       "  '힘드셨겠어요 .',\n",
       "  '가깝게 살아서 더 좋겠네요 .',\n",
       "  '그렇게 해요 .',\n",
       "  '깊은 사이였나요 .',\n",
       "  '마음이라도 청춘이어야죠 .',\n",
       "  '사랑은 한 순간이면서 영원한거 같아요 .',\n",
       "  '이별의 상처를 잘 아물지 않나봐요 .',\n",
       "  '과식하지 말고 먹고 눕지 마세요 !',\n",
       "  '많이 노렸했군요 .',\n",
       "  '아닌건 아니죠 .',\n",
       "  '사랑은 살아가면서 정말 중요한 감정이예요 .',\n",
       "  '섬유탈취제 뿌려보세요 .',\n",
       "  '은연 중에 지금의 심리 상태가 반영되었나봐요 .',\n",
       "  '좋으면서 복잡하겠어요 .',\n",
       "  '어서 어서 고백해봐요 .',\n",
       "  '사적 영역에 깊숙이 들어가보세요 .',\n",
       "  '스스로 많이 다독여주세요 .',\n",
       "  '한창 잠이 많을 때죠 .',\n",
       "  '숨 쉴 수 있어 다행이네요 .',\n",
       "  '생각보다 정신없이 지나가네요 .',\n",
       "  '언젠가 떠날 보낼 날이 올거예요 .',\n",
       "  '믿음을 주세요 .',\n",
       "  '쉽지 않은 결정이었겠지만 잘 하셨어요 .',\n",
       "  '졸린가봐요 .',\n",
       "  '그리웠나봐요 .',\n",
       "  '슬픈 이야기네요 .',\n",
       "  '군대 시계는 멈추지 않아요 .',\n",
       "  '현실은 항상 괴롭게 하는 존재에요 .',\n",
       "  '꿀 떨어지는 소리가 여기까지 들리내요 .',\n",
       "  '바쁜 게 도움이 되지요 .',\n",
       "  '다시 새로 사는 게 마음 편해요 .',\n",
       "  '잘 생각하셨어요 . 처음엔 힘들지만 곧 괜찮아질거라 믿어요 .',\n",
       "  '힘들만해요 .',\n",
       "  '오늘 강추위래요 .',\n",
       "  '그럴 거예요 .',\n",
       "  '요즘은 팀워크가 더 중요해졌어요 .',\n",
       "  '자괴감에서 이제 빠져나오세요 .',\n",
       "  '제가 영원을 약속할게요 .',\n",
       "  '운동 해보세요 .',\n",
       "  '그 사람도 힘들었을 거예요 .',\n",
       "  '좋은 사랑 하셨나봐요 .',\n",
       "  '함께 즐겨보세요 .',\n",
       "  '힘들어도 하루하루 견뎌봐요 .',\n",
       "  '이보다 멋진 사랑은 없을 거예요 .',\n",
       "  '학교 다닐 때가 좋은 거예요 .',\n",
       "  '축하해주세요 .',\n",
       "  '나아질거예요 .',\n",
       "  '그런 사람 만나지 마세요 .',\n",
       "  '많이 힘들었을거라 생각해요 .',\n",
       "  '조금씩 보다 나은 모습을 보여드리세요 .',\n",
       "  '부담갖지 말고 자는 것도 좋아요 .',\n",
       "  '운명인가봐요 .',\n",
       "  '함께한 시간이 있었으니까요 .',\n",
       "  '부지런하시네요 .',\n",
       "  '아직도 생각이 나나봐요 .',\n",
       "  '인연은 만들어 가는거예요 .',\n",
       "  '그분에 대한 궁금증을 접어두셔요 .',\n",
       "  '그런 감정이 살아가는 원동력이 되는거 같아요 .',\n",
       "  '제가 상사예요 .',\n",
       "  '종교의 자유가 있죠',\n",
       "  '잘한 선택일 거라 믿어요 .',\n",
       "  '그 길에서 자신을 만나길 바랄게요 .',\n",
       "  '저는 위기 조차 없네요 .',\n",
       "  '단수가 되었는지 문의해 보세요 .',\n",
       "  '더 생각이 나셨군요 .',\n",
       "  '잘 놀다 오세요 .',\n",
       "  '아직 그립겠지만 괜찮아 질 거예요 .',\n",
       "  '마음도 더 아프죠 !',\n",
       "  '같이 밥을 먹어주죠 .',\n",
       "  '부담된다면 조심스레 말해 보세요 .',\n",
       "  '감정에 솔직한 모습이 보기 좋아요 .',\n",
       "  '운동으로 기분전환을 하는 건 어떨까요 .',\n",
       "  '그런 사람은 빨리 잊는게 상책이에요 . 자신을 더 사랑해주세요 .',\n",
       "  '오늘 못 먹었어도 내일 먹으면 더 맛있을 거예요 .',\n",
       "  '가능합니다 .',\n",
       "  '사랑은 변하고 사람은 안 변해요 .',\n",
       "  '조금씩 변화를 줘보세요 .',\n",
       "  '나가서 좀 걷고 친구들을 만나보세요 .',\n",
       "  '그럼요 . 한 순간에 내 삶속에서 내보내기는 쉽지않을 거예요 .',\n",
       "  '잘 지내고 있길 바랍니다 .',\n",
       "  '새로운 변화가 생기길 바랍니다 .',\n",
       "  '공부 좋죠 .',\n",
       "  '밀당일 수도 있고 혼자만 썸일 수도 있겠어요 .',\n",
       "  '받으면 참 좋을 것 같아요 .',\n",
       "  '많이 사랑했던 만큼 기억이 선연하더라고요 .',\n",
       "  '상처에 약을 발라 드릴게요 .',\n",
       "  '이런 과정도 꼭 필요해요 .',\n",
       "  '힘들면 잠시 놓는것도 방법이에요 .',\n",
       "  '좀 더 알아볼 시간이 필요하겠네요 .',\n",
       "  '좋은차로 선택해보세요 .',\n",
       "  '누구랑 먹는 냐에 따라 다르겠죠 .',\n",
       "  '같이 운동해봐요 .',\n",
       "  '고민하고 있으면 그럴 거예요 .',\n",
       "  '강습 받아보세요 .',\n",
       "  '술 기운이 그렇죠 .',\n",
       "  '가능하면 가는 게 좋겠죠 .',\n",
       "  '스몰웨딩으로 준비하면 조금이라도 줄일 수 있을 거예요 .',\n",
       "  '저와의 대화한 것 자체는 희망적이에요 .',\n",
       "  '갱신해가는 재미가 있죠 .',\n",
       "  '그렇게 하다보면 어느덧 정리될지도 몰라요 .',\n",
       "  '힘들지만 언젠간 기억 저편으로 사라질 거예요 .',\n",
       "  '습관을 들여보세요 .',\n",
       "  '많은 변화가 잇었겠죠 .',\n",
       "  '그 속에서 가치와 의미를 찾아보세요 .',\n",
       "  '꿩 먹고 알 먹고네요 .',\n",
       "  '인내할 수 있는 사람이라면 무엇이든 손에 넣을 수 있을 거예요 .',\n",
       "  '어머 벌써 그런 생각을 하셨군요 .',\n",
       "  '이별의 이유가 있을 테니까요 .',\n",
       "  '캬아 맛있는 안주랑 드세요',\n",
       "  '많이 생각했나봐요 .',\n",
       "  '짝사랑도 이성을 막지는 못하나봐요 .',\n",
       "  '시간은 상대적이죠 .',\n",
       "  '본래 성격이 그럴 수도 있어요 .',\n",
       "  '저도 그런 사람 만나고 싶어요 .',\n",
       "  '헤어짐은 처음이니까 .',\n",
       "  '헤어짐에는 여러가지 이유가 있기 마련이죠 .',\n",
       "  '그런 사람이 있다니 부럽네요 .',\n",
       "  '그러게요 . 오늘 하루 마음이 복잡했나봅니다 .',\n",
       "  '연락 빈도랑 언제 연락오는지 확인해보세요 .',\n",
       "  '사귄 시간이 길다고 무조건 결혼해야하는 건 아니에요 .',\n",
       "  '일찍 주무세요 .',\n",
       "  '기분이 조금이나마 나아졌길 바랍니다 .',\n",
       "  '득템 했네요 .',\n",
       "  '순간 실수할 수 있겠다 판단되면 용서하고 기회를 주세요 .',\n",
       "  '좋은 결과길 바라요 .',\n",
       "  '여자친구가 좋아할 거예요 .',\n",
       "  '새로운 스타일 도전해 보시면 어때요 ?',\n",
       "  '편하고 좋죠 .',\n",
       "  '만들어서 먹는 기쁨이죠 .',\n",
       "  '향이 많은 걸 말해주죠 .',\n",
       "  '안 좋은 꿈이라도 꿨나봅니다 .',\n",
       "  '가고 싶은 곳이 있는지 연락해 보세요 .',\n",
       "  '인연이 거기까지인 가봐요 .',\n",
       "  '공통점 찾기가 좋겠죠 .',\n",
       "  '익숙함이 무서운 것 처럼요 .',\n",
       "  '괜찮을 거예요 .',\n",
       "  '좋아하는 게 있는 건 더없이 좋은 일이에요 .',\n",
       "  '그 사람이 좋아하는 걸 알아보세요 .',\n",
       "  '더 이상 신경쓰지 마세요 .',\n",
       "  '헤아릴 수 없는게 사랑이죠 .',\n",
       "  '불륜보다 낫죠 .',\n",
       "  '한번 말해보세요 .',\n",
       "  '아무 생각 하지 말고 푹 주무세요 .',\n",
       "  '시간은 핑계예요 .',\n",
       "  '주변 사람한테 물어보는 건 어떨까요 .',\n",
       "  '그래도 힘내세요 .',\n",
       "  '심경의 변화가 있었나요 ?',\n",
       "  '처음이라 더 힘들 거예요 .',\n",
       "  '숙취해소제가 도움이 될까요 .',\n",
       "  '그래도 후회는 덜할 거예요 .',\n",
       "  '그럼요 .',\n",
       "  '없애는 게 아니라 무덤덤해지는 걸 거예요 .',\n",
       "  '아무렇지도 않게 추억할 날이 올 거예요 .',\n",
       "  '내가 우선순위면 돼요 .',\n",
       "  '변화를 주는 것도 좋겠죠 .',\n",
       "  '이별이 새로운 시작이 되기도 하니까요 .',\n",
       "  '이제 시작이죠 .',\n",
       "  '폰 요금 절약되겠네요 .',\n",
       "  '마음이 복잡할 거 같아요 .',\n",
       "  '미래에 유명한 자격증일 거예요 .',\n",
       "  '그만큰 사랑했기 때문일 거예요 .',\n",
       "  '인형 뽑기 어려워요 .',\n",
       "  '친구라면 많이 실망할겁니다 .',\n",
       "  '아무 생각 하지 말고 쉬세요 .',\n",
       "  '이제라도 더 조심하세요 .',\n",
       "  '괜한 걱정하지 마요 .',\n",
       "  '운동 잘하는 사람 멋있죠 .',\n",
       "  '그게 최선의 선택이었을 거예요 .',\n",
       "  '직접적인 마음을 확인하기 전까지 확실한 건 없답니다 .',\n",
       "  '바로 시작하세요 .',\n",
       "  '조심히 오세요 .',\n",
       "  '행복은 마음 가짐에 있어요 .',\n",
       "  '저도 몰랐어요 .',\n",
       "  '머리랑 가슴이 가끔 따로 놀죠 .',\n",
       "  '목적이 확실한 곳이니까요 .',\n",
       "  '잠은 정말 중요한데요 .',\n",
       "  '둘이 알콩달콩 잘 살면 되죠 .',\n",
       "  '아물어간다니 다행이에요 .',\n",
       "  '잼 있는 거는 딸기잼에게 물어봐 주세요 .',\n",
       "  '잊었길 바랍니다 .',\n",
       "  '언제든 다시 시작할 수 있어요 .',\n",
       "  '어떤 트라우마가 있었는지도 모르겠어요 .',\n",
       "  '이제 최선의 여자를 만날 차례예요 .',\n",
       "  '아니어서 힘드나봐요 .',\n",
       "  '어서 따듯한 곳으로 가세요',\n",
       "  '당신이 가장 소중하고 사랑받고 있다는 걸 잊지마세요 .',\n",
       "  '좀 더 관대해져도 괜찮아요 .',\n",
       "  '한동안 받아들이기 버거울거예요 .',\n",
       "  '고가의 선물은 부담스러울 수도 있어요 .',\n",
       "  '나아지길 바랄게요 .',\n",
       "  '연락해 보는게 좋겠어요 .',\n",
       "  '망상에서 얼른 벗어나길 바랄게요 .',\n",
       "  '드디어 결혼하는 군요 !',\n",
       "  '재미로 보기 좋죠 .',\n",
       "  '좋은 이별은 없어요 .',\n",
       "  '사랑이 헤아릴 수 없어서 그렇기도 해요 .',\n",
       "  '그게 사랑의 증거가 되겠네요 .',\n",
       "  '데리러 와주면 고맙다고 반응해봐요 .',\n",
       "  '다음 학기를 노려보세요 .',\n",
       "  '정말 사랑하나봅니다 .',\n",
       "  '여러명 좋아할 수도 있죠 .',\n",
       "  '좋은 선택이길 바랄게요 .',\n",
       "  '두통약 드세요 .',\n",
       "  '썸 타다가 연인 되는 게 일반적이죠 .',\n",
       "  '칭찬은 언제든 듣기 좋죠 .',\n",
       "  '선생님께 도움을 청해보세요 .',\n",
       "  '음악이 도움이 되길 바랍니다 .',\n",
       "  '기적같은 일이네요 .',\n",
       "  '연락해도 상관없지만 자신을 비하하지는 마세요 .',\n",
       "  '그러는 편이 나을 거예요 .',\n",
       "  '위로해 드립니다 .',\n",
       "  '하다보면 익숙해질거예요 .',\n",
       "  '제발 좀 정신차리세요 .',\n",
       "  '못된 사람은 이제 잊어버려요 .',\n",
       "  '더 심란한가봐요 .',\n",
       "  '사람이 그리운 걸 수도 있어요 .',\n",
       "  '남과 비교하지 마세요 .',\n",
       "  '대화하면서 얽힌 감정들을 풀어보세요 .',\n",
       "  '잊지 못하고 있나요 .',\n",
       "  '힘드실 거예요 .',\n",
       "  '부럽네요 .',\n",
       "  '정리가 잘 되었길 바랄게요 .',\n",
       "  '먼저 고백해 보세요 .',\n",
       "  '건강에 안 좋아요 .',\n",
       "  '늦은 후회가 왔나봅니다 .',\n",
       "  '내 이야기 같아서겠죠 .',\n",
       "  '잘 보이고 싶은 마음이 커서 그런 것 같아요 .',\n",
       "  '마음이 내 마음 같지 않죠',\n",
       "  '감정적일수록 더 힘들어지기만 할 거예요 .',\n",
       "  '그런거 없어요 .',\n",
       "  '마음에 드는걸로 하세요 .',\n",
       "  '사귀면서 편식을 고쳐봐도 좋을 것 같아요 .',\n",
       "  '옷이요 .',\n",
       "  '힘든 하루였나요 .',\n",
       "  '다시 헤어진 그 때로 돌아간 느낌이죠 .',\n",
       "  '잘 견뎌내고 있는 것 같네요 .',\n",
       "  '그분이 미련이 남아있나 봐요 .',\n",
       "  '저처럼 연락 늦는 사람도 있어요 .',\n",
       "  '후폭풍이 지나갔길 바랄게요 .',\n",
       "  '곧 방학이예요 .',\n",
       "  '먼저 사랑한다고 말해보세요 .',\n",
       "  '마음 단단히 잡긴 바랄게요 .',\n",
       "  '병원에 가야죠 .',\n",
       "  '이뤄질 수도 있답니다 .',\n",
       "  '힘들었겠어요 .',\n",
       "  '다른 반 친구한테 빌려보세요 .',\n",
       "  '부디 돌아오길 바랄게요 .',\n",
       "  '부질없는 일도 있기 마련이에요 .',\n",
       "  '후회하지 않는다면 연락해보세요 .',\n",
       "  '상대방에 대한 예의가 없네요 .',\n",
       "  '구릿빛 피부 좋죠 !',\n",
       "  '그러면 못할 게 없겠네요 .',\n",
       "  '상처받을 거예요 .',\n",
       "  '남에게 피해만 주지 않는다면 괜찮아요 .',\n",
       "  '상대방이 예의가 없네요 .',\n",
       "  '다양하게 먹자고 해보세요 .',\n",
       "  '나이 차이는 극복할 수 있어요 .',\n",
       "  '서울에서 왕서방 찾기네요 .',\n",
       "  '처음은 다 그런가봐요 .',\n",
       "  '자신이 편하고 즐거울 수 있는 방법을 생각해보세요 .',\n",
       "  '꿈은 현실이랑 반대예요 .',\n",
       "  '사람 마음은 알기 어렵죠 .',\n",
       "  '말하기 힘들었겠어요 .',\n",
       "  '사랑은 찾아나서는 노력이 필요해요 .',\n",
       "  '운동을 함께 해보세요 .',\n",
       "  '은근 매력남일 거 같은데요 .',\n",
       "  '받는 것보다 주는 게 더 행복하고 , 더 주고 싶은 마음인 것 같아요 .',\n",
       "  '요즘 상영하는 영화나 맛집부터 시작해보는 것도 좋을 듯합니다 .',\n",
       "  '차분히 생각해보세요 . 사랑은 소유가 아니에요 .',\n",
       "  '알다가도 모를 .',\n",
       "  '쓸데 없는 걱정일 수도 있어요 .',\n",
       "  '힘껏 울고 천천히 털어내길 바랄게요 .',\n",
       "  '힘든 시간 보내고 있으신가봐요 .',\n",
       "  '의아하셨겠어요 .',\n",
       "  '좋아하니까 도와주었다고 생각하게 될 거예요 .',\n",
       "  '야경이 예쁜 곳이요 .',\n",
       "  '달콤한 커피 한 잔 마셔보세요 .',\n",
       "  '당신을 탓하지 마세요 .',\n",
       "  '친구들을 만나보는 건 어떨까요 .',\n",
       "  '좋은 마음이네요 .',\n",
       "  '마음이 허락하는 데까지 아닐까요 .',\n",
       "  '제가 1호팬 하겠습니다 .',\n",
       "  '지나간 사랑은 놓아주세요 .',\n",
       "  '다양하게 경험해보세요 .',\n",
       "  '솔직한 마음으로 다가가보세요 .',\n",
       "  '공부한 만큼 나올 거예요 .',\n",
       "  '언젠간 닥쳐올 순간일 거예요 .',\n",
       "  '쓰지 않으면 모여요 .',\n",
       "  '세상에 비밀은 없어요 .',\n",
       "  '잘 지낼거예요 .',\n",
       "  '개인이 원하는 게 있을 거예요 .',\n",
       "  '그렇다면 여우네요 .',\n",
       "  '질투하지 마세요 .',\n",
       "  '너무 힘드시겠어요 .',\n",
       "  '너무 빨리 지우려고 하면 더 안 지워져요 .',\n",
       "  '같은 말이죠 .',\n",
       "  '마음이 없는 걸 수도 있어요 .',\n",
       "  '노래 연습 꾸준히 해보세요 .',\n",
       "  '제가 위로해 드릴게요 .',\n",
       "  '감수성이 풍부한 사람이군요 .',\n",
       "  '도와주다가 마음이 더 다칠 거예요 .',\n",
       "  '제 생일도 축하해 주세요 .',\n",
       "  '그것은 전혀 문제되지 않아요 .',\n",
       "  '확신이 서지 않나봐요 .',\n",
       "  '상처받고 있다고 말해보세요 .',\n",
       "  '일주일이 즐겁겠어요 .',\n",
       "  '마음 속으로 생일을 축하해줘요 .',\n",
       "  '지식 쌓는 재미가 있죠 .',\n",
       "  '누군가의 반대로 헤어졌나봐요 .',\n",
       "  '이별을 받아들일 시간이 필요할지도 몰라요 .',\n",
       "  '키우기 쉬울 거예요 .',\n",
       "  '변덕이 심한 사람이네요 .',\n",
       "  '학원을 다니거나 연습하면 잘할 수 있을 거예요 .',\n",
       "  '시간 활용에 따라 다르겠죠 .',\n",
       "  '간단하고 좋죠 .',\n",
       "  '생각이 너무 많아서 그런 것 같습니다 .',\n",
       "  '가랑비에 옷 젖는 듯한 사랑이었나봐요 .',\n",
       "  '후회 , 상상 , 자책 모두 멈출 때가 됐어요 .',\n",
       "  '그러기 힘들어서 결혼이라는 제도를 만든 걸 수도 있어요 .',\n",
       "  '이 사람 아니면 결혼 안 하고 살 것 같았나봅니다 .',\n",
       "  '진정한 사랑으로 외로움을 극복해보세요 .',\n",
       "  '관계의 정도에 따라 다르겠지만 너무 길면 안좋지 않을까요 ?',\n",
       "  '나랑 같이 놀아요 .',\n",
       "  '좋아하니까 예뻐보이는 걸 수도 있어요 .',\n",
       "  '사랑에서 가장 어려운 게 사랑을 계속 유지하는 거예요 .',\n",
       "  '마음가는대로 해보세요 .',\n",
       "  '길러도 어울리면 길러보세요 .',\n",
       "  '사람마다 취향도 다르니까요 .',\n",
       "  '살 안 찌는 게 좋을 것 같아요 .',\n",
       "  '일정 안 짰다고 하면서 일정을 물어보세요 .',\n",
       "  '떠나보내고 남는건 빈자리의 공허함이죠 .',\n",
       "  '가려 가며 만나면 돼요 .',\n",
       "  '좋아하는 만큼 지쳐가는 마음 아닐까요 .',\n",
       "  '남편을 의심하지 마세요 .',\n",
       "  '와우 축하해요 .',\n",
       "  '좋은 사람과 함께 가세요 .',\n",
       "  '마음이 떠난 이유를 먼저 생각해봐요 .',\n",
       "  '안 될 것도 없죠 .',\n",
       "  '뜻대로 되는게 많지 않죠 .',\n",
       "  '보고 싶나봐요 .',\n",
       "  '원하던게 아니었을텐데 씁쓸했겠어요 .',\n",
       "  '좋은 오지랖이었으면 좋겠네요 .',\n",
       "  '애석하네요 .',\n",
       "  '당신도 충분히 좋은 사람이었어요 .',\n",
       "  '그러게요 . 그만큼 사랑했다는거겠죠 .',\n",
       "  '전하지 못한 이야기 저에게 해주세요 .',\n",
       "  '여느 때보다 더 힘든 날이었나봅니다 .',\n",
       "  '더 좋은 사람이랑 가세요 .',\n",
       "  '서로 속도를 맞춰보세요 .',\n",
       "  '다시는 그러지 않겠다고 솔직하게 이야기해보세요 .',\n",
       "  '가기 싫어도 가야겠죠 .',\n",
       "  '좋아하는 감정은 정말 복잡하고 힘들어요 .',\n",
       "  '사랑은 끝나도 당신의 시간은 여전히 진행 중인 걸 잊지 마세요 .',\n",
       "  '시작 !',\n",
       "  '생각나나봅니다 .',\n",
       "  '감정에 확신이 있다면 연락해보세요 .',\n",
       "  '거울 보고 이야기해주세요 .',\n",
       "  '이쁜 마스크 사드리고 싶네요 .',\n",
       "  '성적자기결정권이있죠 .',\n",
       "  '다른 사람을 좋아하게 되었나요 .',\n",
       "  '그래도 배울 점이 하나라도 있을 거예요 .',\n",
       "  '짝사랑에 기분이 오락가락하죠 .',\n",
       "  '친구로 지내고 싶은 거겠죠 .',\n",
       "  '놀이동산은 다 좋아할 거예요 .',\n",
       "  '존재 자체로 큰 힘이 되어주고 있나봅니다 .',\n",
       "  '이김에 푹 쉬는 건 어떨까요 . 영화도 보고 맛있는 거 먹고 .',\n",
       "  '더 만나보세요 .',\n",
       "  '다는 기억 못하더라도 노력하는 게 좋겠죠 .'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_que,test_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5f8e0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정성평가\n",
    "def predict_sentence(question, model, tokenizer, max_len=42):\n",
    "\n",
    "    # 질문 전처리\n",
    "    question = preprocess_sentence(question)\n",
    "    question_seq = tokenizer.texts_to_sequences([question])\n",
    "    question_seq = pad_sequences(question_seq, maxlen=max_len, padding='post')\n",
    "    \n",
    "    # 초기 디코더 입력\n",
    "    start_token = tokenizer.word_index[\"<start>\"]\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "    decoder_input = [start_token]\n",
    "    output = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        decoder_input_padded = pad_sequences([decoder_input], maxlen=max_len, padding='post')\n",
    "        \n",
    "        # 마스크 생성\n",
    "        enc_mask, dec_enc_mask, dec_mask = generate_masks(\n",
    "            tf.constant(question_seq), tf.constant(decoder_input_padded)\n",
    "        )\n",
    "        \n",
    "        # 예측\n",
    "        predictions, _, _, _ = model(\n",
    "            tf.constant(question_seq), \n",
    "            tf.constant(decoder_input_padded), \n",
    "            enc_mask, \n",
    "            dec_enc_mask, \n",
    "            dec_mask\n",
    "        )\n",
    "        \n",
    "        # 가장 높은 확률의 단어 선택\n",
    "        next_token = tf.argmax(predictions[0, len(decoder_input) - 1]).numpy()\n",
    "        if next_token == end_token:  # <end> 토큰이면 중단\n",
    "            break\n",
    "        \n",
    "        decoder_input.append(next_token)\n",
    "        output.append(next_token)\n",
    "    \n",
    "    # 인덱스를 단어로 변환\n",
    "    return tokenizer.sequences_to_texts([output])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8e78cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram 기반 metrics \n",
    "# test 셋 검증을 위함 - 위 코드와 구조적으로 동일\n",
    "def evaluate_metrics(predictions, references):\n",
    "    \"\"\"\n",
    "    BLEU 및 ROUGE 점수를 계산합니다.\n",
    "    :param predictions: 모델이 생성한 텍스트 리스트\n",
    "    :param references: 실제 정답 텍스트 리스트\n",
    "    :return: BLEU 및 ROUGE 점수\n",
    "    \"\"\"\n",
    "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "    from rouge_score import rouge_scorer\n",
    "\n",
    "    # BLEU 점수 계산\n",
    "    bleu_scores = []\n",
    "    smooth_fn = SmoothingFunction().method1  # BLEU 점수 스무딩 함수\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        bleu = sentence_bleu([ref.split()], pred.split(), smoothing_function=smooth_fn)\n",
    "        bleu_scores.append(bleu)\n",
    "\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "    # ROUGE 점수 계산\n",
    "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        scores = rouge.score(ref, pred)\n",
    "        for key in rouge_scores:\n",
    "            rouge_scores[key].append(scores[key].fmeasure)\n",
    "\n",
    "    avg_rouge = {key: sum(rouge_scores[key]) / len(rouge_scores[key]) for key in rouge_scores}\n",
    "\n",
    "    return avg_bleu, avg_rouge\n",
    "\n",
    "\n",
    "def predict_responses(test_que, model, tokenizer, max_len):\n",
    "    \"\"\"\n",
    "    테스트 질문 데이터를 입력으로 모델이 예측한 답변을 생성합니다.\n",
    "    진행 과정을 tqdm으로 표시합니다.\n",
    "    :param test_que: 테스트 질문 데이터\n",
    "    :param model: Transformer 모델\n",
    "    :param tokenizer: 토크나이저\n",
    "    :param max_len: 최대 시퀀스 길이\n",
    "    :return: 모델이 생성한 답변 리스트\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for que in tqdm(test_que, desc=\"Predicting Responses\"):\n",
    "        # que 토큰화 및 패딩\n",
    "        que_seq = tokenizer.texts_to_sequences([que])\n",
    "        que_seq = pad_sequences(que_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "        # 디코더 입력 초기화 (<start> 토큰 사용)\n",
    "        dec_input = [[tokenizer.word_index['<start>']]]\n",
    "        for _ in range(max_len):\n",
    "            dec_input_padded = pad_sequences(dec_input, maxlen=max_len, padding='post')\n",
    "\n",
    "            # 마스크 생성\n",
    "            enc_mask = generate_padding_mask(tf.constant(que_seq))\n",
    "            dec_enc_mask = generate_padding_mask(tf.constant(que_seq))\n",
    "            dec_mask = generate_lookahead_mask(dec_input_padded.shape[1])\n",
    "            dec_mask = tf.maximum(dec_mask, generate_padding_mask(tf.constant(dec_input_padded)))\n",
    "\n",
    "            # 모델 예측\n",
    "            logits = model(\n",
    "                [tf.constant(que_seq), tf.constant(dec_input_padded), enc_mask, dec_enc_mask, dec_mask]\n",
    "            )\n",
    "\n",
    "            # 가장 높은 확률을 가진 단어 선택\n",
    "            next_word = tf.argmax(logits[:, len(dec_input[0]) - 1, :], axis=-1).numpy()[0]\n",
    "            if next_word == tokenizer.word_index['<end>']:\n",
    "                break\n",
    "\n",
    "            dec_input[0].append(next_word)\n",
    "\n",
    "        # 디코더 입력을 텍스트로 변환\n",
    "        pred_sentence = tokenizer.sequences_to_texts(dec_input)[0].replace('<start>', '').replace('<end>', '').strip()\n",
    "        predictions.append(pred_sentence)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72365c48",
   "metadata": {},
   "source": [
    "#### 러닝커브 각 에폭에서 비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e5e1559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 무릎 안 좋으면 스쿼트 하면 안되겠지 ?\n",
      "A: 저는 신경 신경 안 같아요 .\n",
      "\n",
      "Q: 나 윗집 남자애 좋아하는 것 같애 .\n",
      "A: 괴로움 마음 이 언제나 단지 지도 몰라요 .\n",
      "\n",
      "Q: 짝남이 자꾸 꿈에 나오는데 꿈에서도 용기 없어서 피하고 그래 .\n",
      "A: 함부로 옷을 잘 안되겠지만 잘할 수 있을 거예요 .\n",
      "\n",
      "Q: 2년동안 나 사랑해줘서 고맙다\n",
      "A: 잊어버리 는 분간 이 불필요 했 나 봐요 .\n",
      "\n",
      "Q: 내가 친절하니까 쉬워보이나 ?\n",
      "A: 항상 사랑했던 걸 수도 있어요 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\"무릎 안 좋으면 스쿼트 하면 안되겠지 ?\", \"나 윗집 남자애 좋아하는 것 같애 .\", \"짝남이 자꾸 꿈에 나오는데 꿈에서도 용기 없어서 피하고 그래 .\", \"2년동안 나 사랑해줘서 고맙다\", \"내가 친절하니까 쉬워보이나 ?\"]\n",
    "\n",
    "for question in questions:\n",
    "    answer = predict_sentence(question, transformer, tokenizer)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ce648030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2958f210d914e1081f8f1e363fa7349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting Responses:   0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test에 대한 예측(ans) \n",
    "predictions = predict_responses(test_que, transformer_model, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "94015667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba27cd9763d467d8fb82bde30bba226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing BLEU References:   0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1160cca933d54a8491ea80dec2d38e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing BLEU Predictions:   0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0008\n"
     ]
    }
   ],
   "source": [
    "# BLEU 점수 계산\n",
    "\n",
    "smooth_fn = SmoothingFunction().method1  # BLEU 스무딩 \n",
    "\n",
    "references = [[ans.split()] for ans in tqdm(test_ans, desc=\"Processing BLEU References\")]\n",
    "predictions_split = [pred.split() for pred in tqdm(predictions, desc=\"Processing BLEU Predictions\")]\n",
    "\n",
    "bleu_score = corpus_bleu(\n",
    "    references,\n",
    "    predictions_split,\n",
    "    smoothing_function=smooth_fn\n",
    ")\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "adf1b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6640e011732450eb89929501bde1c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating ROUGE:   0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Score: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# ROUGE 점수 계산\n",
    "\n",
    "rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []} # n-gram 기반\n",
    "\n",
    "for pred, ref in tqdm(zip(predictions, test_ans), total=len(test_ans), desc=\"Calculating ROUGE\"):\n",
    "    scores = rouge_scorer_instance.score(ref, pred)  # 각 문장에 대해 ROUGE 계산\n",
    "    for key in rouge_scores:\n",
    "        rouge_scores[key].append(scores[key].fmeasure)\n",
    "\n",
    "avg_rouge_score = {key: sum(rouge_scores[key]) / len(rouge_scores[key]) for key in rouge_scores}\n",
    "\n",
    "print(f\"ROUGE Score: {avg_rouge_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ae2d2",
   "metadata": {},
   "source": [
    "#### n-gram으로 맞춰서 precision이나 recall을 측정하는건 사실상 언어, 특히 생성 task에 맞지 않는다. \n",
    "* 단어의 유사도, 즉 문맥 자체를 바라볼 수 있는 metric이 필요하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2e1ebb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating KoBERTScore...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216e4f4fdca34cd993d5fd8d15173ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing KoBERTScore:   0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266031b2e844430da3427a3c20c0c7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91624c170b44e6ea4f1b615ac36db8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.95 seconds, 406.96 sentences/sec\n",
      "KoBERTScore - Precision: 0.7209, Recall: 0.7281, F1: 0.7241\n"
     ]
    }
   ],
   "source": [
    "# KoBERTScore 계산\n",
    "\n",
    "with tqdm(total=len(predictions), desc=\"Processing KoBERTScore\") as pbar:\n",
    "    P, R, F1 = score(predictions, test_ans, lang=\"ko\", verbose=True)\n",
    "    pbar.update(len(predictions))\n",
    "\n",
    "print(f\"KoBERTScore - Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98169b8f",
   "metadata": {},
   "source": [
    "### 문맥의 유사도에 기반하는 KoBERTScore가 챗봇 대화 생성 task에서 적절한 평가 metric이 될 것이다.\n",
    "### 이해나 직관적으로도 가장 납득이 되며, 적은 데이터의 양과 도메인에 큰 영향을 받는 task이기에 특히나 유사도를 기반으로 맥락을 파악하는 것이 적절할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530430e1",
   "metadata": {},
   "source": [
    "#### KoBERTScore를 정량 metric으로 잡고 test que의 예문 5개를 기반하여 정성적 평가를 같이 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf6462",
   "metadata": {},
   "source": [
    "#### 1. 데이터 22000개(mecab - 'VA', 'VV','MAG' 중 최대 2개 변경하여 증강한 데이터셋 ), layer 6개, 15 epoch\n",
    "* train Loss : Loss: 1.1009, KoBERTScore - Precision: 0.7071, Recall: 0.7176, F1: 0.7119\n",
    "\n",
    "#### 2. 데이터 22000개(mecab - 'VA', 'VV','MAG' 중 최대 3개 변경하여 증강한 데이터셋 ), 6 layer, 15 epoch\n",
    "* train Loss : Loss: 1.0342, KoBERTScore - Precision: 0.7224, Recall: 0.7251, F1: 0.7233\n",
    "\n",
    "#### 3. 데이터 22000개(mecab -'NNG', 'NNP', 'VA', 'VV','MAG' 중 최대 3개 변경하여 증강한 데이터셋 ), 6 layer, 15 epoch\n",
    "* train Loss : Loss: 1.0237, KoBERTScore - Precision: 0.7290, Recall: 0.7231, F1: 0.7256\n",
    "\n",
    "#### 4. 데이터 22000개(mecab -'NNG', 'NNP', 'VA', 'VV','MAG' 중 최대 4개 변경하여 증강한 데이터셋 ), 6 layer, 15 epoch\n",
    "* train Loss : Loss: 1.0237, KoBERTScore - Precision: 0.7332, Recall: 0.7251, F1: 0.7286\n",
    "\n",
    "#### 5. 데이터 22000개(mecab -'NNG', 'NNP', 'VA', 'VV','MAG' 중 최대 5개 변경하여 증강한 데이터셋 ), 6 layer, 15 epoch\n",
    "* train Loss : Loss: 1.0489, KoBERTScore - Precision: 0.7112, Recall: 0.7202, F1: 0.7151\n",
    "* 단지 불순물이 더 많이 낀 탓에 학습이 더 필요할수도 있는 상황\n",
    "* Q: 무릎 안 좋으면 스쿼트 하면 안되겠지 ?\n",
    "* A: 따로 신경쓰이는 부분이 없다면 가능합니다 .\n",
    "\n",
    "* Q: 나 윗집 남자애 좋아하는 것 같애 .\n",
    "* A: 충분히 지칠만 해요 .\n",
    "\n",
    "* Q: 짝남이 자꾸 꿈에 나오는데 꿈에서도 용기 없어서 피하고 그래 .\n",
    "* A: 자신감 을 자주 힘든가 봐요 .\n",
    "\n",
    "* Q: 2년동안 나 사랑해줘서 고맙다\n",
    "* A: 충분히 지칠만 해요 .\n",
    "\n",
    "* Q: 내가 친절하니까 쉬워보이나 ?\n",
    "* A: cc는 자들의 변명이에요 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab49df",
   "metadata": {},
   "source": [
    "### 위 실험 중 KoBERTScore가 가장 높았던 4번을 기준으로 잡고 추가 생성 task 진행\n",
    "\n",
    "#### 데이터 26000개(4번 유의어변경 + random_swap 'NNG-NNG', 'MAG-MAG', 'VV-VA') 중 1쌍 변경\n",
    "* train Loss : Loss: 0.6049, KoBERTScore - Precision: 0.7208, Recall: 0.7276, F1: 0.7238\n",
    "* Q: 무릎 안 좋으면 스쿼트 하면 안되겠지 ?\n",
    "* A: 이성으로 입히 없네요 .\n",
    "\n",
    "* Q: 나 윗집 남자애 좋아하는 것 같애 .\n",
    "* A: 각자가 생각하는 기본이 사랑하지 않는 어플을 읽히 겠 어요 .\n",
    "\n",
    "* Q: 짝남이 자꾸 꿈에 나오는데 꿈에서도 용기 없어서 피하고 그래 .\n",
    "* A: 의심 해도 시키 니까요 .\n",
    "\n",
    "* Q: 2년동안 나 사랑해줘서 고맙다\n",
    "* A: 저 는 힘 이 되 고 기분 에 연락 을 찾 는 게 만들 어 보 세요 .\n",
    "\n",
    "* Q: 내가 친절하니까 쉬워보이나 ?\n",
    "* A: 서로의 선에 대해 됩니다 .\n",
    "\n",
    "#### 데이터 34000개(4번 유의어 변경 + random_insertion 명사 앞에 형용사 or 동사 앞에 부사 6 layer, 15 epoch\n",
    "* train Loss : Loss: 0.4902, KoBERTScore - Precision: 0.7209, Recall: 0.7281, F1: 0.7241\n",
    "* Q: 무릎 안 좋으면 스쿼트 하면 안되겠지 ?\n",
    "* A: 저는 신경 신경 안 같아요 .\n",
    "\n",
    "* Q: 나 윗집 남자애 좋아하는 것 같애 .\n",
    "* A: 괴로움 마음 이 언제나 단지 지도 몰라요 .\n",
    "\n",
    "* Q: 짝남이 자꾸 꿈에 나오는데 꿈에서도 용기 없어서 피하고 그래 .\n",
    "* A: 함부로 옷을 잘 안되겠지만 잘할 수 있을 거예요 .\n",
    "\n",
    "* Q: 2년동안 나 사랑해줘서 고맙다\n",
    "* A: 잊어버리 는 분간 이 불필요 했 나 봐요 .\n",
    "\n",
    "* Q: 내가 친절하니까 쉬워보이나 ?\n",
    "* A: 항상 사랑했던 걸 수도 있어요 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d9bd1b",
   "metadata": {},
   "source": [
    "## 결과\n",
    "\n",
    "##### 해보니까 유의어 대체가 좋다. 진행한 실험에선 사실상 유의어 대체만 했을 때 제일 좋다. 품사를 적절하게 선택한게 큰 도움이 되었다.\n",
    "* swap만, insertion만 했을때와 비교분석을 해볼 필요가 있을 것이다.\n",
    "##### swap은 맥락이 망가진다는 단점이 크게 적용할 것이라고 생각했으나 의외로 성능이 나쁘지 않았다.\n",
    "##### random_insertion 역시 word2vec의 맥락 정보를 활용하기에 큰 도움이 될 것이라고 판단했다.\n",
    "##### 유의어대체 + random_swap + random_insertion 모두 활용하고 epoch을 20 이상 주면 더 좋은 결과를 기대할 수 있을 것이다.\n",
    "##### 다만, 대체나 도치의 경우 정성 평가에서 맥락을 튀게 만드는 경향이 크다. 아마 원본 데이터보다  증강 데이터가 압도적으로 많아졌기 때문일 것.\n",
    "* 학습이 아닌 생성 단계에서 beam search를 활용한다면 더 좋은 생성 결과를 얻어볼 수 있을 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
