{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac30e91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.3.3\n",
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import tensorflow\n",
    "import summa\n",
    "from summa.summarizer import summarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, AdditiveAttention, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(pd.__version__)\n",
    "print(version('summa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33f82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dbddf525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71547</th>\n",
       "      <td>Not even a dog knows you: Ssharad on people wh...</td>\n",
       "      <td>Actor Ssharad Malhotra, while talking about pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60337</th>\n",
       "      <td>Aussie coach Tom Moody mistaken for rating age...</td>\n",
       "      <td>Several CPM supporters began trolling and dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47504</th>\n",
       "      <td>ChaKu stabbed SA brutally: Sehwag on spinners'...</td>\n",
       "      <td>Reacting to Indian spinners Kuldeep Yadav and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76214</th>\n",
       "      <td>Chinese tourist assaulted by US border guard a...</td>\n",
       "      <td>A Chinese woman has been awarded Ã¢ÂÂ¹2.9 cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45744</th>\n",
       "      <td>Telangana students found mass copying may face...</td>\n",
       "      <td>Students found mass copying in Telangana class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89207</th>\n",
       "      <td>Modi is illegal not the red beacon on my car: ...</td>\n",
       "      <td>Reiterating that he will not remove the red be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71301</th>\n",
       "      <td>Player falls off chair while swatting a fly at...</td>\n",
       "      <td>USA's Sloane Stephens fell off a chair while t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69545</th>\n",
       "      <td>Ex-White House Press Secretary mocks Trump ove...</td>\n",
       "      <td>Former White House Press Secretary made a surp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13694</th>\n",
       "      <td>Eng cricketers' vehicle gets stuck in mud on a...</td>\n",
       "      <td>The vehicle carrying a few England cricketers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15772</th>\n",
       "      <td>Jet Airways delays part of Aug salaries to pil...</td>\n",
       "      <td>Cash-strapped Jet Airways has told its pilots,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "71547  Not even a dog knows you: Ssharad on people wh...   \n",
       "60337  Aussie coach Tom Moody mistaken for rating age...   \n",
       "47504  ChaKu stabbed SA brutally: Sehwag on spinners'...   \n",
       "76214  Chinese tourist assaulted by US border guard a...   \n",
       "45744  Telangana students found mass copying may face...   \n",
       "89207  Modi is illegal not the red beacon on my car: ...   \n",
       "71301  Player falls off chair while swatting a fly at...   \n",
       "69545  Ex-White House Press Secretary mocks Trump ove...   \n",
       "13694  Eng cricketers' vehicle gets stuck in mud on a...   \n",
       "15772  Jet Airways delays part of Aug salaries to pil...   \n",
       "\n",
       "                                                    text  \n",
       "71547  Actor Ssharad Malhotra, while talking about pe...  \n",
       "60337  Several CPM supporters began trolling and dire...  \n",
       "47504  Reacting to Indian spinners Kuldeep Yadav and ...  \n",
       "76214  A Chinese woman has been awarded Ã¢ÂÂ¹2.9 cro...  \n",
       "45744  Students found mass copying in Telangana class...  \n",
       "89207  Reiterating that he will not remove the red be...  \n",
       "71301  USA's Sloane Stephens fell off a chair while t...  \n",
       "69545  Former White House Press Secretary made a surp...  \n",
       "13694  The vehicle carrying a few England cricketers ...  \n",
       "15772  Cash-strapped Jet Airways has told its pilots,...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daa3b2c",
   "metadata": {},
   "source": [
    "### 데이터 전처리하기(추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e6a24277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98401"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "14ef8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bac875fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0a0ded3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e7d9e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ca22bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "044c86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 전처리 함수\n",
    "# def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "#     sentence = sentence.lower() # 텍스트 소문자화\n",
    "#     sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "#     sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "#     sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "#     sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "#     sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "#     sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "#     sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "#     # 불용어 제거 (Text)\n",
    "#     if remove_stopwords:\n",
    "#         tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "#     # 불용어 미제거 (Summary)\n",
    "#     else:\n",
    "#         tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "#     return tokens\n",
    "# print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "561f3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower()  # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text  # HTML 문법 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)  # 괄호 안에 문자열 제거\n",
    "    sentence = re.sub('\"', '', sentence)  # 쌍따옴표 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])  # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\", \"\", sentence)  # 소유격 제거\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)  # 영어 외 문자 제거\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence)  # m이 3개 이상이면 2개로 변경\n",
    "    sentence = re.sub('\\s+', ' ', sentence).strip()  # 연속된 공백 제거\n",
    "    sentence = ' '.join([word for word in sentence.split() if len(word) <= 20])  # 단어 길이 제한\n",
    "    sentence = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', sentence)  # 중복 단어 제거\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f4c78",
   "metadata": {},
   "source": [
    "* EX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "edc8cbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.. Father. fffffffffffffffffffffffff'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d96e418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 91\n",
      "텍스트의 평균 길이 : 58.23813542090281\n",
      "제목의 최소 길이 : 1\n",
      "제목의 최대 길이 : 18\n",
      "제목의 평균 길이 : 9.553660024400163\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcRklEQVR4nO3df5RV5X3v8feHEWYiomBEqyiirZoRbv3BXEIMTTQao8Qb07uSVFZuq3YCma44SS/eGw3Te7XpguhqNT80K3MxWE2vd2KaarGVRF0yxk5CSQaj0ThJpUQD+AMMEEArDMP3/nE2rMN4zjAM5+y9z5nPa6295uxf53xx+azPeZ6993MUEZiZmeXNmKwLMDMzK8UBZWZmueSAMjOzXHJAmZlZLjmgzMwslxxQZmaWSw4oM6s5kl6UdEmVP2OapJB0RLL+hKRPJa8/KenRan6+OaByr1INMY0GbTZaRMR9EXFp1nXUOweUmZnlkgMqxyT9HTAV+CdJOyV9XtJsST+StE3SM5IuTI69QNLrkk5J1s+RtFXSu0q9T1b/JrMKOlfSzyT9VtL9kpoAJF0h6emkjfxI0u/vO0HSjZL+XdIOSc9L+sOifQ2S/iZpR+uAD5f7YEnXSOopWg9JbZJeSD7365JUtP9PJfUlbfIRSacm2yXpy5I2Sdou6VlJMyr836l2RYSXHC/Ai8AlyespwG+AuRS+XHwwWZ+c7F8MrATeATwLXFfqfbx4qfUl+f/5x8BJwLFAH9AGnAdsAt4NNABXJ8c2Jud9PDlnDPBHwBvAicm+NuAXwCnJe3YDARyR7H8C+FTy+hqgp6ieAP4ZmEjhy+Bm4LJk35XAWqAZOAL4C+BHyb4PAWuS85Qcc2LW/33zsrgHVVv+G7AiIlZExN6IeAzopRBYADcDx1BouBuBr2dSpVk6vhYRL0fEFuCfgHOBBcD/iYjVETEQEfcCu4DZABHx98k5eyPifuAFYFbyfp8AvhIR65P3/NIh1nNLRGyLiF9TCLdzk+1twJcioi8i9gBLKPT+TgX6gQnAuwAlx7wykv8Y9cgBVVtOBT6eDCFsk7QNmAOcCBAR/cA9wAzgtki+opnVqVeLXr8JHEWhjVw/qI2cQqHXhKQ/KRr+20ahrRyXvMdJwPqi93ypAvWQ1PTVos/cQqG3NCUiVgJ3UvgyuUnSUklHH+Ln1i0HVP4Vh8x64O8iYmLRMj4ibgGQNAW4Cfhb4DZJjWXex6xerQcWD2ojR0ZEV9JjuQu4DnhnREwEnqMQFgCvUAizfaZWsKZPD6rpHRHxI4CI+FpEzATOBs4E/meFPrfmOaDy7zXg9OT1/wX+i6QPJRd0myRdKOnk5ILsPcAyoJVCY/urMu9jVq/uAtokvTu5AWG8pA9LmgCMp/BFbTOApGsp9KD2+Q7w2aQ9TQJurFBNncAXJE1PPvcYSR9PXv/npNaxFK6HvQXsrdDn1jwHVP59CfiLZGjgjyhccF1EoZGtp/BtawzwWeB44H8lQ3vXAtdK+oPB7yPpf6T7TzBLR0T0AvMpDJttpXBzwjXJvueB24BVFL6w/Sfgh0Wn3wU8AjwDPAU8UKGaHgRuBb4taTuFXtvlye6jk8/dSmFI8TfAX1fic+uBfJnCzMzyyD0oMzPLJQeUmZnlkgPKzMxyyQFlZma5dESaH3bcccfFtGnT0vxIs4pYs2bN6xExOes6ynHbslpWrn2lGlDTpk2jt7c3zY80qwhJhzqrQKrctqyWlWtfHuIzM7NcckCZmVkuOaDMzCyXHFBmZpZLDigzM8slB5SZmeWSA6rGdXV1MWPGDBoaGpgxYwZdXV1Zl2RWN9y+spXqc1BWWV1dXXR0dLBs2TLmzJlDT08Pra2tAMybNy/j6sxqm9tXDkREasvMmTPDKmf69OmxcuXKA7atXLkypk+fnlFF9QvojRTbyqEubluV5/aVnnLtK9Xfg2ppaQk/7V45DQ0NvPXWW4wdO3b/tv7+fpqamhgYGMiwsvojaU1EtGRdRzluW5Xn9pWecu3L16BqWHNzMz09PQds6+npobm5OaOKzOqH21f2HFA1rKOjg9bWVrq7u+nv76e7u5vW1lY6OjqyLs2s5rl9Zc83SdSwfRdq29vb6evro7m5mcWLF/sCbg5Iuhu4AtgUETOSbfcDZyWHTAS2RcS5Jc59EdgBDAB78jy0WM/cvrLna1Bmw3Co16AkvQ/YCXxrX0AN2n8b8NuI+GKJfS8CLRHx+nA/z23Lalm59uUelFkVRMSTkqaV2idJwCeAD6RalFmN8TUos/T9AfBaRLxQZn8Aj0paI2lBuTeRtEBSr6TezZs3V6VQsyw5oMzSNw8YakqCORFxPnA58JlkuPBtImJpRLRERMvkybn9sV+zEXNAmaVI0hHAfwXuL3dMRGxM/m4CHgRmpVOdWb44oMzSdQnwi4jYUGqnpPGSJux7DVwKPJdifWa54YAyqwJJXcAq4CxJGyS1JruuYtDwnqSTJK1IVk8AeiQ9A/wYeDgivp9W3WZ54rv4zKogIko+LBMR15TY9jIwN3m9DjinqsWZ1Qj3oMzMLJccUGZmlksOKDMzyyUHlJmZ5ZIDyszMcskBZWZmueSAMjOzXHJAmZlZLjmgzMwslxxQZmaWSw4oM7MyGhoakLR/aWhoyLqkUWVYASXpv0v6uaTnJHVJapJ0mqTVktZKul/SuGoXa2aWloaGBvbu3ctRRx3FmjVrOOqoo9i7d69DKkUHDShJU4DPAi0RMQNooDAj863AlyPi94CtQGv5dzEzqy37wmnHjh2cf/757NixY39IWTqGO8R3BPCO5MfWjgReAT4AfDfZfy/w0YpXZ2aWoR/84AdDrlt1HTSgkl/3/Bvg1xSC6bfAGmBbROxJDtsATCl1vqQFknol9W7evLkyVZuZpeD973//kOtWXcMZ4psEXAmcBpwEjAcuG+4HRMTSiGiJiJbJkyePuFAzszSNGTOGnTt3MmHCBJ566ikmTJjAzp07GTPG95alZTg/WHgJ8KuI2Awg6QHgvcBESUckvaiTgY3VK9PMLF0DAwM0NDSwc+dOZs6cCRRCa2BgIOPKRo/hfBX4NTBb0pGSBFwMPA90Ax9LjrkaWF6dEs3MsjEwMEBE7F8cTukazjWo1RRuhngKeDY5ZylwA7BQ0lrgncCyKtZpZmajzHCG+IiIm4CbBm1eB8yqeEVmZmZ4JgkzM8spB5SZmeWSA8qsCiTdLWmTpOeKtt0saaOkp5NlbplzL5P0y2QasRvTq9oGK56Hb99i6XFAmVXHPZR+XvDLEXFusqwYvFNSA/B14HLgbGCepLOrWqmVVBxG5513XsntVl3DuknCzA5NRDwpadoITp0FrI2IdQCSvk3hQfnnK1ieHYKI2P/a4ZQu96DM0nWdpJ8lQ4CTSuyfAqwvWvc0Yhkq7jmVWrfqckCZpecbwO8C51KY1/K2w3kzTyNWfT/96U+HXLfqckCZpSQiXouIgYjYC9xF6ecINwKnFK17GrGMSeL888/38F4GHFBmKZF0YtHqHwLPlTjsJ8AZyQ+CjqPw22sPpVGfHaj42lNxz6l4u1WXb5IwqwJJXcCFwHGSNlCYieVCSecCAbwIfDo59iTgmxExNyL2SLoOeITCj4PeHRE/T/9fYOAwypoDyqwKImJeic0l56uMiJeBuUXrK4C33YJuNtp4iM/MzHLJAWVmZrnkgDIzs1xyQJmZWS75JgkzszJKPfvkO/vS4x6UmVkJ5R7M9QO76XEPysxsCJ4sNjvuQZmZWS45oMzMLJc8xGdmNgQP62XHPSgzsxLK3a3nu/jS4x6UmVkZDqNsuQdlZma55ICqce3t7TQ1NSGJpqYm2tvbsy7JzKwiHFA1rL29nc7OTpYsWcIbb7zBkiVL6OzsdEiZWV1QmmOsLS0t0dvbm9rn1bumpiZaWlro7e1l165dNDY27l9/6623si6vrkhaExEtWddRjtuW1bJy7cs9qBq2a9cuVq9efUAPavXq1ezatSvr0szqgqS3LZYeB1SNmzt3LgsXLuTII49k4cKFzJ079+AnmdlBeS6+7DmgatzDDz/M7bffzptvvsntt9/Oww8/nHVJZnUlIvYvli4HVA1rbGxk9uzZLFq0iPHjx7No0SJmz55NY2Nj1qWZmR02B1QNmz9/fslrUPPnz8+6NDOzw+a7+GrMSMe/PTxxeHwX3+gzVFtze6os38VXJ4rHwwePjZfb58aUPkl3S9ok6bmibX8t6ReSfibpQUkTy5z7oqRnJT0tyamTEc/Flz0HlFl13ANcNmjbY8CMiPh94N+ALwxx/kURcW6ee22jgb/sZcsBZVYFEfEksGXQtkcjYk+y+q/AyakXZlZDHFBm2fhT4Htl9gXwqKQ1khakWJNZrvjnNsxSJqkD2APcV+aQORGxUdLxwGOSfpH0yAa/zwJgAcDUqVOrVq9ZVobVg5I0UdJ3kwu8fZLeI+lYSY9JeiH5O6naxZrVOknXAFcAn4wyFzQiYmPydxPwIDCrzHFLI6IlIlomT55cpYrNsjPcIb6vAt+PiHcB5wB9wI3A4xFxBvB4sm5mZUi6DPg88JGIeLPMMeMlTdj3GrgUeK7UsWb17qABJekY4H3AMoCI2B0R24ArgXuTw+4FPlqdEs1qj6QuYBVwlqQNklqBO4EJFIbtnpbUmRx7kqQVyaknAD2SngF+DDwcEd/P4J9geLLYrA3nGtRpwGbgbyWdA6wBPgecEBGvJMe8SqFhvY3HyQ/dsccey9atWw/5vJE0nkmTJrFly5aDH2iHJCLmldi8rMyxLwNzk9frKIxSWMaGmizWt5unYzhDfEcA5wPfiIjzgDcYNJyXjKWXG0/3OPkh2rp165AP3VZyGUkQmo0mfgYqO8PpQW0ANkTE6mT9uxQC6jVJJ0bEK5JOBDZVq8jRJm46Gm4+Jr3PMjPLoYMGVES8Kmm9pLMi4pfAxcDzyXI1cEvyd3lVKx1F9JfbU/u2Jom4OZWPMjM7JMN9DqoduE/SOGAdcC2F4cHvJBd/XwI+UZ0Szcyy4xsjsjOsgIqIp4FSc4JdXNFqzMxyIiJKhpOvRaXHM0mYmZXhMMqWAyqn0hpWmDTJE4CYWT45oHJoJN/a/GyGmdUbz2ZuZma55IAyM7NcckCZmVkuOaDMzCyXHFBmZpZLvovPzIzDe7TDd9BWhwPKzIyhQ8aPcWTDAVXjir/17XvthmRm9cABVWOGMwzh+cPMrB44oGpMcdAMFVYOJDOrdb6Lz8zMcsk9qDow3F6VmVktcUDVAYeSmdUjD/GZmVkuOaDMzCyXHFBmVSDpbkmbJD1XtO1YSY9JeiH5W/LXIiVdnRzzgqSr06vaLF8cUGbVcQ9w2aBtNwKPR8QZwOPJ+gEkHQvcBLwbmAXcVC7IzOqdA8qsCiLiSWDLoM1XAvcmr+8FPlri1A8Bj0XElojYCjzG24PObFTwXXxm6TkhIl5JXr8KnFDimCnA+qL1Dcm2t5G0AFgAMHXq1AqWWeduPuaQT4mbjh7Redz820M/x/ZzQJllICJC0mFN9xERS4GlAC0tLZ46ZJj0l9tTmWlFEnFz1T+mrnmIzyw9r0k6ESD5u6nEMRuBU4rWT062mY06Diiz9DwE7Lsr72pgeYljHgEulTQpuTni0mSb2ajjgDKrAkldwCrgLEkbJLUCtwAflPQCcEmyjqQWSd8EiIgtwF8BP0mWLybbzEYdX4Myq4KImFdm18Ulju0FPlW0fjdwd5VKM6sZ7kHVidNPPz3rEszMKsoBVSfWrVuXdQlmZhXlgDIzs1xyQJmZWS45oMzMLJccUGZmlku+zbzGjRkzhoGBgf3rDQ0N7N27N8OKzPIvjV+hnjTJk9AfLgdUjdu7d69/8t3sEIxkHj5JqczfZwfyEJ+ZmeWSA8rMzHLJAWVmZrk07ICS1CDpp5L+OVk/TdJqSWsl3S9pXPXKtHImTZpEY2MjAI2Njb4wa2Z141B6UJ8D+orWbwW+HBG/B2wFWitZmA3P1q1bmTlzJi+//DIzZ85k69atWZdkZlYRwwooSScDHwa+mawL+ADw3eSQe4GPVqE+O4ijjz6aVatWcdJJJ7Fq1SqOPvrorEsyM6uI4fagvgJ8Htj3gM07gW0RsSdZ3wBMKXWipAWSeiX1bt68+XBqtRK2b99OW1sb27Zto62tje3bt2ddkplZRRw0oCRdAWyKiDUj+YCIWBoRLRHRMnny5JG8hZXR2NjImWeeSWdnJxMnTqSzs5Mzzzxz/zUpM7NaNpwe1HuBj0h6Efg2haG9rwITJe170PdkYGNVKrSy5s+fz9q1azn++OORxPHHH8/atWuZP39+1qWZmR22gwZURHwhIk6OiGnAVcDKiPgk0A18LDnsamB51aq0ki644ALGjx/Pli1biAi2bNnC+PHjueCCC7IuzczssB3Oc1A3AAslraVwTWpZZUqy4Vq8eDHLly9n9+7dRAS7d+9m+fLlLF68OOvSzMwO2yHNxRcRTwBPJK/XAbMqX5INV19fH3PmzDlg25w5c+jr6ytzhpmVc7A5LYfa73n6qsMzSdSw5uZmenp6DtjW09NDc3NzRhWZ1a6IGPFi1eGAqmEdHR20trbS3d1Nf38/3d3dtLa20tHRkXVpZmaHzT+3UcPmzZsHQHt7O319fTQ3N7N48eL92y1/JJ0F3F+06XTgf0fEV4qOuZDCTUe/SjY9EBFfTKlEs9xwQNW4efPmOZBqSET8EjgXCvNbUng848ESh/5LRFyRYmlmueMhPrPsXAz8e0S8lHUhZnnkgDLLzlVAV5l975H0jKTvSZpe6gBPI2b1zgFlloHk52k+Avx9id1PAadGxDnAHcA/lnoPTyNm9c4BZZaNy4GnIuK1wTsiYntE7ExerwDGSjou7QLNsuaAMsvGPMoM70n6neQnbZA0i0I7/U2KtVlC0tsWS4/v4jNLmaTxwAeBTxdtawOIiE4Kc1z+maQ9wH8AV4WfBk1duTCS5IdzU+KAMktZRLxBYf7K4m2dRa/vBO5Muy4rrTiM3INKl4f4zMwslxxQZmaWSx7iMzMbgof1suMelJlZCeVuhPANEulxD8rMrAyHUbbcgzIzs1xyQJmZWS45oMzMLJccUGZmlksOKDMzyyXfxWdmVkapZ6B8Z1963IMyMythqMliLR3uQZmZDcGTxWbHPSgzM8slB5SZmeWSh/jMzIbgYb3suAdlZlaCJ4vNnntQZmZlOIyy5R6UmZnlkgPKzMxyyQFlZma55IAyM7NcckCZpUzSi5KelfS0pN4S+yXpa5LWSvqZpPOzqNMKt5gPXiw9vovPLBsXRcTrZfZdDpyRLO8GvpH8tRQNNRef7+5Lh3tQZvlzJfCtKPhXYKKkE7MuarSKiP2LpcsBZZa+AB6VtEbSghL7pwDri9Y3JNsOIGmBpF5JvZs3b65SqWbZcUCZpW9ORJxPYSjvM5LeN5I3iYilEdESES2TJ0+ubIVmOXDQgJJ0iqRuSc9L+rmkzyXbj5X0mKQXkr+Tql+uWe2LiI3J303Ag8CsQYdsBE4pWj852WYZ8A0S2RlOD2oPcH1EnA3MpvCN72zgRuDxiDgDeDxZN7MhSBovacK+18ClwHODDnsI+JPkbr7ZwG8j4pWUSx31PBdf9g56F1/SMF5JXu+Q1EdhPPxK4MLksHuBJ4AbqlKlWf04AXgw+TZ+BPD/IuL7ktoAIqITWAHMBdYCbwLXZlTrqOcwytYh3WYuaRpwHrAaOKHoW92rFBpeqXMWAAsApk6dOuJCzepBRKwDzimxvbPodQCfSbMuszwa9k0Sko4C/gH484jYXrwvaVAlv2r4Qq6ZmY3EsAJK0lgK4XRfRDyQbH5t37MZyd9N1SnRzMxGo+HcxSdgGdAXEbcX7XoIuDp5fTWwvPLlmZnZaDWca1DvBf4YeFbS08m2RcAtwHcktQIvAZ+oSoVmZjYqDecuvh6g3AMAF1e2HDOz/Cj17JPv7EuPZ5IwMythXziNHTuWnp4exo4de8B2qz7PZm5mVsbYsWPZvXs3ALt372bcuHH09/dnXNXo4R6UmVkZ3d3dQ65bdTmgzMzKuOiii4Zct+pyQJmZldHf38+4ceP44Q9/6OG9DPgalJlZCRGBJPr7+5kzZ84B2y0dDigzszIcRtnyEJ+ZmeWSA8rMzHLJAWVmZrnkgDIzs1xyQJmZldHe3k5TUxOSaGpqor29PeuSRhUHlJlZCe3t7XR2drJkyRLeeOMNlixZQmdnp0MqRQ4oM7MS7rrrLm699VYWLlzIkUceycKFC7n11lu56667si5t1HBAmZmVsGvXLtra2g7Y1tbWxq5duzKqaPRxQJmZldDY2EhnZ+cB2zo7O2lsbMyootHHM0mYmZUwf/58brjhBqDQc+rs7OSGG254W6/KqscBZZYiSacA3wJOAAJYGhFfHXTMhcBy4FfJpgci4osplmnAHXfcAcCiRYu4/vrraWxspK2tbf92qz4HlFm69gDXR8RTkiYAayQ9FhHPDzruXyLiigzqsyJ33HGHAylDvgZllqKIeCUinkpe7wD6gCnZVmWWTw4os4xImgacB6wusfs9kp6R9D1J08ucv0BSr6TezZs3V7NUs0w4oMwyIOko4B+AP4+I7YN2PwWcGhHnAHcA/1jqPSJiaUS0RETL5MmTq1qvWRYcUGYpkzSWQjjdFxEPDN4fEdsjYmfyegUwVtJxKZdpljkHlFmKJAlYBvRFxO1ljvmd5DgkzaLQTn+TXpVm+eC7+MzS9V7gj4FnJT2dbFsETAWIiE7gY8CfSdoD/AdwVfinXW0UckCZpSgiegAd5Jg7gTvTqcgsvzzEZ2ZmueSAMjOzXHJAmZlZLjmgzMwslxxQZmaWSw4oMzPLJQeUmZnlkgPKzMxyyQFlZma55IAyM7NcckDVuK6uLmbMmEFDQwMzZsygq6sr65LM6obbV7Y8F18N6+rqoqOjg2XLljFnzhx6enpobW0FYN68eRlXZ1bb3L5yICJGvACXAb8E1gI3Huz4mTNnhlXO9OnTY+XKlQdsW7lyZUyfPj2jiuoX0BuH0VaqvbhtVZ7bV3rKtS/FCGfxl9QA/BvwQWAD8BNgXkQ8X+6clpaW6O3tHdHn2ds1NDTw1ltvMXbs2P3b+vv7aWpqYmBgIMPK6o+kNRHRknUd5bhtVZ7bV3rKta/DuQY1C1gbEesiYjfwbeDKw3g/O0TNzc309PQcsK2np4fm5uaMKjKrH25f2TucgJoCrC9a35Bss5R0dHTQ2tpKd3c3/f39dHd309raSkdHR9almdU8t6/sVf0mCUkLgAUAU6dOrfbHjSr7LtS2t7fT19dHc3Mzixcv9gVcswpw+8re4VyDeg9wc0R8KFn/AkBEfKncOR4nt1rla1Bm1VONa1A/Ac6QdJqkccBVwEOH8X5mZmb7jXiILyL2SLoOeARoAO6OiJ9XrDIzMxvVDusaVESsAFZUqBYzM7P9PNWRmZnlkgPKzMxyyQFlZma5NOLbzEf0YdJm4KXUPnB0OQ54Pesi6tipETE56yLKcduqOrev6irZvlINKKseSb15fk7HrJa5fWXDQ3xmZpZLDigzM8slB1T9WJp1AWZ1zO0rA74GZWZmueQelJmZ5ZIDyszMcskBVeMk3S1pk6Tnsq7FrN64fWXLAVX77gEuy7oIszp1D25fmXFA1biIeBLYknUdZvXI7StbDigzM8slB5SZmeWSA8rMzHLJAWVmZrnkgKpxkrqAVcBZkjZIas26JrN64faVLU91ZGZmueQelJmZ5ZIDyszMcskBZWZmueSAMjOzXHJAmZlZLjmgzMwslxxQZmaWS/8fttl58rUcZWgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('제목의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('제목의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('제목의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bcd897b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 전처리 후 결과:  0    saurav kant alumnus upgrad iiit pg program mac...\n",
      "1    kunal shah credit card bill payment platform c...\n",
      "2    new zealand defeated india wickets fourth odi ...\n",
      "3    aegon life iterm insurance plan customers enjo...\n",
      "4    speaking sexual harassment allegations rajkuma...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "clean_text = []\n",
    "\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "clean_text = data['text'].apply(lambda x: preprocess_sentence(x) if pd.notnull(x) else \"\")\n",
    "\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c82dcbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines 전처리 후 결과:  0    upgrad learner switches to career in ml al wit...\n",
      "1    delhi techie wins free food from swiggy for on...\n",
      "2    new zealand end rohit sharma led india match w...\n",
      "3    aegon life iterm insurance plan helps customer...\n",
      "4    have known hirani for yrs what if metoo claims...\n",
      "Name: headlines, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "clean_headlines = []\n",
    "\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "clean_headlines = data['headlines'].apply(lambda x: preprocess_sentence(x,remove_stopwords=False) if pd.notnull(x) else \"\")\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "556b3202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7927a887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0c778f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a2499965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9922ac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.9998576657177715\n",
      "전체 샘플 중 길이가 12 이하인 샘플의 비율: 0.9881150874339162\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(summary_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9a6d1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 굳이 할 필요 없을 것 같긴한데...\n",
    "# text 열에서 단어 시퀀스 길이 제한\n",
    "data['text'] = data['text'].apply(lambda s: ' '.join(s.split()[:text_max_len]) if pd.notnull(s) else s)\n",
    "\n",
    "# headlines 열에서 단어 시퀀스 길이 제한\n",
    "data['headlines'] = data['headlines'].apply(lambda s: ' '.join(s.split()[:summary_max_len]) if pd.notnull(s) else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b93a9c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2a0f7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제목에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e19723bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "38959519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41129 83074 46320 ... 78006 92386 90138]\n"
     ]
    }
   ],
   "source": [
    "# 셔플 \n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ca00fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일하게 \n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f2230d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19672\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "29e35550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04bb3c",
   "metadata": {},
   "source": [
    "### 인코더 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d1976043",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "35b55aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78688"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8833d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c00f46e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69782\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 45803\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 : 23979\n",
      "단어 집합에서 희귀 단어의 비율 : 65.63727035625233\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율 : 3.1020956817483905\n",
      "         word  frequency  inverse_frequency  freq_inverse_ratio        TF  \\\n",
      "0  government       8915           0.000112                 1.0  1.000000   \n",
      "1      monday       3673           0.000272                 1.0  0.291786   \n",
      "2     imposed        564           0.001773                 1.0  0.042883   \n",
      "3      import        114           0.008772                 1.0  0.008593   \n",
      "4        duty        382           0.002618                 1.0  0.027989   \n",
      "\n",
      "        IDF    TF-IDF  \n",
      "0  2.177656  2.177656  \n",
      "1  3.064222  0.894097  \n",
      "2  4.936433  0.211690  \n",
      "3  6.528327  0.056100  \n",
      "4  5.325224  0.149050  \n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(src_tokenizer.word_index)  # 단어 집합 크기\n",
    "rare_cnt = 0  # 등장 빈도수가 threshold보다 작은 단어 개수\n",
    "total_freq = 0  # 전체 단어 빈도수 총합\n",
    "rare_freq = 0  # 희귀 단어 빈도수 총합\n",
    "\n",
    "# 전체 문서 수 (예: 샘플 수)\n",
    "total_documents = len(encoder_input_train)\n",
    "# 결과 저장용 리스트\n",
    "freq_inverse_freq_data = []\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    # 전체 빈도수 합계\n",
    "    total_freq += value\n",
    "\n",
    "    # 희귀 단어 체크\n",
    "    if value < threshold:\n",
    "        rare_cnt += 1\n",
    "        rare_freq += value\n",
    "\n",
    "    # 빈도-역빈도 계산 (TF와 IDF 추가)\n",
    "    tf = value / total_freq  # Term Frequency (TF)\n",
    "    idf = math.log((total_documents + 1) / (value + 1))  # Inverse Document Frequency (IDF)\n",
    "    tf_idf = tf * idf  # TF-IDF 계산\n",
    "\n",
    "    # 빈도, 역빈도, TF-IDF 데이터 저장\n",
    "    inverse_frequency = 1 / value\n",
    "    freq_inverse_ratio = value * inverse_frequency\n",
    "    freq_inverse_freq_data.append((key, value, inverse_frequency, freq_inverse_ratio, tf, idf, tf_idf))\n",
    "\n",
    "# 결과 출력\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s' % (threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 : %s' % (total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율 :\", (rare_cnt / total_cnt) * 100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율 :\", (rare_freq / total_freq) * 100)\n",
    "\n",
    "# 빈도-역빈도 데이터프레임 생성\n",
    "import pandas as pd\n",
    "freq_df = pd.DataFrame(freq_inverse_freq_data, columns=[\n",
    "    \"word\", \"frequency\", \"inverse_frequency\", \"freq_inverse_ratio\", \"TF\", \"IDF\", \"TF-IDF\"\n",
    "])\n",
    "\n",
    "# 상위 몇 개 단어를 출력\n",
    "print(freq_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "168603ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00032806689789110225"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df['TF-IDF'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a7141399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 10000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c0ed4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 60, 897, 3958, 1365, 30, 1788, 1275, 5763, 2135, 3054, 1036, 2474, 5763, 1170, 1414, 3158, 4732, 163, 289, 33, 1138, 8, 293, 3958, 1365, 592, 1414], [24, 2792, 744, 87, 24, 1935, 71, 160, 111, 441, 130, 95, 757, 71, 2413, 2212, 107, 2243, 1637, 130, 692, 1889, 71, 2212, 2413, 107, 76, 904, 130, 4252, 71], [196, 2648, 14, 1227, 3159, 6984, 4253, 1943, 9177, 815, 1289, 1801, 2633, 2920, 187, 171, 1638, 584, 4, 815, 8428, 1289, 4057, 3160, 101, 55, 80, 2576]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89f06b",
   "metadata": {},
   "source": [
    "### 디코더 (타겟) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b3e4141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "52b2c20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 30212\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 20709\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 : 9503\n",
      "단어 집합에서 희귀 단어의 비율 : 68.54561101549054\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율 : 5.349849686517276\n",
      "       word  frequency  inverse_frequency  freq_inverse_ratio        TF  \\\n",
      "0  sostoken      78688           0.000013                 1.0  1.000000   \n",
      "1      govt       2182           0.000458                 1.0  0.026982   \n",
      "2   imposes         52           0.019231                 1.0  0.000643   \n",
      "3       tax        298           0.003356                 1.0  0.003669   \n",
      "4        on      10154           0.000098                 1.0  0.111126   \n",
      "\n",
      "        IDF    TF-IDF  \n",
      "0  0.000000  0.000000  \n",
      "1  3.584803  0.096724  \n",
      "2  7.302967  0.004693  \n",
      "3  5.572815  0.020447  \n",
      "4  2.047537  0.227534  \n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index)  # 단어 집합 크기\n",
    "rare_cnt = 0  # 등장 빈도수가 threshold보다 작은 단어 개수\n",
    "total_freq = 0  # 전체 단어 빈도수 총합\n",
    "rare_freq = 0  # 희귀 단어 빈도수 총합\n",
    "\n",
    "# 전체 문서 수 (예: 샘플 수)\n",
    "total_documents = len(decoder_input_train)\n",
    "# 결과 저장용 리스트\n",
    "freq_inverse_freq_data = []\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    # 전체 빈도수 합계\n",
    "    total_freq += value\n",
    "\n",
    "    # 희귀 단어 체크\n",
    "    if value < threshold:\n",
    "        rare_cnt += 1\n",
    "        rare_freq += value\n",
    "\n",
    "    # 빈도-역빈도 계산 (TF와 IDF 추가)\n",
    "    tf = value / total_freq  # Term Frequency (TF)\n",
    "    idf = math.log((total_documents + 1) / (value + 1))  # Inverse Document Frequency (IDF)\n",
    "    tf_idf = tf * idf  # TF-IDF 계산\n",
    "\n",
    "    # 빈도, 역빈도, TF-IDF 데이터 저장\n",
    "    inverse_frequency = 1 / value\n",
    "    freq_inverse_ratio = value * inverse_frequency\n",
    "    freq_inverse_freq_data.append((key, value, inverse_frequency, freq_inverse_ratio, tf, idf, tf_idf))\n",
    "\n",
    "# 결과 출력\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s' % (threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 : %s' % (total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율 :\", (rare_cnt / total_cnt) * 100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율 :\", (rare_freq / total_freq) * 100)\n",
    "\n",
    "# 빈도-역빈도 데이터프레임 생성\n",
    "import pandas as pd\n",
    "freq_df = pd.DataFrame(freq_inverse_freq_data, columns=[\n",
    "    \"word\", \"frequency\", \"inverse_frequency\", \"freq_inverse_ratio\", \"TF\", \"IDF\", \"TF-IDF\"\n",
    "])\n",
    "\n",
    "# 상위 몇 개 단어를 출력\n",
    "print(freq_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9fc4749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 24, 2230, 342, 7, 3261, 6, 2441, 1639], [1, 161, 1435, 194, 4835, 158, 3333], [1, 4249, 151, 250, 1407, 3, 6849, 2961, 754], [1, 379, 820, 6, 1923, 3, 5218, 58, 47, 1811], [1, 3899, 176, 3678, 95, 3, 21, 353, 924, 6479]]\n",
      "target\n",
      "decoder  [[24, 2230, 342, 7, 3261, 6, 2441, 1639, 2], [161, 1435, 194, 4835, 158, 3333, 2], [4249, 151, 250, 1407, 3, 6849, 2961, 754, 2], [379, 820, 6, 1923, 3, 5218, 58, 47, 1811, 2], [3899, 176, 3678, 95, 3, 21, 353, 924, 6479, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 8000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "21cd0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 78687\n",
      "훈련 레이블의 개수 : 78687\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b42b22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705683e",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘 사용하기(추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9c768",
   "metadata": {},
   "source": [
    "* layer와 텐서 라이브러리가 위 과정 어딘가에서 더럽혀지는 현상이 확인되었다.\n",
    "* 재정의를 해주니까 에러없이 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4b0f8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "31962a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding \n",
    "\n",
    "def positional_encoding(max_position, d_model):\n",
    "    positions = np.arange(max_position)[:, np.newaxis]\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "    pos_encoding = np.zeros((max_position, d_model))\n",
    "    pos_encoding[:, 0::2] = np.sin(positions * div_term)\n",
    "    pos_encoding[:, 1::2] = np.cos(positions * div_term)\n",
    "    return tf.cast(pos_encoding[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "#어텐션 블록\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights\n",
    "\n",
    "# 멀티헤드 \n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "        self.dense = Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.split_heads(self.wq(q), batch_size)\n",
    "        k = self.split_heads(self.wk(k), batch_size)\n",
    "        v = self.split_heads(self.wv(v), batch_size)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(q, k, v, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "        return output\n",
    "\n",
    "# ffn\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        Dense(dff, activation='relu'),\n",
    "        Dense(d_model)\n",
    "    ])\n",
    "\n",
    "# 트랜스포머 \n",
    "class TransformerLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1, name=None):\n",
    "        super(TransformerLayer, self).__init__(name=name)  # 이름을 부모 클래스에 전달\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        attn_output = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "\n",
    "# 함수 \n",
    "def build_transformer_model(text_vocab_size, summary_vocab_size, text_max_len, summary_max_len, d_model=128, num_heads=4, dff=512, num_layers=4, dropout_rate=0.1):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(text_max_len,), name=\"encoder_inputs\")\n",
    "    encoder_embedding = Embedding(text_vocab_size, d_model)(encoder_inputs)\n",
    "    encoder_pos_encoding = positional_encoding(text_max_len, d_model)\n",
    "    encoder_output = encoder_embedding + encoder_pos_encoding\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        encoder_output = TransformerLayer(d_model, num_heads, dff, dropout_rate, name=f\"encoder_layer_{i}\")(encoder_output)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(summary_max_len,), name=\"decoder_inputs\")\n",
    "    decoder_embedding = Embedding(summary_vocab_size, d_model)(decoder_inputs)\n",
    "    decoder_pos_encoding = positional_encoding(summary_max_len, d_model)\n",
    "    decoder_output = decoder_embedding + decoder_pos_encoding\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        # 디코더는 인코더 출력를 받게끔\n",
    "        decoder_output = TransformerLayer(d_model, num_heads, dff, dropout_rate, name=f\"decoder_layer_{i}\")(decoder_output)\n",
    "        attention_output = MultiHeadAttention(d_model, num_heads)(decoder_output, encoder_output, encoder_output)\n",
    "        decoder_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(decoder_output + attention_output)\n",
    "\n",
    "    # 최종\n",
    "    final_output = Dense(summary_vocab_size, activation='softmax', name=\"final_dense\")(decoder_output)\n",
    "\n",
    "    return Model(inputs=[encoder_inputs, decoder_inputs], outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0c7dd5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 \n",
    "text_vocab_size = 15000  \n",
    "summary_vocab_size = 8000  \n",
    "text_max_len = 50\n",
    "summary_max_len = 12\n",
    "d_model = 128  # 임베딩 차원\n",
    "num_heads = 4  # 멀티헤드 어텐션의 헤드 수\n",
    "dff = 512  # FFN의 차원\n",
    "num_layers = 4  # 트랜스포머 레이어\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# 모델 빌드\n",
    "model = build_transformer_model(\n",
    "    text_vocab_size=text_vocab_size,\n",
    "    summary_vocab_size=summary_vocab_size,\n",
    "    text_max_len=text_max_len,\n",
    "    summary_max_len=summary_max_len,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    num_layers=num_layers,\n",
    "    dropout_rate=dropout_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4e131d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 50, 128)      1920000     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_34 (TFOpLa (None, 50, 128)      0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_0 (TransformerLay (None, 50, 128)      198272      tf.__operators__.add_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 12, 128)      1024000     decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_1 (TransformerLay (None, 50, 128)      198272      encoder_layer_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_35 (TFOpLa (None, 12, 128)      0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_2 (TransformerLay (None, 50, 128)      198272      encoder_layer_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_0 (TransformerLay (None, 12, 128)      198272      tf.__operators__.add_35[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer_3 (TransformerLay (None, 50, 128)      198272      encoder_layer_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_45 (MultiH (None, None, 128)    66048       decoder_layer_0[0][0]            \n",
      "                                                                 encoder_layer_3[0][0]            \n",
      "                                                                 encoder_layer_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_36 (TFOpLa (None, 12, 128)      0           decoder_layer_0[0][0]            \n",
      "                                                                 multi_head_attention_45[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_92 (LayerNo (None, 12, 128)      256         tf.__operators__.add_36[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_1 (TransformerLay (None, 12, 128)      198272      layer_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_47 (MultiH (None, None, 128)    66048       decoder_layer_1[0][0]            \n",
      "                                                                 encoder_layer_3[0][0]            \n",
      "                                                                 encoder_layer_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_37 (TFOpLa (None, 12, 128)      0           decoder_layer_1[0][0]            \n",
      "                                                                 multi_head_attention_47[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_95 (LayerNo (None, 12, 128)      256         tf.__operators__.add_37[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_2 (TransformerLay (None, 12, 128)      198272      layer_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_49 (MultiH (None, None, 128)    66048       decoder_layer_2[0][0]            \n",
      "                                                                 encoder_layer_3[0][0]            \n",
      "                                                                 encoder_layer_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_38 (TFOpLa (None, 12, 128)      0           decoder_layer_2[0][0]            \n",
      "                                                                 multi_head_attention_49[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_98 (LayerNo (None, 12, 128)      256         tf.__operators__.add_38[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_3 (TransformerLay (None, 12, 128)      198272      layer_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_51 (MultiH (None, None, 128)    66048       decoder_layer_3[0][0]            \n",
      "                                                                 encoder_layer_3[0][0]            \n",
      "                                                                 encoder_layer_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_39 (TFOpLa (None, 12, 128)      0           decoder_layer_3[0][0]            \n",
      "                                                                 multi_head_attention_51[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_101 (LayerN (None, 12, 128)      256         tf.__operators__.add_39[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "final_dense (Dense)             (None, 12, 8000)     1032000     layer_normalization_101[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 5,827,392\n",
      "Trainable params: 5,827,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9f452af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c35b3f",
   "metadata": {},
   "source": [
    "### accuracy는 괜히 넣은듯 싶다\n",
    "* 과적합까지 굉장히 오래 걸릴 듯 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "73208cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1230/1230 [==============================] - 79s 56ms/step - loss: 6.2053 - accuracy: 0.2038 - val_loss: 6.1197 - val_accuracy: 0.2071\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.11969, saving model to best_transformer_weights.h5\n",
      "Epoch 2/5\n",
      "1230/1230 [==============================] - 67s 55ms/step - loss: 6.1561 - accuracy: 0.2040 - val_loss: 6.1154 - val_accuracy: 0.2071\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.11969 to 6.11545, saving model to best_transformer_weights.h5\n",
      "Epoch 3/5\n",
      "1230/1230 [==============================] - 68s 55ms/step - loss: 6.1514 - accuracy: 0.2040 - val_loss: 6.1101 - val_accuracy: 0.2071\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.11545 to 6.11012, saving model to best_transformer_weights.h5\n",
      "Epoch 4/5\n",
      "1230/1230 [==============================] - 67s 55ms/step - loss: 6.1488 - accuracy: 0.2040 - val_loss: 6.1096 - val_accuracy: 0.2071\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.11012 to 6.10957, saving model to best_transformer_weights.h5\n",
      "Epoch 5/5\n",
      "1230/1230 [==============================] - 67s 55ms/step - loss: 6.1472 - accuracy: 0.2040 - val_loss: 6.1073 - val_accuracy: 0.2071\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.10957 to 6.10726, saving model to best_transformer_weights.h5\n"
     ]
    }
   ],
   "source": [
    "# 가중치 저장 콜백\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_transformer_weights.h5',  \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True, \n",
    "    save_weights_only=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "history = model.fit(\n",
    "    [encoder_input_train, decoder_input_train], \n",
    "    decoder_target_train,  \n",
    "    validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \n",
    "    epochs=5, \n",
    "    batch_size=64,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002df86",
   "metadata": {},
   "source": [
    "## 과적합까지 시간이 없어 도달하지 못했지만, loss는 꾸준히 감소한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f9f2c2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "34c55e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 가중치 로드\n",
    "model.load_weights('best_transformer_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c725cbe",
   "metadata": {},
   "source": [
    "### 실제 결과와 요약문 비교하기(추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "27b09275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 변수 확인 및 매핑\n",
    "src_index_to_word = src_tokenizer.index_word  # 원문 단어 집합에서 정수 -> 단어\n",
    "tar_word_to_index = tar_tokenizer.word_index  # 요약 단어 집합에서 단어 -> 정수\n",
    "tar_index_to_word = tar_tokenizer.index_word  # 요약 단어 집합에서 정수 -> 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "45fb5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "encoder_model = Model(\n",
    "    inputs=model.input[0],  \n",
    "    outputs=model.get_layer(\"encoder_layer_3\").output  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2574ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization\n",
    "\n",
    "decoder_inputs = Input(shape=(1,), name=\"decoder_inputs_test\")  # 단어 단위 \n",
    "decoder_embedding = model.get_layer(\"embedding_11\")(decoder_inputs)  # 디코더 임베딩 \n",
    "decoder_pos_encoding = positional_encoding(1, d_model)  # 포지셔널 \n",
    "decoder_outputs = decoder_embedding + decoder_pos_encoding\n",
    "\n",
    "encoder_outputs = Input(shape=(text_max_len, d_model), name=\"encoder_outputs_test\")\n",
    "\n",
    "for i in range(4):  \n",
    "    decoder_layer = model.get_layer(f\"decoder_layer_{i}\")\n",
    "    mha_layer = model.get_layer(f\"multi_head_attention_{45 + i * 2}\")  # 정확한 레이어 이름 매핑\n",
    "    decoder_outputs = decoder_layer(decoder_outputs)\n",
    "    attention_output = mha_layer(decoder_outputs, encoder_outputs, encoder_outputs)\n",
    "    decoder_outputs = LayerNormalization(epsilon=1e-6)(decoder_outputs + attention_output)\n",
    "\n",
    "final_output = model.get_layer(\"final_dense\")(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_inputs, encoder_outputs], outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cd208dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    encoder_output = encoder_model.predict(input_seq)\n",
    "\n",
    "   \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        \n",
    "        output_tokens = decoder_model.predict([target_seq, encoder_output])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word.get(sampled_token_index, '<UNK>')\n",
    "\n",
    "        if sampled_token != 'eostoken':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        \n",
    "        if (sampled_token == 'eostoken' or len(decoded_sentence.split()) >= (summary_max_len - 1)):\n",
    "            stop_condition = True\n",
    "\n",
    "       \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c1ec5301",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1, 19672\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80/3271191860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_80/2017408077.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# 디코더 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1718\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[1;32m   1719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1720\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1721\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1647\u001b[0m           label, \", \".join(str(i.shape[0]) for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1648\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1, 19672\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "decode_sequence(encoder_input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d009e",
   "metadata": {},
   "source": [
    "### 인코더 디코더 분리에서 에러가 났다. \n",
    " * 1) 학습이 덜 되어서 문제가 일어났다.\n",
    " * 2) 인코더 디코더 분리 함수 자체에 문제가 있다. \n",
    "    * 받아오는 레이어 층수에 충돌이 난 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d7698",
   "metadata": {},
   "source": [
    "### Summa을 이용해서 추출적 요약해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae16004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: summa in /opt/conda/lib/python3.9/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.19 in /opt/conda/lib/python3.9/site-packages (from summa) (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/conda/lib/python3.9/site-packages (from scipy>=0.19->summa) (1.21.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c32942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c89666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines:\n",
      "Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience.\n",
      "The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike.\n",
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "\n",
    "# 첫번째행만\n",
    "text_to_summarize = data['text'][0]  \n",
    "\n",
    "# 요약\n",
    "summary = summarizer.summarize(text_to_summarize, ratio=0.3,words=50)\n",
    "\n",
    "# 요약이 비어있음?\n",
    "if summary:\n",
    "    print(\"headlines:\")\n",
    "    print(summary)\n",
    "else:\n",
    "    print(\"요약없음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b78d6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines:\n",
      "The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike.\n",
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "# 첫번째행만\n",
    "text_to_summarize = data['text'][0]  \n",
    "\n",
    "# 요약\n",
    "summary = summarizer.summarize(text_to_summarize, ratio=0.3,words=40)\n",
    "\n",
    "# 요약이 비어있음?\n",
    "if summary:\n",
    "    print(\"headlines:\")\n",
    "    print(summary)\n",
    "else:\n",
    "    print(\"요약없음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b5999",
   "metadata": {},
   "source": [
    "* decoder 시퀀스 디버깅 후, 원문과 비교한 다음\n",
    "* summa와 비교해볼것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
