{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "747cb3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41522771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding, [1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # SparseTensor를 일반 Dense Tensor로 변환\n",
    "    if isinstance(inputs, tf.SparseTensor):\n",
    "      inputs = tf.sparse.to_dense(inputs)\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "61cf45c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab55744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b63717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n",
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a5c8dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11b83ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ba60c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2426712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3503c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/aiffel/songys_chatbot/data/ChatbotData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3325511f",
   "metadata": {},
   "source": [
    "### 특이하게도 라벨이 존재한다\n",
    "* 0 : 중립\n",
    "* 1 : 긍정\n",
    "* 2 : 부정\n",
    "#### 이라고 하는데 아래 예시만봐도 틀린게 있는 것 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4827cab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ebc608f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5290\n",
       "1    3570\n",
       "2    2963\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "05212e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 11662\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 7779\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Q'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['A'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d0590c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac079971",
   "metadata": {},
   "source": [
    "### GPT는 이럴때 효율이 최고다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5704279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_contractions = {\n",
    "    \"맘\": \"마음\",\n",
    "    \"가바\": \"가봐\",\n",
    "    \"그런건가바\": \"그런 건가 봐\",\n",
    "    \"배고프당\": \"배고프다\",\n",
    "    \"졸리당\": \"졸리다\",\n",
    "    \"몰겠엉\": \"모르겠어\",\n",
    "    \"맛있엉\": \"맛있어\",\n",
    "    \"ㅂㅂ\": \"바이바이\",\n",
    "    \"ㅎㅇ\": \"안녕하세요\",\n",
    "    \"안녕ㅎㅇ\": \"안녕하세요\",\n",
    "    \"ㅋㅋ\": \"웃음\",\n",
    "    \"ㅠㅠ\": \"슬픔\",\n",
    "    \"ㅇㅇ\": \"응\",\n",
    "    \"ㅈㅅ\": \"죄송\",\n",
    "    \"ㅁㄹ\": \"모르겠어\",\n",
    "    \"넘\": \"너무\",\n",
    "    \"귀찮앙\": \"귀찮아\",\n",
    "    \"고마웡\": \"고마워\",\n",
    "    \"미안행\": \"미안해\",\n",
    "    \"알겠엉\": \"알겠어\",\n",
    "    \"안뇽\": \"안녕하세요\",\n",
    "    \"하쥬\": \"하죠\",\n",
    "    \"이게모얌\": \"이게 뭐야\",\n",
    "    \"졸려죽겟다\": \"졸려 죽겠다\",\n",
    "    \"재밋어\": \"재미있어\",\n",
    "    \"재밋엇다\": \"재미있었다\",\n",
    "    \"힘드러\": \"힘들어\",\n",
    "    \"잘될꺼야\": \"잘 될 거야\",\n",
    "    \"배고파죽겟어\": \"배고파 죽겠어\",\n",
    "    \"뭐하냥\": \"뭐하니\",\n",
    "    \"하루종일잇었엉\": \"하루 종일 있었어\",\n",
    "    \"괜찮을깡\": \"괜찮을까\",\n",
    "    \"모르겟다\": \"모르겠다\",\n",
    "    \"먹엇어\": \"먹었어\",\n",
    "    \"피곤해죽겟어\": \"피곤해 죽겠어\",\n",
    "    \"ㄱㄷ\": \"기다려\",\n",
    "    \"ㄱㅅ\": \"감사\",\n",
    "    \"ㄴㄴ\": \"아니야\",\n",
    "    \"ㄱㅇㄷ\": \"개이득\",\n",
    "    \"ㅎㄹ\": \"할래\",\n",
    "    \"ㅊㅋ\": \"축하\",\n",
    "    \"이해안대\": \"이해 안 돼\",\n",
    "    \"잘자용\": \"잘 자\",\n",
    "    \"ㅂㅇㅂㅇ\": \"바이바이\",\n",
    "    \"감동이얌\": \"감동이야\",\n",
    "    \"빠이\": \"안녕\",\n",
    "    \"몰루\": \"몰라\",\n",
    "    \"넘좋아\": \"너무 좋아\",\n",
    "    \"쫌만더\": \"조금만 더\",\n",
    "    \"심심해쥬금\": \"심심해 죽겠음\",\n",
    "    \"알았엉\": \"알았어\",\n",
    "    \"피곤해쥬금\": \"피곤해 죽겠음\",\n",
    "    \"기달려\": \"기다려\",\n",
    "    \"그랬엉\": \"그랬어\",\n",
    "    \"졸려죽겟음\": \"졸려 죽겠음\",\n",
    "    \"도와줘잉\": \"도와줘\",\n",
    "    \"배아파쥬금\": \"배 아파 죽겠음\",\n",
    "    \"배불러죽겟어\": \"배불러 죽겠어\",\n",
    "    \"행복해쥬금\": \"행복해 죽겠어\",\n",
    "    \"맛없엉\": \"맛없어\",\n",
    "    \"피곤햌\": \"피곤해\",\n",
    "    \"귀찮아용\": \"귀찮아\",\n",
    "    \"미치겟다\": \"미치겠다\",\n",
    "    \"좋아햌\": \"좋아해\",\n",
    "    \"재밋겟당\": \"재미있겠다\",\n",
    "    \"잘잇어\": \"잘 있어\",\n",
    "    \"오랜만이얌\": \"오랜만이야\",\n",
    "    \"대박이얌\": \"대박이야\",\n",
    "    \"웃기당\": \"웃기다\",\n",
    "    \"졸귀\": \"졸라 귀여워\",\n",
    "    \"행쇼\": \"행복하자\",\n",
    "    \"안믿겟다\": \"안 믿겠다\",\n",
    "    \"모햌\": \"뭐해\",\n",
    "    \"배고팡\": \"배고파\",\n",
    "    \"슬프당\": \"슬프다\",\n",
    "    \"귀찮앜\": \"귀찮아\",\n",
    "    \"졸립다\": \"졸리다\",\n",
    "    \"머해\": \"뭐해\",\n",
    "    \"놀자아\": \"놀자\",\n",
    "    \"알겟엉\": \"알겠어\",\n",
    "    \"반가웡\": \"반가워\",\n",
    "    \"어케해\": \"어떻게 해\",\n",
    "    \"배불러옹\": \"배불러\",\n",
    "    \"오키\": \"오케이\",\n",
    "    \"뭐해용\": \"뭐해\",\n",
    "    \"행복햌\": \"행복해\",\n",
    "    \"쩐다\": \"대단하다\",\n",
    "    \"빨리해줘\": \"빨리 해줘\",\n",
    "    \"나쫌졸려\": \"나 좀 졸려\",\n",
    "    \"짱나\": \"짜증나\",\n",
    "    \"놀고싶당\": \"놀고 싶다\",\n",
    "    \"모르겟엉\": \"모르겠어\",\n",
    "    \"졸려어\": \"졸려\",\n",
    "    \"그럴껄\": \"그럴 걸\",\n",
    "    \"밥먹엇니\": \"밥 먹었니\",\n",
    "    \"뭐드셧어요\": \"뭐 드셨어요\",\n",
    "    \"맛있어보엉\": \"맛있어 보여\",\n",
    "    \"나힘들어ㅠ\": \"나 힘들어\",\n",
    "    \"배부르당\": \"배부르다\",\n",
    "    \"웃기넼\": \"웃기네\",\n",
    "    \"이해안됨\": \"이해 안 돼\",\n",
    "    \"졸림\": \"졸려\",\n",
    "    \"집에갈랭\": \"집에 갈래\",\n",
    "    \"덥다아\": \"덥다\",\n",
    "    \"좋겠다아\": \"좋겠다\",\n",
    "    \"심심햌\": \"심심해\",\n",
    "    \"집가고싶엉\": \"집 가고 싶어\",\n",
    "    \"뭐임\": \"뭐야\",\n",
    "    \"미쳣다\": \"미쳤다\",\n",
    "    \"오랫만\": \"오랜만\",\n",
    "    \"어케알았어\": \"어떻게 알았어\",\n",
    "    \"신기하당\": \"신기하다\",\n",
    "    \"조심하세용\": \"조심하세요\",\n",
    "    \"잼잇당\": \"재미있다\",\n",
    "    \"심심하당\": \"심심하다\",\n",
    "    \"감사합니당\": \"감사합니다\",\n",
    "    \"감동이얌\": \"감동이야\",\n",
    "    \"피곤해욤\": \"피곤해요\",\n",
    "    \"알앗어\": \"알았어\",\n",
    "    \"즐겁당\": \"즐겁다\",\n",
    "    \"귀여웡\": \"귀여워\",\n",
    "    \"힘들엉\": \"힘들어\",\n",
    "    \"속상해쥬금\": \"속상해 죽겠음\",\n",
    "    \"아깝당\": \"아깝다\",\n",
    "    \"잘못햇어\": \"잘못했어\",\n",
    "    \"이뻐용\": \"예뻐요\",\n",
    "    \"맛있겠당\": \"맛있겠다\",\n",
    "    \"멋져용\": \"멋져요\",\n",
    "    \"좋아욤\": \"좋아요\",\n",
    "    \"졸린다아\": \"졸린다\",\n",
    "    \"보고싶당\": \"보고 싶다\",\n",
    "    \"힘들다아\": \"힘들다\",\n",
    "    \"이해했엉\": \"이해했어\",\n",
    "    \"맛나보엉\": \"맛나 보여\",\n",
    "    \"웃곀\": \"웃겨\",\n",
    "    \"귀찮군\": \"귀찮아\",\n",
    "    \"보고싶엉\": \"보고 싶어\",\n",
    "    \"짜증난당\": \"짜증난다\",\n",
    "    \"잘될꺼얌\": \"잘 될 거야\",\n",
    "    \"잘잤엉\": \"잘 잤어\",\n",
    "    \"졸리웡\": \"졸려\",\n",
    "    \"미안혀\": \"미안해\",\n",
    "    \"힘내세욤\": \"힘내세요\",\n",
    "    \"졸린당\": \"졸리다\",\n",
    "    \"모르겟삼\": \"모르겠다\",\n",
    "    \"빨리와\": \"빨리 와\",\n",
    "    \"헐대박\": \"정말 대단하다\",\n",
    "    \"놀랫자나\": \"놀랐잖아\",\n",
    "    \"기여워\": \"귀여워\",\n",
    "    \"심심해요ㅠ\": \"심심해요\",\n",
    "    \"사랑햌\": \"사랑해\",\n",
    "    \"어이엄슴\": \"어이없음\",\n",
    "    \"몰라욤\": \"몰라요\",\n",
    "    \"뭥미\": \"뭐임\",\n",
    "    \"덥당\": \"덥다\",\n",
    "    \"추웡\": \"추워\",\n",
    "    \"대단하당\": \"대단하다\",\n",
    "    \"기다리쥬\": \"기다려줘\",\n",
    "    \"뭐하냥용\": \"뭐하니\",\n",
    "    \"못참겟어\": \"못 참겠어\",\n",
    "    \"미쳤넼\": \"미쳤네\",\n",
    "    \"졸려죽겟엉\": \"졸려 죽겠어\"\n",
    "}\n",
    "\n",
    "# 정규화 \n",
    "def normalize_text(text, contractions_dict):\n",
    "    for contraction, expansion in contractions_dict.items():\n",
    "        text = text.replace(contraction, expansion)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492caf8",
   "metadata": {},
   "source": [
    "### 라벨을 줬는데 이걸 안 써먹을 순 없겠다.\n",
    "### 학습할 때, 라벨을 맨 앞에 넣어준다면? 그 라벨을 따라서 방향을 학습하겠지\n",
    "* 단, 중립,긍정,부정이라는 말이 우리의 일상에서도 쓰이기 때문에 유의해야할 것이다. 숫자(1,2,3?)로 넣으면??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8b1084f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>중립 12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>중립 1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>중립 3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>중립 3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>중립 PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>부정 훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>부정 훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>부정 흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>부정 힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>부정 힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Q                         A  label\n",
       "0                       중립 12시 땡!                하루가 또 가네요.      0\n",
       "1                  중립 1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 중립 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              중립 3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      중립 PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                           ...                       ...    ...\n",
       "11818           부정 훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           부정 훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              부정 흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  부정 힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               부정 힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규화 적용\n",
    "data['Q'] = data['Q'].apply(lambda x: normalize_text(x, korean_contractions))\n",
    "\n",
    "# 라벨링 써먹기 \n",
    "label_mapping = {0: '중립', 1: '긍정', 2: '부정'}\n",
    "data['Q'] = data.apply(lambda row: f\"{label_mapping[row['label']]} {row['Q']}\", axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57ae60c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 \n",
    "def preprocess_sentence(sentence):\n",
    "    # 입력받은 sentence를 양쪽 공백을 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\"]+', \" \", sentence)\n",
    "\n",
    "    # (ㄱ-ㅎ, 가-힣, a-z, A-Z, 0-9, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백으로 대체합니다. (숫자+한글+영어+문장부호)\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎ가-힣a-zA-Z0-9?.!,]+\", \" \", sentence) #정규표현식\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "88ad8270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# data['Q']와 data['A']에 대해 질문과 답변 쌍 생성 함수\n",
    "def load_conversations(data):\n",
    "    inputs, outputs = [], []\n",
    "    for q, a in zip(data['Q'], data['A']):\n",
    "        # 전처리 함수를 질문에만 적용 (답변에는 적용하지 않음)\n",
    "        inputs.append(preprocess_sentence(q))\n",
    "        outputs.append(a)\n",
    "    return inputs, outputs\n",
    "\n",
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations(data)\n",
    "\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb8ddb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 중립 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요.\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "52bfeae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23646"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions + answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93a6ee38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdee21",
   "metadata": {},
   "source": [
    "### 이왕이면 2의 승수로 맞춰주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3618a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87bc5eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0369aeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [14396]\n",
      "END_TOKEN의 번호 : [14397]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "93872746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14398\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1b204",
   "metadata": {},
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "52a714be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [3, 8, 9009, 6922, 124, 208, 55]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [3918, 13509, 472, 24, 621, 28, 14186]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[9555]))) # 혹시 1,2,3으로 들어갔나? \n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[9555])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f7e7cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 최대 길이: 16\n",
      "대답 최대 길이: 21\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 열에 대해 최대 길이를 추출하는 함수\n",
    "def get_max_length_for_column(dataframe, column_name):\n",
    "    return max(len(sentence.split()) for sentence in dataframe[column_name])\n",
    "\n",
    "# data 데이터프레임의 'Q' 열에 대해 최대 길이 추출\n",
    "max_len_questions = get_max_length_for_column(pd.DataFrame(data), 'Q')\n",
    "print('질문 최대 길이:', max_len_questions)\n",
    "\n",
    "# data 데이터프레임의 'A' 열에 대해 최대 길이 추출\n",
    "max_len_questions = get_max_length_for_column(pd.DataFrame(data), 'A')\n",
    "print('대답 최대 길이:', max_len_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b89e887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# 최대길이 설정 깔끔하게[]\n",
    "MAX_LENGTH = 20\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d8e2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0355c26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 14398\n",
      "필터링 후의 질문 샘플 개수: 11805\n",
      "필터링 후의 답변 샘플 개수: 11805\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f20190d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 12000 \n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44d4f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c736c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    4740096     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    5267456     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 14398)  3700286     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,707,838\n",
      "Trainable params: 13,707,838\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46d588b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    # y_pred의 길이에 맞춰 y_true를 reshape\n",
    "    y_true = tf.reshape(y_true, shape=(-1, tf.shape(y_pred)[1]))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eedeffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # step을 float32로 변환\n",
    "        step = tf.cast(step, tf.float32) # 타입 맞춰주기\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc7fd216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a146b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # 여기도 y_pred의 길이에 맞춰 y_true를 reshape\n",
    "    y_true = tf.reshape(y_true, shape=(-1, tf.shape(y_pred)[1]))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e156cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 15s 47ms/step - loss: 7.8428 - accuracy: 0.5520\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 4.4687 - accuracy: 0.6814\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 2.0940 - accuracy: 0.7754\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 1.7508 - accuracy: 0.7861\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 1.6213 - accuracy: 0.7927\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 1.5144 - accuracy: 0.7986\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 1.3947 - accuracy: 0.8072\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 1.2646 - accuracy: 0.8190\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 1.1288 - accuracy: 0.8344\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.9877 - accuracy: 0.8510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7d58daed49d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f42d23",
   "metadata": {},
   "source": [
    "### 10번만 더해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adb95795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.8421 - accuracy: 0.8669\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.6923 - accuracy: 0.8854\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.5487 - accuracy: 0.9050\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.4211 - accuracy: 0.9236\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.3087 - accuracy: 0.9430\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.2186 - accuracy: 0.9585\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.1498 - accuracy: 0.9717\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.1076 - accuracy: 0.9793\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.0822 - accuracy: 0.9837\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 9s 49ms/step - loss: 0.0688 - accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwqklEQVR4nO3dd3hUZfr/8fedSSWdJJQkdBBMKAFCt2BDbOB3LQsCioggCljWtey6u6zlp6vrWlEBFVQUZLEsNlBUREWBgCCEJgaEUANCQktCkvv3xww4YAIJyXCSzP26rlzMOec5Zz45wNxznlMeUVWMMcb4rwCnAxhjjHGWFQJjjPFzVgiMMcbPWSEwxhg/Z4XAGGP8nBUCY4zxc1YITJUQkU9E5IaqbuskEdkoIhf6YLvzRGS45/UgEfm0PG1P4X0ai8h+EXGdalbjH6wQ+DHPh8SRnxIROeQ1Pagi21LVS1T1tapuWx2JyH0iMr+U+fEiUigibcu7LVV9U1X7VFGuYwqXqm5S1QhVLa6K7R/3XioiLat6u8YZVgj8mOdDIkJVI4BNwBVe89480k5EAp1LWS1NBXqKSLPj5g8AVqjqSgcyGXPKrBCY3xGR3iKSLSL3ish2YLKIxIrIhyKSIyJ7PK+Tvdbx7u4YKiLfiMi/PW03iMglp9i2mYjMF5F9IjJXRMaLyNQycpcn40Mi8q1ne5+KSLzX8iEi8ouI7BaRv5a1f1Q1G/gCGHLcouuB10+W47jMQ0XkG6/pi0RkjYjkisjzgHgtayEiX3jy7RKRN0UkxrPsDaAx8IHniO4eEWnq+eYe6GmTKCKzRORXEVkvIjd7bXuciMwQkdc9+yZTRNLL2gdlEZFozzZyPPvyAREJ8CxrKSJfeX63XSLytme+iMhTIrJTRPJEZEVFjqpM5VkhMGVpANQFmgAjcP9bmeyZbgwcAp4/wfrdgLVAPPA48IqIyCm0fQtYBMQB4/j9h6+38mS8DrgRqAcEA3cDiEgK8KJn+4me9yv1w9vjNe8sItIaSPPkrei+OrKNeOBd4AHc++JnoJd3E+BRT74zgUa49wmqOoRjj+oeL+UtpgPZnvWvBv6fiJzvtbyfp00MMKs8mUvxHBANNAfOxV0cb/Qsewj4FIjFvW+f88zvA5wDnOFZ91pg9ym8tzlVqmo/9gOwEbjQ87o3UAiEnqB9GrDHa3oeMNzzeiiw3mtZHUCBBhVpi/tDtAio47V8KjC1nL9TaRkf8Jq+FZjtef13YLrXsnDPPriwjG3XAfKAnp7pR4D/neK++sbz+nrge692gvuDe3gZ270S+KG0v0PPdFPPvgzEXTSKgUiv5Y8CUzyvxwFzvZalAIdOsG8VaHncPJdnn6V4zRsJzPO8fh2YCCQft975wDqgOxDg9P8Ff/yxIwJTlhxVzT8yISJ1RGSC53A/D5gPxEjZV6RsP/JCVQ96XkZUsG0i8KvXPIDNZQUuZ8btXq8PemVK9N62qh7gBN9KPZn+C1zvOXoZhPuD7lT21RHHZ1DvaRGpLyLTRWSLZ7tTcR85lMeRfbnPa94vQJLX9PH7JlQqdn4oHgjybLe097gHd3Fb5Ol6Ggagql/gPvoYD+wUkYkiElWB9zWVZIXAlOX4x9L+CWgNdFPVKNyH8uDVh+0D24C6IlLHa16jE7SvTMZt3tv2vGfcSdZ5DXc3xkVAJPBBJXMcn0E49vf9f7j/Xtp5tjv4uG2e6FHCW3Hvy0iveY2BLSfJVBG7gMO4u8R+9x6qul1Vb1bVRNxHCi+I58ojVX1WVTvjPhI5A/hzFeYyJ2GFwJRXJO6+7r0iUhf4h6/fUFV/ATKAcSISLCI9gCt8lHEmcLmInCUiwcCDnPz/x9fAXtzdHdNVtbCSOT4CUkXkD55v4mNxd5EdEQnsB3JFJInff1juwN03/zuquhlYADwqIqEi0h64CfdRxakK9mwrVERCPfNmAI+ISKSINAHuOvIeInKN10nzPbgLV4mIdBGRbiISBBwA8oGSSuQyFWSFwJTX00AY7m993wOzT9P7DgJ64O6meRh4Gygoo+3TnGJGVc0EbsN9sncb7g+q7JOso7i7g5p4/qxUDlXdBVwDPIb7920FfOvV5J9AJyAXd9F497hNPAo8ICJ7ReTuUt5iIO7zBluB94B/qOrc8mQrQybugnfk50ZgDO4P8yzgG9z781VP+y7AQhHZj/tk9O2qmgVEAZNw7/NfcP/uT1Qil6kg8ZysMaZG8FxyuEZVfX5EYoy/sCMCU615ug1aiEiAiPQF+gPvOxzLmFrF7hg11V0D3F0gcbi7akap6g/ORjKmdrGuIWOM8XPWNWSMMX6uxnUNxcfHa9OmTZ2OYYwxNcqSJUt2qWpCactqXCFo2rQpGRkZTscwxpgaRUR+KWuZdQ0ZY4yfs0JgjDF+zgqBMcb4uRp3jsAYU70cPnyY7Oxs8vPzT97Y+FxoaCjJyckEBQWVex0rBMaYSsnOziYyMpKmTZtS9thD5nRQVXbv3k12djbNmh0/kmrZrGvIGFMp+fn5xMXFWRGoBkSEuLi4Ch+dWSEwxlSaFYHq41T+LvymEGzYdYB/zV6DPVLDGGOO5TeF4LNV23lx3s/8+9O1TkcxxlSh3bt3k5aWRlpaGg0aNCApKenodGFh4QnXzcjIYOzYsSd9j549e1ZJ1nnz5nH55ZdXybaqkt+cLL757OZs2HWA8V/+TMPoMAZ3b3LylYwx1V5cXBzLli0DYNy4cURERHD33b+Ny1NUVERgYOkfdenp6aSnp5/0PRYsWFAlWasrvzkiEBEe6t+W81on8Pf/rWTuqh1ORzLG+MjQoUO55ZZb6NatG/fccw+LFi2iR48edOzYkZ49e7J2rbtnwPsb+rhx4xg2bBi9e/emefPmPPvss0e3FxERcbR97969ufrqq2nTpg2DBg062t388ccf06ZNGzp37szYsWMr9M1/2rRptGvXjrZt23LvvfcCUFxczNChQ2nbti3t2rXjqaeeAuDZZ58lJSWF9u3bM2DAgMrvLPzoiAAg0BXA89d1YuCk7xk9bSnTbu5Ox8axTscyptb45weZrNqaV6XbTEmM4h9XpFZ4vezsbBYsWIDL5SIvL4+vv/6awMBA5s6dy1/+8hfeeeed362zZs0avvzyS/bt20fr1q0ZNWrU767H/+GHH8jMzCQxMZFevXrx7bffkp6ezsiRI5k/fz7NmjVj4MCB5c65detW7r33XpYsWUJsbCx9+vTh/fffp1GjRmzZsoWVK1cCsHfvXgAee+wxNmzYQEhIyNF5leU3RwRHhIcE8soNXagXGcpNr2WwcdcBpyMZY3zgmmuuweVyAZCbm8s111xD27ZtufPOO8nMzCx1ncsuu4yQkBDi4+OpV68eO3b8vuega9euJCcnExAQQFpaGhs3bmTNmjU0b9786LX7FSkEixcvpnfv3iQkJBAYGMigQYOYP38+zZs3JysrizFjxjB79myioqIAaN++PYMGDWLq1KlldnlVlF8dERyREBnClBu7cNWLC7hh8iLeHdWTuIgQp2MZU+Odyjd3XwkPDz/6+m9/+xvnnXce7733Hhs3bqR3796lrhMS8tvngMvloqio6JTaVIXY2FiWL1/OnDlzeOmll5gxYwavvvoqH330EfPnz+eDDz7gkUceYcWKFZUuCH53RHBE84QIXr6hC9tz8xn2WgaHCoudjmSM8ZHc3FySkpIAmDJlSpVvv3Xr1mRlZbFx40YA3n777XKv27VrV7766it27dpFcXEx06ZN49xzz2XXrl2UlJRw1VVX8fDDD7N06VJKSkrYvHkz5513Hv/617/Izc1l//79lc7vt4UAoHOTWJ4d2JEfs/cyZtpSiopLnI5kjPGBe+65h/vvv5+OHTv65Bt8WFgYL7zwAn379qVz585ERkYSHR1datvPP/+c5OTkoz8bN27kscce47zzzqNDhw507tyZ/v37s2XLFnr37k1aWhqDBw/m0Ucfpbi4mMGDB9OuXTs6duzI2LFjiYmJqXR+n45ZLCJ9gWcAF/Cyqj523PLGwGtAjKfNfar68Ym2mZ6erlU9MM3r323k7//LZHD3xjzUv63dJWlMBaxevZozzzzT6RiO279/PxEREagqt912G61ateLOO+90JEtpfyciskRVS71W1mdHBCLiAsYDlwApwEARSTmu2QPADFXtCAwAXvBVnhO5vkdTRp7bnKnfb+LFr352IoIxpoabNGkSaWlppKamkpuby8iRI52OVG6+PFncFVivqlkAIjId6A+s8mqjQJTndTSw1Yd5Tujei9uwbW8+j89eS8PoUP6vY7JTUYwxNdCdd97p2BFAZfmyECQBm72ms4Fux7UZB3wqImOAcODC0jYkIiOAEQCNGzeu8qAAAQHCE9e0J2dfAffM/JF6kaH0ahnvk/cyprZRVetSrSZOpbvf6ZPFA4EpqpoMXAq8ISK/y6SqE1U1XVXTExISfBYmJNDFS0M60zw+glveWMLqbVV7Y4wxtVFoaCi7d++2BzpWA0fGIwgNDa3Qer48ItgCNPKaTvbM83YT0BdAVb8TkVAgHtjpw1wnFB0WxOQbu/CHFxYwdPIi3ru1F4kxYU7FMabaS05OJjs7m5ycHKejGH4boawifFkIFgOtRKQZ7gIwALjuuDabgAuAKSJyJhAKOP6vKTEmjCnDunDNi98xdPIi/ntLT6LDyj/smzH+JCgoqEKjYZnqx2ddQ6paBIwG5gCrcV8dlCkiD4pIP0+zPwE3i8hyYBowVKvJ8WWbBlFMGNKZDbsOMPKNDAqK7IYzY0zt5NP7CHzBF/cRnMj7P2zhjreXcUWHRJ75YxoBAXZCzBhT85zoPgK/fNZQRVzZMYmtuYd4fPZaEmNCuf8Su3HGGFO7WCEoh1HntmDr3kNM+CqLxOgwbujZ1OlIxhhTZawQlIOI8M9+bdmRV8C4DzKpHxVK37YNnI5ljDFVwun7CGoMV4Dw7ICOdEiO4fbpP7Dklz1ORzLGmCphhaACwoJdvHJDOg2jQxn+2mKycir/+FdjjHGaFYIKiosI4bVhXQkQ4YbJi8jZV+B0JGOMqRQrBKegSVw4rwztQs6+AoZNWcyBAt+MUGSMMaeDFYJTlNYohucHdiJzay6j37JBbYwxNZcVgkq4MKU+D13Zli/X5vC3/620h24ZY2oku3y0kgZ1a8K2vfk8/+V6EqPDGHNBK6cjGWNMhVghqAJ/6nMGW3MP8eRn62gQHco16Y1OvpIxxlQTVgiqgIjw2B/aszOvgPvfXUH9qFDOOcN34yYYY0xVsnMEVSQ4MIAXB3eiZb0IRk1dQubWXKcjGWNMuVghqEKRoUFMubEr0WFBDJ28mOw9B52OZIwxJ2WFoIo1iA5lyrCu5B8uZujkxew9WOh0JGOMOSErBD5wRv1IJl2fzqbdBxnx+hLyD9ugNsaY6sunhUBE+orIWhFZLyL3lbL8KRFZ5vlZJyJ7fZnndOrePI4nr+3Aoo2/8qcZyykpsXsMjDHVk8+uGhIRFzAeuAjIBhaLyCxVXXWkjare6dV+DNDRV3mccEWHRLbn5vPIx6tpGB3KA5enOB3JGGN+x5eXj3YF1qtqFoCITAf6A6vKaD8Q+IcP8zhi+NnN2LL3EC9/s4GGMWHcdJYN8m2MqV58WQiSgM1e09lAt9IaikgToBnwhQ/zOEJE+NvlKWzPzefhj1bRMDqUS9s1dDqWMcYcVV1OFg8AZqpqqWdVRWSEiGSISEZOTs5pjlZ5rgDh6QFpdGocyx1vL2Pxxl+djmSMMUf5shBsAbyftZDsmVeaAcC0sjakqhNVNV1V0xMSauYdu6FBLl6+Pp3kmDBumrKYNdvznI5kjDGAbwvBYqCViDQTkWDcH/azjm8kIm2AWOA7H2apFmLDg3ltWFfCgl1c/8oiNv9qN5wZY5zns0KgqkXAaGAOsBqYoaqZIvKgiPTzajoAmK5+8gznRnXr8MZN3SgoKmHwKwtthDNjjOOkpn3+pqena0ZGhtMxKm3ppj0MmrSQpvHhvD2yO1GhQU5HMsbUYiKyRFXTS1tWXU4W+51OjWN5aUhn1u/cx/DXMuzuY2OMY6wQOOjcMxL4z7VpLN74qw13aYxxjBUCh13RIZEH+7dl7uqd3PvOCnsUhTHmtLOBaaqBId2bsOdAIf/5bB0xdYJ44LIzERGnYxlj/IQVgmpizPkt+fVAIa98s4G64cHcdl5LpyMZY/yEFYJqQkT4++Up7D1YyBNz1hJbJ5jrujV2OpYxxg9YIahGAgKEJ67pQF5+EQ+8v4KYOkH2XCJjjM/ZyeJqJsgVwPjrOrmfSzR9Gd/8tMvpSMaYWs4KQTUUFuzilaFdaJ4Qzog3Mli2ea/TkYwxtZgVgmoqOiyI14d1JS4imBsnL2L9zn1ORzLG1FJWCKqxelGhTL2pG66AAIa8sogtew85HckYUwtZIajmmsSF8/qwruwvKGLIKwvZvd8eUmeMqVpWCGqAlMQoXh3ahS17DnHjlMXsLyhyOpIxphaxQlBDdGlalxcHdyJzax4jXs+goMgeUmeMqRpWCGqQ89vU59/XtGfBz7u5fdoyiu25RMaYKmCFoIb5v47J/P3yFGZnbuev762gpo0nYYypfuzO4hpo2FnN2HOwkOe+WE9seDD39m3jdCRjTA3m0yMCEekrImtFZL2I3FdGm2tFZJWIZIrIW77MU5vcddEZDOrWmBfn/cyk+VlOxzHG1GA+OyIQERcwHrgIyAYWi8gsVV3l1aYVcD/QS1X3iEg9X+WpbUSEB/u3Ze+hwzzy8Wpi6gRxTXojp2MZY2ogX3YNdQXWq2oWgIhMB/oDq7za3AyMV9U9AKq604d5ah1XgPDUtWnkHTrMfe+uIDosiD6pDZyOZYypYXzZNZQEbPaazvbM83YGcIaIfCsi34tI39I2JCIjRCRDRDJycnJ8FLdmCg4M4KXBnWmXFM3oaT/wfdZupyMZY2oYp68aCgRaAb2BgcAkEYk5vpGqTlTVdFVNT0hIOL0Ja4DwkEAmD+1C47p1GP5aBiu35DodyRhTg/iyEGwBvDutkz3zvGUDs1T1sKpuANbhLgymgmLDg3njpq5EhwVxw6uL2LDrgNORjDE1hC8LwWKglYg0E5FgYAAw67g27+M+GkBE4nF3FdklMKeoYXQYb9zUFYDBLy9ke26+w4mMMTWBzwqBqhYBo4E5wGpghqpmisiDItLP02wOsFtEVgFfAn9WVevkroTmCRFMubEruYcOc/2rC9l7sNDpSMaYak5q2p2p6enpmpGR4XSMau+7n3dzw+RFpCZG8ebwbtQJtnsHjfFnIrJEVdNLW+b0yWLjIz1axPHcwI4s37yXW6YupbCoxOlIxphqygpBLXZxagMeu6o989flcNcMe0idMaZ01l9Qy12b3og9Bwp59JM1xNYJ5sH+qYiI07GMMdWIFQI/MPLcFvx6sJAJX2VRNzyYOy86w+lIxphqxAqBn7ivbxv2HjjMM5//RGydIIb2auZ0JGNMNWGFwE+ICI/8X1v2Hipk3AeriKkTzJUdj3/ihzHGH9nJYj8S6ArgmQEd6dE8jrv/u5wv1uxwOpIxphqwQuBnQoNcTLy+MymJUdzyxlI+zdzudCRjjMOsEPihyNAg3ripGymJUdz65lI+/HGr05GMMQ6yQuCnosOCmDq8G50axzJ22g+8syTb6UjGGIdYIfBjESGBTBnWhZ4t4rl75nLeWrjJ6UjGGAdYIfBzdYIDefmGdM5rXY+/vLeCyd9ucDqSMeY0s0JgCA1y8dLgzlzStgH//GAVL8772elIxpjTyAqBAdxDXj43sCP90xL51+w1PPXZOmrak2mNMafGbigzRwW6AvjPtWmEBAbwzOc/kV9UzH1929iziYyp5awQmGO4AoTH/tCekEAXE77KouBwCX+/PIWAACsGxtRWVgjM7wQECA/2TyU0KIBJX2+goKiYR65sZ8XAmFrKp+cIRKSviKwVkfUicl8py4eKSI6ILPP8DPdlHlN+IsJfLj2TMee3ZNqizdz93+UUFdvgNsbURj47IhARFzAeuAjIBhaLyCxVXXVc07dVdbSvcphTJyL8qU9rQgID+Pen6ygoKuHpAWkEuewaA2NqE192DXUF1qtqFoCITAf6A8cXAlPNjT6/FaFBLh7+aDUFRcU8f10nQoNcTscyxlQRX361SwI2e01ne+Yd7yoR+VFEZopIo9I2JCIjRCRDRDJycnJ8kdWcxPCzm/PQlW2Zu3onN7+ewaHCYqcjGWOqiNPH+B8ATVW1PfAZ8FppjVR1oqqmq2p6QkLCaQ1ofjOkexMev7o936zfxY1TFrG/oMjpSMaYKuDLQrAF8P6Gn+yZd5Sq7lbVAs/ky0BnH+YxVeDa9EY8/cc0Fm/cw/WvLCQv/7DTkYwxlVSuQiAi4SIS4Hl9hoj0E5Ggk6y2GGglIs1EJBgYAMw6brsNvSb7AavLH904pX9aEuOv68iKLbkMmrSQPQcKnY5kjKmE8h4RzAdCRSQJ+BQYAkw50QqqWgSMBubg/oCfoaqZIvKgiPTzNBsrIpkishwYCwyt+K9gnNC3bUMmDkln7Y59DJz0Pbv2F5x8JWNMtSTleZ6MiCxV1U4iMgYIU9XHRWSZqqb5POFx0tPTNSMj43S/rSnDNz/tYvjri0mKCePN4d1pEB3qdCRjTClEZImqppe2rLxHBCIiPYBBwEeeeXb9oOGsVvG8Pqwb23Pz+ePE78jec9DpSMaYCipvIbgDuB94z9O90xz40mepTI3StVldpg7vxp4Dhfxxwvds3HXA6UjGmAooVyFQ1a9UtZ+q/stz0niXqo71cTZTg3RsHMtbN3fnYGER1074jvU79zsdyRhTTuW9augtEYkSkXBgJbBKRP7s22impmmbFM3bI3tQovDHCd+xelue05GMMeVQ3q6hFFXNA64EPgGa4b5yyJhjnFE/khkjuxPkCmDgpO9ZkZ3rdCRjzEmUtxAEee4buBKYpaqHARu+ypSqeUIEM0b2ICIkkOsmfc+SX351OpIx5gTKWwgmABuBcGC+iDQB7LjflKlxXB1mjOxBfGQIQ15ZxHc/73Y6kjGmDOU9Wfysqiap6qXq9gtwno+zmRouMSaMt0d0JykmjKGTF/HVOntgoDHVUXlPFkeLyH+OPAFURJ7EfXRgzAnViwpl+ojuNE+I4ObXMvhs1Q6nIxljjlPerqFXgX3AtZ6fPGCyr0KZ2iUuIoTpN3fnzIaRjJq6hI9+3OZ0JGOMl/IWghaq+g9VzfL8/BNo7stgpnaJrhPE1OHd6Ng4hjHTlvLeD9lORzLGeJS3EBwSkbOOTIhIL+CQbyKZ2ioyNIjXhnWle/M47pqxnGmLNjkdyRhD+YeqvAV4XUSiPdN7gBt8E8nUZnWCA3l1aBdumbqE+99dQcHhYob2auZ0LGP8WnmvGlquqh2A9kB7Ve0InO/TZKbWCg1yMWFIZ/qk1GfcB6t4Zu5PlOcpuMYY36jQCGWqmue5wxjgLh/kMX4iJNDF+EGd+EOnJJ6au467ZiynoMjGQTbGCeXtGiqNVFkK45eCXAE8eU0HmsWF8+Rn68jec5AJQ9KpGx7sdDRj/Eplxiw+6bG8iPQVkbUisl5E7jtBu6tEREWk1EETTO0lIoy5oBXPX9eR5dm5XDn+W3tyqTGn2QkLgYjsE5G8Un72AYknWdcFjAcuAVKAgSKSUkq7SOB2YOEp/xamxru8fSLTR7gfY/2HF77l2/W7nI5kjN84YSFQ1UhVjSrlJ1JVT9at1BVY77nvoBCYDvQvpd1DwL+A/FP6DUyt0alxLO/d2osG0aHc8Ooiu7zUmNOkMl1DJ5MEbPaazvbMO0pEOgGNVPUjTkBERhx5vEVOjj2vpjZrVLcOM0f1pGfLeO5/dwWPfryakhK7osgYX/JlITghz0hn/wH+dLK2qjpRVdNVNT0hIcH34YyjokKDePWGdK7v0YQJ87O4ZeoSDhYWOR3LmFrLl4VgC9DIazrZM++ISKAtME9ENgLdgVl2wtgABLoCeLB/W8ZdkcLc1Tu4dsJ3bM+13kNjfMGXhWAx0EpEmolIMDAAmHVkoarmqmq8qjZV1abA90A/Vc3wYSZTwwzt1YyXb0hnQ84Brhz/LSu32IhnxlQ1nxUCVS0CRgNzgNXADFXNFJEHRaSfr97X1D7nt6nPzFE9CRC4dsJ39ihrY6qY1LRb+9PT0zUjww4a/NHOvHxufj2DH7fk8tdLz+Sms5ohYvc1GlMeIrJEVUvtenfsZLExFeUe5KYHfVMb8PBHq/nr+ys5XFzidCxjajwrBKZGCQt2Mf66TtzauwVvLdzEsCmLyT102OlYxtRoVghMjRMQINzTtw2PX92e77N2c9WLC9i0+6DTsYypsawQmBrr2vRGvD6sGzn7CrjyhW9Z8suvTkcypkayQmBqtB4t4njv1p5EhwUxcNJC/rdsy8lXMsYcwwqBqfGaJ0Tw7qiedGwUw+3Tl/H03HU20I0xFWCFwNQKseHBvHFTN67unMzTc3/ijreXkX/YBroxpjwqMzCNMdVKcGAAT1zdnuYJ4Tw+ey3Zew4xcUhn4iJCnI5mTLVmRwSmVhERbu3dkhcGdWLlllyufOFbftqxz+lYxlRrVghMrXRpu4a8PbIHhwpL+MOLC/j6J3t8uTFlsUJgaq20RjH8b3QvkmLCGDp5MW8u/MXpSMZUS1YITK2WFBPGzFE9OadVPH99byUPf7iKYhvoxphjWCEwtV5ESCCTrk9naM+mvPzNBka+sYQDBTbQjTFHWCEwfiHQFcC4fqk82D+VL9bs4JqXvmNb7iGnYxlTLVghMH7l+h5NeXVoFzb9epArx3/Limwb6MYYKwTG7/RuXY93RvUkMCCAayd8x5zM7U5HMsZRVgiMX2rdIJL3b+tF6waR3DJ1CRO++tkeS2H8lk8LgYj0FZG1IrJeRO4rZfktIrJCRJaJyDcikuLLPMZ4S4gMYfqI7lzariGPfrKGkW8sIWdfgdOxjDntfFYIRMQFjAcuAVKAgaV80L+lqu1UNQ14HPiPr/IYU5rQIBfPDejIA5edybx1OVz89Hw+WbHN6VjGnFa+PCLoCqxX1SxVLQSmA/29G6hqntdkOGDH5ua0CwgQhp/dnI/HnkVybBij3lzKHdN/IPegjXxm/IMvC0ESsNlrOtsz7xgicpuI/Iz7iGBsaRsSkREikiEiGTk59qgA4xst60Xyzqie3HXRGXz44zb6PP0V89budDqWMT7n+MliVR2vqi2Ae4EHymgzUVXTVTU9ISHh9AY0fiXIFcDYC1rx/m29iA4LYujkxdz/7gr22w1ophbzZSHYAjTymk72zCvLdOBKH+YxptzaJkXzwZizGHluc6Yv3kTfp+fzfdZup2MZ4xO+LASLgVYi0kxEgoEBwCzvBiLSymvyMuAnH+YxpkJCAl3cf8mZzLylB64AYeCk73now1U24I2pdXxWCFS1CBgNzAFWAzNUNVNEHhSRfp5mo0UkU0SWAXcBN/gqjzGnqnOTunxy+9kM6d6EV77ZwGXPfs3yzXudjmVMlZGadhNNenq6ZmRkOB3D+KlvftrFPTOXs2NfAbf2bsGY81sRHOj4qTZjTkpElqhqemnL7F+wMRVwVqt4Zt95DlemJfHcF+u5cvy3rNmed/IVjanGrBAYU0FRoUE8eW0HJg7pzM59+Vzx3De8MG+9jXNgaiwrBMacoj6pDfj0znO5KKU+j89eyzUvLWDDrgNOxzKmwqwQGFMJdcODGX9dJ54ZkMbPOQe45Jn5vLZgIyV2dGBqECsExlSSiNA/LYlP7zyH7s3j+MesTAa/spDsPQedjmZMuVghMKaK1I8KZfLQLjz2h3Ys37yXvk9/zYyMzfZ4a1PtWSEwpgqJCAO6Nmb2HeeQmhjFPTN/ZPhrGezcl+90NGPKZIXAGB9oVLcO027uzt8uT+Gb9bvo89R8Pvxxq9OxjCmVFQJjfCQgQLjprGZ8NPZsmsSFM/qtHxgz7Qf2HCh0Opoxx7BCYIyPtawXwTu39ODuPmcwe+U2+jw9ny/W7HA6ljFHWSEw5jQIdAUw+nz3463jwoMZNiWDe2YuZ1++DX5jnGeFwJjTKDUxmv+N7sWtvVswc0k2fZ/+mgU/73I6lvFzVgiMOc1CAl3c07cN/72lJ8GBAVw3aSHjZmVyqNAeb22cYYXAGId0bhLLx2PPZmjPpkxZsJFLn/2apZv2OB3L+CErBMY4KCzYxbh+qbw1vBuFRSVc9eIC7pj+AxvtmUXmNLJCYEw10LNlPJ/ccTYjz2nB7MztXPCfr7j/3R/ZuveQ09GMH/BpIRCRviKyVkTWi8h9pSy/S0RWiciPIvK5iDTxZR5jqrOo0CDuu6QN8/98HoO7NWbmkmx6PzGPf36QSc6+AqfjmVrMZyOUiYgLWAdcBGTjHsN4oKqu8mpzHrBQVQ+KyCigt6r+8UTbtRHKjL/I3nOQZz//iZlLsgkJdHFjr6aMPKcF0XWCnI5maiCnRijrCqxX1SxVLQSmA/29G6jql6p65BGN3wPJPsxjTI2SHFuHx6/uwNy7zuXClPq8MO9nznr8C577/Cf2FxQ5Hc/UIr4sBEnAZq/pbM+8stwEfFLaAhEZISIZIpKRk5NThRGNqf6aJ0Tw3MCOfHL72XRrFseTn63j3Me/5OWvs8g/bJecmsqrFieLRWQwkA48UdpyVZ2oqumqmp6QkHB6wxlTTZzZMIqXb0jnvVt7cmbDKB7+aDW9n5jHmwt/4XBxidPxTA3my0KwBWjkNZ3smXcMEbkQ+CvQT1XtjJgxJ9GxcSxTh3fjrZu7kRgTyl/fW8kFT37Fu0uzbdxkc0p8WQgWA61EpJmIBAMDgFneDUSkIzABdxHY6cMsxtQ6PVvE886onrw6NJ2IkEDumrGcvk/P55MV22wwHFMhPisEqloEjAbmAKuBGaqaKSIPikg/T7MngAjgvyKyTERmlbE5Y0wpRITz29TnwzFnMf66TpSoMurNpfR7/lvmrd1pBcGUi88uH/UVu3zUmLIVFZfw/rKtPD13Hdl7DtGlaSx392lNt+ZxTkczDjvR5aNWCIyphQqLSnh78Sae+2I9O/cVcHareO7u05oOjWKcjmYcYoXAGD91qLCYN77fyIvzfmbPwcP0SanPn/q0pnWDSKejmdPMCoExfm5f/mFe/WYjL3+dxf7CIvp1SOTOC8+gaXy409HMaWKFwBgDwJ4DhUyYn8WUBRs4XKxcm57MmPNbkRgT5nQ042NWCIwxx9i5L58XvvyZtxZuAmBQ98bc2rslCZEhDiczvmKFwBhTqiMPtntn6RaCXQH2YLtazAqBMeaEsnL289Tcn/hg+VYiQwO5sWdTruiQSMt6EYiI0/FMFbBCYIwpl9Xb8njy03XMXb0DgObx4VzctgF9UxvQPjnaikINZoXAGFMhO/Ly+TRzO3Myd/Bd1m6KS5SG0aFcnNqAi1Mb0KVpLIGuavHMSlNOVgiMMads78FCPl+9k9mZ25m/LoeCohJi6wRxUUp9Lk5tQK+W8YQGuZyOaU7CCoExpkocLCziq7U5zM7czherd7KvoIjwYBfntanHxakNOK9NPSJCAp2OaUpxokJgf2PGmHKrExzIJe0ackm7hhQUFfPdz7uZk7mdTzN38OGP2wgODOCslvH0TW3AhSn1qRse7HRkUw52RGCMqbTiEmXJL3uYvXI7czK3s2XvIQIEujarS9/UBvRJbWA3rTnMuoaMMaeNqpK5Ne9oUfhp534AOiRHc3Fb98nmFgkRDqf0P1YIjDGOWb9zv6f7aDvLs3MBaFUvgr6eopCaGGWXpZ4GVgiMMdXClr2HPJelbmfRhl8pUUiKCTtaFDo3icUVYEXBF6wQGGOqnd37C5i7egdzMnfwzU+7KCwuIT4imItSGnBxan16tognONDuVagqjhUCEekLPAO4gJdV9bHjlp8DPA20Bwao6syTbdMKgTG1z778w8zzXJb65ZqdHCwsJjI0kB7N42ibFE1qYhSpidHUjwqxbqRT5MjloyLiAsYDFwHZwGIRmaWqq7yabQKGAnf7KocxpvqLDA3iig6JXNEhkfzDxXy7fhezV25nyS97+HTVjqPt4sKDSUmMOqY4NKlbhwDrTqoUX95H0BVYr6pZACIyHegPHC0EqrrRs6zEhzmMMTVIaJCLC86szwVn1gdgf0ERq7flkbkll8yteWRuzePlr7M4XOzuzYgICeTMhpGkJv5WHFrVjyDIHoFRbr4sBEnAZq/pbKDbqWxIREYAIwAaN25c+WTGmBojIiSQLk3r0qVp3aPzCoqK+WnHfjK3/lYcZmRs5mBhMQDBrgDOaBBBasNoUpPcxeHMhpHUCbZ7aEtTI/aKqk4EJoL7HIHDcYwxDgsJdNE2KZq2SdFH5xWXKBt3H3AXBs/Rw6ertvN2hvv7qIj7aareRw6piVHE2t3PPi0EW4BGXtPJnnnGGFPlXAFCi4QIWiRE0K9DIuC+uW1bbr7nqMFdHDI2/sqs5VuPrpcUE0ZKYtQxxaFhdKhfnZT2ZSFYDLQSkWa4C8AA4Dofvp8xxhxDREiMCSMxJoyLUuofnb/nQOExxSFzay5zV+/gyEWUdcODSU2M8hSIaJrFhVM/KoS4iJBaeZ+Dry8fvRT35aEu4FVVfUREHgQyVHWWiHQB3gNigXxgu6qmnmibdvmoMcYXDhQUsWZ7nqdrKY/Mbbms276fwuLfrmUJEEiIDKF+VCj1IkOpFxVC/chQ6kd55nn+rFsnuNpdyWQ3lBljzCkoLCph/c79ZO85yI59BezMy2dHXj478grY6ZnefaDwd+sFBgj1IkOoF/VbkXAXj99e148KITos6LR1QdljqI0x5hQEBwaQ4ukiKkthUQk5+wvYkZfvKRQFXsUinw27DvB91q/kHjpc6vbrHz2qCD16tPFb8XAXk8iQQJ8WDCsExhhTCcGBASTFhJF0ksds5x8uZmdeATv2eR1VeB1hrNmex/x1BewrKPrdumFBLupHhXDnRWfQPy2pyn8HKwTGGHMahAa5aBxXh8ZxdU7Y7kBBETv3HTmqyHcXj7x8duwrIC48xCfZrBAYY0w1Eh4SSLOQQJrFh5+297R7sI0xxs9ZITDGGD9nhcAYY/ycFQJjjPFzVgiMMcbPWSEwxhg/Z4XAGGP8nBUCY4zxczXuoXMikgP8coqrxwO7qjBOTWf741i2P35j++JYtWF/NFHVhNIW1LhCUBkiklHW0/f8ke2PY9n++I3ti2PV9v1hXUPGGOPnrBAYY4yf87dCMNHpANWM7Y9j2f74je2LY9Xq/eFX5wiMMcb8nr8dERhjjDmOFQJjjPFzflMIRKSviKwVkfUicp/TeZwiIo1E5EsRWSUimSJyu9OZqgMRcYnIDyLyodNZnCYiMSIyU0TWiMhqEenhdCaniMidnv8nK0VkmoiEOp3JF/yiEIiICxgPXAKkAANFJMXZVI4pAv6kqilAd+A2P94X3m4HVjsdopp4Bpitqm2ADvjpfhGRJGAskK6qbQEXMMDZVL7hF4UA6AqsV9UsVS0EpgP9Hc7kCFXdpqpLPa/34f5PXvWjYdcgIpIMXAa87HQWp4lINHAO8AqAqhaq6l5HQzkrEAgTkUCgDrDV4Tw+4S+FIAnY7DWdjZ9/+AGISFOgI7DQ4ShOexq4ByhxOEd10AzIASZ7uspeFpHTN3huNaKqW4B/A5uAbUCuqn7qbCrf8JdCYI4jIhHAO8AdqprndB6niMjlwE5VXeJ0lmoiEOgEvKiqHYEDgF+eUxORWNw9B82ARCBcRAY7m8o3/KUQbAEaeU0ne+b5JREJwl0E3lTVd53O47BeQD8R2Yi7y/B8EZnqbCRHZQPZqnrkKHEm7sLgjy4ENqhqjqoeBt4FejqcySf8pRAsBlqJSDMRCcZ9wmeWw5kcISKCu/93tar+x+k8TlPV+1U1WVWb4v538YWq1spvfeWhqtuBzSLS2jPrAmCVg5GctAnoLiJ1PP9vLqCWnjgPdDrA6aCqRSIyGpiD+8z/q6qa6XAsp/QChgArRGSZZ95fVPVj5yKZamYM8KbnS1MWcKPDeRyhqgtFZCawFPfVdj9QSx81YY+YMMYYP+cvXUPGGGPKYIXAGGP8nBUCY4zxc1YIjDHGz1khMMYYP2eFwBgPESkWkWVeP1V2R62INBWRlVW1PWOqkl/cR2BMOR1S1TSnQxhzutkRgTEnISIbReRxEVkhIotEpKVnflMR+UJEfhSRz0WksWd+fRF5T0SWe36OPJbAJSKTPM+3/1REwjztx3rGh/hRRKY79GsaP2aFwJjfhB3XNfRHr2W5qtoOeB7300oBngNeU9X2wJvAs575zwJfqWoH3M/pOXIXeytgvKqmAnuBqzzz7wM6erZzi29+NWPKZncWG+MhIvtVNaKU+RuB81U1y/PAvu2qGiciu4CGqnrYM3+bqsaLSA6QrKoFXttoCnymqq080/cCQar6sIjMBvYD7wPvq+p+H/+qxhzDjgiMKR8t43VFFHi9Lua3c3SX4R5BrxOw2DMIijGnjRUCY8rnj15/fud5vYDfhi4cBHztef05MAqOjoUcXdZGRSQAaKSqXwL3AtHA745KjPEl++ZhzG/CvJ7ICu5xe49cQhorIj/i/lY/0DNvDO6RvP6Me1SvI0/pvB2YKCI34f7mPwr3CFelcQFTPcVCgGf9fGhI4wA7R2DMSXjOEaSr6i6nsxjjC9Y1ZIwxfs6OCIwxxs/ZEYExxvg5KwTGGOPnrBAYY4yfs0JgjDF+zgqBMcb4uf8P5O7VJy3w6Q8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# 손실 저장\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None) # VAL 존재x\n",
    "\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "if val_loss is not None:\n",
    "    plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0607c6a5",
   "metadata": {},
   "source": [
    "### 그래프로는 뭔가 수상쩍은데 일단 진행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d532efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "928a6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdf9deee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 죽고싶다...\n",
      "출력 : 제가 곁에 있을게요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'제가 곁에 있을게요.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"죽고싶다...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e365a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕?\n",
      "출력 : 안녕하세요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"안녕?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef33023c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너 바보야?\n",
      "출력 : 저는 위로봇입니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 위로봇입니다.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너 바보야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b781e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 위로 해줘\n",
      "출력 : 제게 기대세요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'제게 기대세요.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"위로 해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "178618c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 고맙다\n",
      "출력 : 감사합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'감사합니다.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"고맙다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "daf17229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨 어때?\n",
      "출력 : 날씨 어플에 물어보세요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'날씨 어플에 물어보세요.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 날씨 어때?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18d532",
   "metadata": {},
   "source": [
    "### 생각보다 성능이 좋다. 데이터셋이 굉장히 단순하기 때문일 것\n",
    "* 데이터셋이 굉장히 늘어났을때가 궁금해지는 실습이었다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
